import "../messages/messages.tsp";

namespace Azure.AI.Projects;

@doc("Represents advanced options for controlling agent runs.")
model RunOptions {
  @doc("Strategy for truncating messages when input exceeds model limits.")
  truncationStrategy?: TruncationStrategy;
}

@doc("Enumerates known truncation strategy types, but also allows any custom fallback string.")
union TruncationStrategyType {
  string,

  @doc("Automatically truncate messages to fit limits.")
  auto: "auto",

  @doc("Truncate older messages, keeping only the last few.")
  lastMessages: "lastMessages",
}

@doc("Describes how to truncate messages if they exceed model or provider limits.")
model TruncationStrategy {
  @doc("The type of truncation strategy to apply. Known values: 'auto', 'lastMessages', or a custom string.")
  type: TruncationStrategyType;

  @doc("The number of most recent messages to retain when using 'lastMessages' strategy.")
  lastMessages?: int32;
}

@doc("Parameters for creating a new run request.")
model RunInputs {
  @doc("Unique identifier for the agent responsible for the run.")
  agentId: string;

  @doc("The list of input messages for the run.")
  input: ChatMessage[];

  @doc("Optional identifier for an existing conversation thread.")
  threadId?: string;

  @doc("Optional metadata associated with the run request.")
  metadata?: Record<string>;

  @doc("Optional configuration for run generation.")
  options?: RunOptions;

  @doc("Identifier for the user making the request.")
  userId?: string;
}

@doc("Detailed token usage data for a run request.")
model CompletionUsage {
  @doc("Number of run (completion) tokens used over the course of the run.")
  outputTokens: int64;

  @doc("Number of prompt tokens used over the course of the run step.")
  inputTokens: int64;

  @doc("Total number of tokens used (prompt + run).")
  totalTokens: int64;

  @doc("Details of the prompt tokens.")
  inputTokenDetails?: {
    @doc("The number of cached prompt tokens.")
    cachedTokens?: int32;
  };

  @doc("Breakdown of tokens used in a run.")
  outputTokenDetails?: {
    @doc("Tokens generated by the model for reasoning.")
    reasoningTokens?: int32;
  };
}

@doc("A streaming update indicating incremental changes to an agent-generated completion.")
model StreamingAgentCompletionUpdate {
  @doc("Identifier of the message being updated.")
  messageId: string;

  @doc("Optional name of the message author.")
  authorName?: string;

  @doc("Role of the author for the updated message.")
  authorRole?: AuthorRole;

  @doc("Optional content updates from the AI.")
  update?: StreamingOperation;

  @doc("Token usage information associated with this streaming update.")
  usage: CompletionUsage;
}

@doc("Known status values for a run, plus a fallback string for unrecognized statuses.")
union RunOutputsStatus {
  string,

  @doc("The run is ongoing.")
  inProgress: "inProgress",

  @doc("The run did not produce a complete output.")
  incomplete: "incomplete",

  @doc("The run was canceled.")
  cancelled: "cancelled",

  @doc("The run failed.")
  failed: "failed",

  @doc("The run completed successfully.")
  completed: "completed",
}

@doc("Fields describing the final run outcome, including status, output messages, and usage.")
model RunOutputs {
  @doc("Final status of the run request. Known values: 'inProgress', 'incomplete', 'cancelled', 'failed', 'completed' - or custom string.")
  status: RunOutputsStatus;

  @doc("List of output messages generated by the agent.")
  messages: ChatMessage[];

  @doc("Token usage details for this run.")
  usage: CompletionUsage;

  @doc("Details about why the response is incomplete, if applicable.")
  incompleteDetails?: {
    reason: string;
  };
}

@doc("An agent-generated run record, including both the requested inputs and the final outputs.")
@Rest.resource("runs")
model Run {
  @key
  @visibility(Lifecycle.Read)
  @doc("Unique identifier for this run.")
  @visibility(Lifecycle.Read)
  runId: string;

  @doc("Timestamp when the run was initiated (Unix time).")
  createdAt: safeint;

  @doc("Timestamp when the run finished processing (Unix time).")
  completedAt: safeint;

  @doc("The inputs that were used to start this run.")
  runInputs: RunInputs;

  @doc("The final outcome of this run, including status, output messages, token usage.")
  runOutputs: RunOutputs;

  @doc("Optional configuration for run generation.")
  options?: RunOptions;

  @doc("Identifier for the user making the request.")
  userId?: string;

  @doc("Flag indicating whether to store the run and associated messages.")
  store?: boolean;
}
