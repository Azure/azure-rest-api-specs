import "./content_parts.tsp";
import "@azure-tools/typespec-client-generator-core";

using Azure.ClientGenerator.Core;

namespace VoiceLive;

union ItemType {
  string,
  message: "message",
  function_call: "function_call",
  function_call_output: "function_call_output",
}

// Base for user content parts
@discriminator("type")
@usage(RequestUsage)
/** Base for any message content part; discriminated by `type`. */
model MessageContentPart {
  /** The type of the content part. */
  type: ContentPartType;
}

// Variants
@usage(RequestUsage)
/** Input text content part. */
model InputTextContentPart extends MessageContentPart {
  type: ContentPartType.input_text;
  text: string;
}

@usage(RequestUsage)
/** Input audio content part. */
model InputAudioContentPart extends MessageContentPart {
  type: ContentPartType.input_audio;
  audio: string;
  transcript?: string;
}

/** Output text content part. */
@usage(ResponseUsage)
model OutputTextContentPart extends MessageContentPart {
  /** The type of the content part. */
  type: ContentPartType.text;
  /** The text content. */
  text: string;
}

// Status enum
/** Indicates the processing status of an item or parameter. */
union ItemParamStatus {
  string,
  /** Item or parameter is still being processed. */
  completed: "completed",
  /** Item or parameter is not yet complete. */
  incomplete: "incomplete",
}

/** Base for any response item; discriminated by `type`. */
@discriminator("type")
@usage(RequestUsage)
model ConversationRequestItem {
  type: ItemType;
  id?: string;
}

// ----- Message Items -----
@discriminator("role")
@usage(RequestUsage)
/** A message item within a conversation. */
#suppress "@azure-tools/typespec-azure-core/no-multiple-discriminator" // The messages have multiple discriminators, but this is intentional. This follows the OpenAI style.
model MessageItem extends ConversationRequestItem {
  /** The type of the item; must be 'message' for message items. */
  type: ItemType.message;
  /** The role of the message origionator. */
  role: MessageRole;
  /** The content parts of the message. */
  content: MessageContentPart[];
  /** Processing status of the message item. */
  status?: ItemParamStatus;
}

@usage(RequestUsage)
#suppress "@azure-tools/typespec-azure-core/no-multiple-discriminator" // The messages have multiple discriminators, but this is intentional. This follows the OpenAI style.
/** A system message item within a conversation. */
model SystemMessageItem extends MessageItem {
  role: MessageRole.system;
}

@usage(RequestUsage)
#suppress "@azure-tools/typespec-azure-core/no-multiple-discriminator" // The messages have multiple discriminators, but this is intentional. This follows the OpenAI style.
/** A user message item within a conversation. */
model UserMessageItem extends MessageItem {
  role: MessageRole.user;
}

@usage(DualUsage)
#suppress "@azure-tools/typespec-azure-core/no-multiple-discriminator" // The messages have multiple discriminators, but this is intentional. This follows the OpenAI style.
/** An assistant message item within a conversation. */
model AssistantMessageItem extends MessageItem {
  role: MessageRole.assistant;
}

// ----- Function Call Items -----
@usage(RequestUsage)
/** A function call item within a conversation. */
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model FunctionCallItem extends ConversationRequestItem {
  type: ItemType.function_call;
  name: string;
  call_id: string;
  arguments: string;
  status?: ItemParamStatus;
}

@usage(RequestUsage)
/** A function call output item within a conversation. */
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model FunctionCallOutputItem extends ConversationRequestItem {
  type: ItemType.function_call_output;
  call_id: string;
  output: string;
  status?: ItemParamStatus;
}

@discriminator("type")
/** Base for any response item; discriminated by `type`. */
@usage(ResponseUsage)
model ResponseItem {
  // must stay here, required, broad type
  type: ItemType;
  id?: string;
  object?: "realtime.item";
}

@usage(ResponseUsage)
/** Base type for message item within a conversation. */
model ResponseMessageItem extends ResponseItem {
  type: ItemType.message;
  role: MessageRole;
  content: ContentPart[];
  status: ResponseItemStatus;
}

@usage(ResponseUsage)
/** A function call item within a conversation. */
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model ResponseFunctionCallItem
  extends ResponseItem {
  type: ItemType.function_call;
  name: string;
  call_id: string;
  arguments: string;
  status: ResponseItemStatus;
}

@usage(ResponseUsage)
/** A function call output item within a conversation. */
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model ResponseFunctionCallOutputItem
  extends ResponseItem {
  type: ItemType.function_call_output;
  call_id: string;
  output: string;
}

@usage(ResponseUsage)
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
/** Indicates the processing status of a response item. */
union ResponseItemStatus {
  string,
  /** Item that is in progress. */
  in_progress: "in_progress",
  /** Item has been fully processed and is complete. */
  completed: "completed",
  /** Item has been processed but is incomplete. */
  incomplete: "incomplete",
}

union MessageRole {
  string,
  system: "system",
  user: "user",
  assistant: "assistant",
}

/** Terminal status of a response. */
union ResponseStatus {
  string,
  completed: "completed",
  cancelled: "cancelled",
  failed: "failed",
  incomplete: "incomplete",
  in_progress: "in_progress",
}

/** Base for all non-success response details. */
@discriminator("type")  // or just @discriminator("type") if imported unqualified
@usage(ResponseUsage)
model ResponseStatusDetails {
  // Required discriminator key on the base; keep it as a broad string.
  type: ResponseStatus;
}

/** Details for a cancelled response. */
@usage(ResponseUsage)
model ResponseCancelledDetails extends ResponseStatusDetails {
  // Narrow the discriminator to a literal in each child:
  type: "cancelled";
  reason: "turn_detected" | "client_cancelled" | string;
}

/** Details for an incomplete response. */
@usage(ResponseUsage)
model ResponseIncompleteDetails extends ResponseStatusDetails {
  type: "incomplete";
  reason: "max_output_tokens" | "content_filter" | string;
}

/** Details for a failed response. */
@usage(ResponseUsage)
#suppress "@azure-tools/typespec-azure-core/no-unknown" // The error can be of any type, depending on the failure.
model ResponseFailedDetails extends ResponseStatusDetails {
  type: "failed";
  error: unknown;
}

/** Details of input token usage. */
@usage(ResponseUsage)
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model InputTokenDetails {
  /** Number of cached tokens used in the input. */
  cached_tokens: int32;

  /** Number of text tokens used in the input. */
  text_tokens: int32;

  /** Number of audio tokens used in the input. */
  audio_tokens: int32;

  /** Details of cached token usage. */
  cached_tokens_details: CachedTokenDetails;
}

/** Details of output token usage. */
@usage(ResponseUsage)
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model OutputTokenDetails {
  /** Number of text tokens generated in the output. */
  text_tokens: int32;

  /** Number of audio tokens generated in the output. */
  audio_tokens: int32;
}

/** Details of output token usage. */
@usage(ResponseUsage)
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model CachedTokenDetails {
  /** Number of cached text tokens. */
  text_tokens: int32;

  /** Number of cached audio tokens. */
  audio_tokens: int32;
}

/** Overall usage statistics for a response. */
@usage(ResponseUsage)
#suppress "@azure-tools/typespec-azure-core/casing-style" // Service message format is snake_case to remain close to OpenAI style.
model TokenUsage {
  /** Total number of tokens (input + output). */
  total_tokens: int32;

  /** Number of input tokens. */
  input_tokens: int32;

  /** Number of output tokens. */
  output_tokens: int32;

  /** Detailed breakdown of input tokens. */
  input_token_details: InputTokenDetails;

  /** Detailed breakdown of output tokens. */
  output_token_details: OutputTokenDetails;
}
