{
  "swagger": "2.0",
  "info": {
    "title": "Azure AI Face API",
    "version": "v1.1-preview.1",
    "x-typespec-generated": [
      {
        "emitter": "@azure-tools/typespec-autorest"
      }
    ]
  },
  "schemes": [
    "https"
  ],
  "x-ms-parameterized-host": {
    "hostTemplate": "{endpoint}",
    "useSchemePrefix": false,
    "parameters": [
      {
        "name": "endpoint",
        "in": "path",
        "description": "Supported Cognitive Services endpoints (protocol and hostname, for example:\nhttps://{resource-name}.cognitiveservices.azure.com).",
        "required": true,
        "type": "string"
      }
    ]
  },
  "produces": [
    "application/json"
  ],
  "consumes": [
    "application/json"
  ],
  "security": [
    {
      "KeyAuth": []
    },
    {
      "AADToken": [
        "https://cognitiveservices.azure.com/.default"
      ]
    }
  ],
  "securityDefinitions": {
    "AADToken": {
      "type": "oauth2",
      "description": "The Azure Active Directory OAuth2 Flow",
      "flow": "accessCode",
      "authorizationUrl": "https://api.example.com/oauth2/authorize",
      "scopes": {
        "https://cognitiveservices.azure.com/.default": ""
      },
      "tokenUrl": "https://api.example.com/oauth2/token"
    },
    "KeyAuth": {
      "type": "apiKey",
      "description": "The secret key for your Azure AI Face subscription.",
      "name": "Ocp-Apim-Subscription-Key",
      "in": "header"
    }
  },
  "tags": [],
  "paths": {
    "/face/{apiVersion}/detect": {
      "post": {
        "operationId": "FaceDetectionOperations_Detect",
        "summary": "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.",
        "description": "> [!IMPORTANT]\n> To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. We will also retire the Snapshot API, which allowed biometric data transfer from one Face subscription to another. Existing customers have until 30 June 2023 to use the emotion, gender, age, smile, facial hair, hair, and makeup attributes and the Snapshot API through Face API before they are retired.\n\n* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.\n* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\n* For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces. Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.\n* Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.\n  * 'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\n  * 'recognition_02': Recognition model released in 2019 March.\n  * 'recognition_03': Recognition model released in 2020 May.\n  * 'recognition_04': Recognition model released in 2021 February. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.",
        "consumes": [
          "application/octet-stream"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnFaceId"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnFaceLandmarks"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnFaceAttributes"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.recognitionModel"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnRecognitionModel"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.faceIdTimeToLive"
          },
          {
            "name": "imageContent",
            "in": "body",
            "description": "The input image binary.",
            "required": true,
            "schema": {
              "type": "string",
              "format": "binary"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of face entries ranked by face rectangle size in descending order. An empty response indicates no faces detected.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceDetectionResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "Detect with Image": {
            "$ref": "./examples/Detect.json"
          }
        }
      }
    },
    "/face/{apiVersion}/detectLiveness/singleModal/sessions": {
      "get": {
        "operationId": "LivenessSessionOperations_GetLivenessSessions",
        "summary": "Lists sessions for /detectLiveness/SingleModal.",
        "description": "List sessions from the last sessionId greater than the 'start'.\nThe result should be ordered by sessionId in ascending order.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LivenessSessionItem"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_GetLivenessSessions": {
            "$ref": "./examples/LivenessSessionOperations_GetLivenessSessions.json"
          }
        }
      },
      "post": {
        "operationId": "LivenessSessionOperations_CreateLivenessSession",
        "summary": "Create a new detect liveness session.",
        "description": "A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.\n\nPermissions includes...\n* Ability to call /detectLiveness/singleModal for up to 3 reties.\n* A token lifetime of 10 minutes.\n\n> [!NOTE]\n> Client access can be revoked by deleting the session using the Delete Liveness Session operation. To retrieve a result, use the Get Liveness Session. To audit the individual requests that a client has made to your resource, use the List Liveness Session Audit Entries.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/LivenessSessionCreationContent"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call create a session for a client device and provide an authorization token for use by the client application for a limited purpose and time.",
            "schema": {
              "$ref": "#/definitions/LivenessSessionCreationResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_CreateLivenessSession": {
            "$ref": "./examples/LivenessSessionOperations_CreateLivenessSession.json"
          }
        }
      }
    },
    "/face/{apiVersion}/detectLiveness/singleModal/sessions/{sessionId}": {
      "get": {
        "operationId": "LivenessSessionOperations_GetLivenessSessionResult",
        "description": "Get session result of detectLiveness/singleModal call.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "sessionId",
            "in": "path",
            "description": "Unique ID to reference this session.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/LivenessSession"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_GetLivenessSessionResult": {
            "$ref": "./examples/LivenessSessionOperations_GetLivenessSessionResult.json"
          }
        }
      },
      "delete": {
        "operationId": "LivenessSessionOperations_DeleteLivenessSession",
        "summary": "Delete all session related information for matching the specified session id.",
        "description": "> [!NOTE]\n> Deleting a session deactivates the Session Auth Token by blocking future API calls made with that Auth Token. While this can be used to remove any access for that token, those requests will still count towards overall resource rate limits. It's best to leverage TokenTTL to limit length of tokens in the case that it is misused.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "sessionId",
            "in": "path",
            "description": "Unique ID to reference this session.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_DeleteLivenessSession": {
            "$ref": "./examples/LivenessSessionOperations_DeleteLivenessSession.json"
          }
        }
      }
    },
    "/face/{apiVersion}/detectLiveness/singleModal/sessions/{sessionId}/audit": {
      "get": {
        "operationId": "LivenessSessionOperations_GetLivenessSessionAuditEntries",
        "description": "Gets session requests and response body for the session.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "sessionId",
            "in": "path",
            "description": "Unique ID to reference this session.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LivenessSessionAuditEntry"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_GetLivenessSessionAuditEntries": {
            "$ref": "./examples/LivenessSessionOperations_GetLivenessSessionAuditEntries.json"
          }
        }
      }
    },
    "/face/{apiVersion}/detectLivenessWithVerify/singleModal/sessions": {
      "get": {
        "operationId": "LivenessSessionOperations_GetLivenessWithVerifySessions",
        "summary": "Lists sessions for /detectLivenessWithVerify/SingleModal.",
        "description": "List sessions from the last sessionId greater than the \"start\".\nThe result should be ordered by sessionId in ascending order.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LivenessSessionItem"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_GetLivenessWithVerifySessions": {
            "$ref": "./examples/LivenessSessionOperations_GetLivenessWithVerifySessions.json"
          }
        }
      },
      "post": {
        "operationId": "LivenessSessionOperations_CreateLivenessWithVerifySessionWithVerifyImage",
        "summary": "Create a new liveness session with verify. Provide the verify image during session creation.",
        "description": "A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.\n\nPermissions includes...\n* Ability to call /detectLivenessWithVerify/singleModal for up to 3 reties.\n* A token lifetime of 10 minutes.\n\n> [!NOTE]\n> Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation. To retrieve a result, use the Get Liveness With Verify Session. To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.\n\nRecommended Option: VerifyImage is provided during session creation.",
        "consumes": [
          "multipart/form-data"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/LivenessSessionWithVerifyImageCreationContent.Parameters"
          },
          {
            "$ref": "#/parameters/LivenessSessionWithVerifyImageCreationContent.VerifyImage"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call create a session for a client device and provide an authorization token for use by the client application for a limited purpose and time.",
            "schema": {
              "$ref": "#/definitions/LivenessSessionCreationResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_CreateLivenessWithVerifySessionWithVerifyImage": {
            "$ref": "./examples/LivenessSessionOperations_CreateLivenessWithVerifySessionWithVerifyImage.json"
          }
        }
      }
    },
    "/face/{apiVersion}/detectLivenessWithVerify/singleModal/sessions/{sessionId}": {
      "get": {
        "operationId": "LivenessSessionOperations_GetLivenessWithVerifySessionResult",
        "description": "Get session result of detectLivenessWithVerify/singleModal call.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "sessionId",
            "in": "path",
            "description": "Unique ID to reference this session.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/LivenessWithVerifySession"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_GetLivenessWithVerifySessionResult": {
            "$ref": "./examples/LivenessSessionOperations_GetLivenessWithVerifySessionResult.json"
          }
        }
      },
      "delete": {
        "operationId": "LivenessSessionOperations_DeleteLivenessWithVerifySession",
        "summary": "Delete all session related information for matching the specified session id.",
        "description": "> [!NOTE]\n> Deleting a session deactivates the Session Auth Token by blocking future API calls made with that Auth Token. While this can be used to remove any access for that token, those requests will still count towards overall resource rate limits. It's best to leverage TokenTTL to limit length of tokens in the case that it is misused.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "sessionId",
            "in": "path",
            "description": "Unique ID to reference this session.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_DeleteLivenessWithVerifySession": {
            "$ref": "./examples/LivenessSessionOperations_DeleteLivenessWithVerifySession.json"
          }
        }
      }
    },
    "/face/{apiVersion}/detectLivenessWithVerify/singleModal/sessions/{sessionId}/audit": {
      "get": {
        "operationId": "LivenessSessionOperations_GetLivenessWithVerifySessionAuditEntries",
        "description": "Gets session requests and response body for the session.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "sessionId",
            "in": "path",
            "description": "Unique ID to reference this session.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LivenessSessionAuditEntry"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_GetLivenessWithVerifySessionAuditEntries": {
            "$ref": "./examples/LivenessSessionOperations_GetLivenessWithVerifySessionAuditEntries.json"
          }
        }
      }
    },
    "/face/{apiVersion}/dynamicpersongroups": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetDynamicPersonGroups",
        "summary": "List all existing dynamic person groups by dynamicPersonGroupId along with name and userData.",
        "description": "* Dynamic person groups are stored in alphabetical order of dynamicPersonGroupId.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/DynamicPersonGroup"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetDynamicPersonGroups": {
            "$ref": "./examples/PersonDirectoryOperations_GetDynamicPersonGroups.json"
          }
        }
      }
    },
    "/face/{apiVersion}/dynamicpersongroups/{dynamicPersonGroupId}": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetDynamicPersonGroup",
        "summary": "Retrieve the information of a dynamic person group, including its name and userData.",
        "description": "This API returns dynamic person group information only, use PersonDirectory DynamicPersonGroup - List Persons instead to retrieve person information under the dynamic person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "dynamicPersonGroupId",
            "in": "path",
            "description": "ID of the dynamic person group.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the dynamic person group's information.",
            "schema": {
              "$ref": "#/definitions/DynamicPersonGroup"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetDynamicPersonGroup": {
            "$ref": "./examples/PersonDirectoryOperations_GetDynamicPersonGroup.json"
          }
        }
      },
      "put": {
        "operationId": "PersonDirectoryOperations_CreateDynamicPersonGroup",
        "summary": "Creates a new dynamic person group with specified dynamicPersonGroupId, name, and user-provided userData.",
        "description": "A dynamic person group is a container that references PersonDirectory Person - Create. After creation, use PersonDirectory DynamicPersonGroup - Update to add or remove persons into the dynamic person group. DynamicPersonGroup and UserData will be stored on server until PersonDirectory DynamicPersonGroup - Delete is called. Use Face - Identify with the dynamicPersonGroupId parameter to identify against persons.\nNo image will be stored. Only the person's extracted face feature(s) and userData will be stored on server until PersonDirectory Person - Delete or PersonDirectory Person - Delete Face is called.\n\n'recognitionModel' does not need to be specified with dynamic person groups. Dynamic person groups are references to PersonDirectory Person - Create and therefore work with most all 'recognitionModels'. The faceId's provided during Face - Identify determine the 'recognitionModel' used.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "dynamicPersonGroupId",
            "in": "path",
            "description": "ID of the dynamic person group.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/CreateDynamicPersonGroupContent"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours. The URL provides the status of when PersonDirectory Person - List DynamicPersonGroup References will return the changes made in this request.",
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_CreateDynamicPersonGroup": {
            "$ref": "./examples/PersonDirectoryOperations_CreateDynamicPersonGroup.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonDirectoryOperations_UpdateDynamicPersonGroup",
        "summary": "Update an existing dynamic person group name, userData, add, or remove persons.",
        "description": "The properties keep unchanged if they are not in request body.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "dynamicPersonGroupId",
            "in": "path",
            "description": "ID of the dynamic person group.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UpdateDynamicPersonGroupContent"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours. The URL provides the status of when PersonDirectory Person - List DynamicPersonGroup References will return the changes made in this request.",
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_UpdateDynamicPersonGroup": {
            "$ref": "./examples/PersonDirectoryOperations_UpdateDynamicPersonGroup.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonDirectoryOperations_DeleteDynamicPersonGroup",
        "summary": "Deletes an existing dynamic person group with specified dynamicPersonGroupId.",
        "description": "Deleting this dynamic person group only delete the references to persons data. To delete actual person see PersonDirectory Person - Delete.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "dynamicPersonGroupId",
            "in": "path",
            "description": "ID of the dynamic person group.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours. The URL provides the status of when PersonDirectory Person - List DynamicPersonGroup References will return the changes made in this request.",
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_DeleteDynamicPersonGroup": {
            "$ref": "./examples/PersonDirectoryOperations_DeleteDynamicPersonGroup.json"
          }
        },
        "x-ms-long-running-operation": true
      }
    },
    "/face/{apiVersion}/dynamicpersongroups/{dynamicPersonGroupId}/persons": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetDynamicPersonGroupPersons",
        "summary": "List all persons in the specified dynamic person group.",
        "description": "* Persons are stored in alphabetical order of personId created in PersonDirectory Person - Create.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "dynamicPersonGroupId",
            "in": "path",
            "description": "ID of the dynamic person group.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/ListPersonResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetDynamicPersonGroupPersons": {
            "$ref": "./examples/PersonDirectoryOperations_GetDynamicPersonGroupPersons.json"
          }
        }
      }
    },
    "/face/{apiVersion}/facelists": {
      "get": {
        "operationId": "FaceListOperations_GetFaceLists",
        "description": "List face lists' faceListId, name, userData and recognitionModel.\nTo get face information inside faceList use Get Face List.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceListItem"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_GetFaceLists": {
            "$ref": "./examples/FaceListOperations_GetFaceLists.json"
          }
        }
      }
    },
    "/face/{apiVersion}/facelists/{faceListId}": {
      "get": {
        "operationId": "FaceListOperations_GetFaceList",
        "description": "Retrieve a face list's faceListId, name, userData, recognitionModel and faces in the face list.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "faceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/FaceList"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_GetFaceList": {
            "$ref": "./examples/FaceListOperations_GetFaceList.json"
          }
        }
      },
      "put": {
        "operationId": "FaceListOperations_CreateFaceList",
        "summary": "Create an empty face list with user-specified faceListId, name, an optional userData and recognitionModel.",
        "description": "Up to 64 face lists are allowed in one subscription.\nFace list is a list of faces, up to 1,000 faces, and used by Face - Find Similar.\nAfter creation, user should use FaceList - Add Face to import the faces. No image will be stored. Only the extracted face feature(s) will be stored on server until FaceList - Delete is called.\nFind Similar is used for scenario like finding celebrity-like faces, similar face filtering, or as a light way face identification. But if the actual use is to identify person, please use PersonGroup / LargePersonGroup and Face - Identify.\nPlease consider LargeFaceList when the face number is large. It can support up to 1,000,000 faces.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "faceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/FaceList"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_CreateFaceList": {
            "$ref": "./examples/FaceListOperations_CreateFaceList.json"
          }
        }
      },
      "patch": {
        "operationId": "FaceListOperations_UpdateFaceList",
        "description": "Update information of a face list, including name and userData.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "faceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFieldsUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_UpdateFaceList": {
            "$ref": "./examples/FaceListOperations_UpdateFaceList.json"
          }
        }
      },
      "delete": {
        "operationId": "FaceListOperations_DeleteFaceList",
        "description": "Delete a specified face list.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "faceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_DeleteFaceList": {
            "$ref": "./examples/FaceListOperations_DeleteFaceList.json"
          }
        }
      }
    },
    "/face/{apiVersion}/facelists/{faceListId}/persistedfaces": {
      "post": {
        "operationId": "FaceListOperations_AddFaceListFace",
        "summary": "Add a face to a specified face list, up to 1,000 faces.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until FaceList - Delete Face or FaceList - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.",
        "consumes": [
          "application/octet-stream"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "faceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "imageContent",
            "in": "body",
            "description": "The image to be analyzed",
            "required": true,
            "schema": {
              "type": "string",
              "format": "binary"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_AddFaceListFace": {
            "$ref": "./examples/FaceListOperations_AddFaceListFaceFromStream.json"
          }
        }
      }
    },
    "/face/{apiVersion}/facelists/{faceListId}/persistedfaces/{persistedFaceId}": {
      "delete": {
        "operationId": "FaceListOperations_DeleteFaceListFace",
        "summary": "Delete a face from a face list by specified faceListId and persistedFaceId.",
        "description": "Adding/deleting faces to/from a same face list are processed sequentially and to/from different face lists are in parallel.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "faceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_DeleteFaceListFace": {
            "$ref": "./examples/FaceListOperations_DeleteFaceListFace.json"
          }
        }
      }
    },
    "/face/{apiVersion}/findsimilars": {
      "post": {
        "operationId": "FaceRecognitionOperations_FindSimilar",
        "summary": "Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect.",
        "description": "Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.\n\nFind similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.\n\nThe 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceId": {
                  "type": "string",
                  "description": "faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call."
                },
                "maxNumOfCandidatesReturned": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20."
                },
                "mode": {
                  "$ref": "#/definitions/FindSimilarMatchMode",
                  "description": "Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'."
                },
                "faceIds": {
                  "type": "array",
                  "description": "An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000.",
                  "items": {
                    "type": "string"
                  }
                }
              },
              "required": [
                "faceId",
                "faceIds"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of the most similar faces represented in faceId if the input parameter is faceIds or persistedFaceId if the input parameter is faceListId or largeFaceListId.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceFindSimilarResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_FindSimilar": {
            "$ref": "./examples/FaceRecognitionOperations_FindSimilar.json"
          }
        }
      }
    },
    "/face/{apiVersion}/group": {
      "post": {
        "operationId": "FaceRecognitionOperations_Group",
        "summary": "Divide candidate faces into groups based on face similarity.",
        "description": "* The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result.\n* MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts.\n* Group API needs at least 2 candidate faces and 1000 at most. We suggest to try Face - Verify when you only have 2 candidate faces.\n* The 'recognitionModel' associated with the query faces' faceIds should be the same.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceIds": {
                  "type": "array",
                  "description": "Array of candidate faceId created by Face - Detect. The maximum is 1000 faces.",
                  "items": {
                    "type": "string"
                  }
                }
              },
              "required": [
                "faceIds"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns one or more groups of similar faces (rank by group size) and a messyGroup.",
            "schema": {
              "$ref": "#/definitions/FaceGroupingResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_Group": {
            "$ref": "./examples/FaceRecognitionOperations_Group.json"
          }
        }
      }
    },
    "/face/{apiVersion}/identify": {
      "post": {
        "operationId": "FaceRecognitionOperations_IdentifyFromPersonGroup",
        "summary": "1-to-many identification to find the closest matches of the specific query person face from a person group.",
        "description": "For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.\n\n> [!NOTE]\n> * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.\n> * Each person in the person group/large person group could have more than one face, but no more than 248 faces.\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.\n> * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceIds": {
                  "type": "array",
                  "description": "Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10].",
                  "minItems": 1,
                  "maxItems": 10,
                  "items": {
                    "type": "string"
                  }
                },
                "personGroupId": {
                  "type": "string",
                  "description": "\tpersonGroupId of the target person group, created by PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time."
                },
                "maxNumOfCandidatesReturned": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10).",
                  "minimum": 1,
                  "maximum": 100
                },
                "confidenceThreshold": {
                  "type": "number",
                  "format": "float",
                  "description": "Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates.",
                  "minimum": 0,
                  "maximum": 1
                }
              },
              "required": [
                "faceIds",
                "personGroupId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the identified candidate person(s) for each query face.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceIdentificationResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_IdentifyFromPersonGroup": {
            "$ref": "./examples/FaceRecognitionOperations_IdentifyFromPersonGroup.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largefacelists": {
      "get": {
        "operationId": "FaceListOperations_GetLargeFaceLists",
        "summary": "List large face lists' information of largeFaceListId, name, userData and recognitionModel.",
        "description": "To get face information inside largeFaceList use LargeFaceList Face - Get.\nLarge face lists are stored in alphabetical order of largeFaceListId.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LargeFaceList"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_GetLargeFaceLists": {
            "$ref": "./examples/FaceListOperations_GetLargeFaceLists.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largefacelists/{largeFaceListId}": {
      "get": {
        "operationId": "FaceListOperations_GetLargeFaceList",
        "description": "Retrieve a large face list's largeFaceListId, name, userData and recognitionModel.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/LargeFaceList"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_GetLargeFaceList": {
            "$ref": "./examples/FaceListOperations_GetLargeFaceList.json"
          }
        }
      },
      "put": {
        "operationId": "FaceListOperations_CreateLargeFaceList",
        "summary": "Create an empty large face list with user-specified largeFaceListId, name, an optional userData and recognitionModel.",
        "description": "Large face list is a list of faces, up to 1,000,000 faces, and used by Find Similar.\nAfter creation, user should use Add Large Face List Face to import the faces and Train Large Face List to make it ready for Find Similar. No image will be stored. Only the extracted face feature(s) will be stored on server until Delete Large Face List is called.\nFind Similar is used for scenario like finding celebrity-like faces, similar face filtering, or as a light way face identification. But if the actual use is to identify person, please use Person Group / Large Person Group and Identify.\n\n> [!NOTE]\n> * Free-tier subscription quota: 64 large face lists.\n> * S0-tier subscription quota: 1,000,000 large face lists.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/LargeFaceList"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_CreateLargeFaceList": {
            "$ref": "./examples/FaceListOperations_CreateLargeFaceList.json"
          }
        }
      },
      "patch": {
        "operationId": "FaceListOperations_UpdateLargeFaceList",
        "description": "Update information of a large face list, including name and userData.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFieldsUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_UpdateLargeFaceList": {
            "$ref": "./examples/FaceListOperations_UpdateLargeFaceList.json"
          }
        }
      },
      "delete": {
        "operationId": "FaceListOperations_DeleteLargeFaceList",
        "summary": "Delete a face from a large face list by specified largeFaceListId and persistedFaceId.",
        "description": "Adding/deleting faces to/from a same large face list are processed sequentially and to/from different large face lists are in parallel.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_DeleteLargeFaceList": {
            "$ref": "./examples/FaceListOperations_DeleteLargeFaceList.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largefacelists/{largeFaceListId}/persistedfaces": {
      "get": {
        "operationId": "FaceListOperations_GetLargeFaceListFaces",
        "summary": "List faces' persistedFaceId and userData in a specified large face list.",
        "description": "Faces are stored in alphabetical order of persistedFaceId created in LargeFaceList Face - Add.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LargeFaceListFace"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_GetLargeFaceListFaces": {
            "$ref": "./examples/FaceListOperations_GetLargeFaceListFaces.json"
          }
        }
      },
      "post": {
        "operationId": "FaceListOperations_AddLargeFaceListFace",
        "summary": "Add a face to a specified large face list, up to 1,000,000 faces.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until LargeFaceList - Delete Face or LargeFaceList - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.\n\n> [!NOTE]\n> * Free-tier subscription quota: 1,000 faces per large face list.\n> * S0-tier subscription quota: 1,000,000 faces per large face list.",
        "consumes": [
          "application/octet-stream"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "imageContent",
            "in": "body",
            "description": "The image to be analyzed",
            "required": true,
            "schema": {
              "type": "string",
              "format": "binary"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_AddLargeFaceListFace": {
            "$ref": "./examples/FaceListOperations_AddLargeFaceListFaceFromStream.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largefacelists/{largeFaceListId}/persistedfaces/{persistedFaceId}": {
      "get": {
        "operationId": "FaceListOperations_GetLargeFaceListFace",
        "description": "Retrieve persisted face in large face list by largeFaceListId and persistedFaceId.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/LargeFaceListFace"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_GetLargeFaceListFace": {
            "$ref": "./examples/FaceListOperations_GetLargeFaceListFace.json"
          }
        }
      },
      "patch": {
        "operationId": "FaceListOperations_UpdateLargeFaceListFace",
        "description": "Update a specified face's userData field in a large face list by its persistedFaceId.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/LargeFaceListFaceUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_UpdateLargeFaceListFace": {
            "$ref": "./examples/FaceListOperations_UpdateLargeFaceListFace.json"
          }
        }
      },
      "delete": {
        "operationId": "FaceListOperations_DeleteLargeFaceListFace",
        "description": "Delete a face from a large face list by specified largeFaceListId and persistedFaceId.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_DeleteLargeFaceListFace": {
            "$ref": "./examples/FaceListOperations_DeleteLargeFaceListFace.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largefacelists/{largeFaceListId}/train": {
      "post": {
        "operationId": "FaceListOperations_TrainLargeFaceList",
        "summary": "Submit a large face list training task.",
        "description": "Training is a crucial step that only a trained large face list can be used by Find Similar.\nThe training task is an asynchronous task. Training time depends on the number of face entries in a large face list. It could be in seconds, or up to half an hour for 1,000,000 faces. To check training completion, please use Get Large Face List Training Status.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "202": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_TrainLargeFaceList": {
            "$ref": "./examples/FaceListOperations_TrainLargeFaceList.json"
          }
        },
        "x-ms-long-running-operation": true
      }
    },
    "/face/{apiVersion}/largefacelists/{largeFaceListId}/training": {
      "get": {
        "operationId": "FaceListOperations_GetLargeFaceListTrainingStatus",
        "description": "To check the large face list training status completed or still ongoing. LargeFaceList Training is an asynchronous operation triggered by Train Large Face List.\nTraining time depends on the number of face entries in a large face list. It could be in seconds, or up to half an hour for 1,000,000 faces.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/CollectionTrainingStatus"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_GetLargeFaceListTrainingStatus": {
            "$ref": "./examples/FaceListOperations_GetLargeFaceListTrainingStatus.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups": {
      "get": {
        "operationId": "PersonGroupOperations_GetLargePersonGroups",
        "summary": "List all existing large person groups' largePersonGroupId, name, userData and recognitionModel.",
        "description": "* Large person groups are stored in alphabetical order of largePersonGroupId.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LargePersonGroup"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetLargePersonGroups": {
            "$ref": "./examples/PersonGroupOperations_GetLargePersonGroups.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}": {
      "get": {
        "operationId": "PersonGroupOperations_GetLargePersonGroup",
        "description": "Retrieve the information of a large person group, including its name, userData and recognitionModel. This API returns large person group information only, use LargePersonGroup Person - List instead to retrieve person information under the large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/LargePersonGroup"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetLargePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_GetLargePersonGroup.json"
          }
        }
      },
      "put": {
        "operationId": "PersonGroupOperations_CreateLargePersonGroup",
        "summary": "Create a new large person group with user-specified largePersonGroupId, name, an optional userData and recognitionModel.",
        "description": "A large person group is a container holding the uploaded person data, including the face recognition features. It can hold up to 1,000,000 entities.\nAfter creation, use LargePersonGroup Person - Create to add person into the group, and call LargePersonGroup - Train to get this group ready for Face - Identify.\nNo image will be stored. Only the person's extracted face feature(s) and userData will be stored on server until LargePersonGroup Person - Delete or LargePersonGroup - Delete is called.\n\n'recognitionModel' should be specified to associate with this large person group. The default value for 'recognitionModel' is 'recognition_01', if the latest model needed, please explicitly specify the model you need in this parameter. New faces that are added to an existing large person group will use the recognition model that's already associated with the collection. Existing face feature(s) in a large person group can't be updated to features extracted by another version of recognition model.\n\n> [!NOTE]\n> * Free-tier subscription quota: 1,000 large person groups.\n> * S0-tier subscription quota: 1,000,000 large person groups.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/LargePersonGroup"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_CreateLargePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_CreateLargePersonGroup.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonGroupOperations_UpdateLargePersonGroup",
        "description": "Update an existing large person group's name and userData. The properties keep unchanged if they are not in request body.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFieldsUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_UpdateLargePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_UpdateLargePersonGroup.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonGroupOperations_DeleteLargePersonGroup",
        "description": "Delete an existing large person group with specified personGroupId. Persisted data in this large person group will be deleted.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_DeleteLargePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_DeleteLargePersonGroup.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}/persons": {
      "get": {
        "operationId": "PersonGroupOperations_GetLargePersonGroupPersons",
        "summary": "List all persons' information in the specified large person group, including personId, name, userData and persistedFaceIds of registered person faces.",
        "description": "* Persons are stored in alphabetical order of personId created in LargePersonGroup Person - Create.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/LargePersonGroupPerson"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetLargePersonGroupPersons": {
            "$ref": "./examples/PersonGroupOperations_GetLargePersonGroupPersons.json"
          }
        }
      },
      "post": {
        "operationId": "PersonGroupOperations_CreateLargePersonGroupPerson",
        "summary": "Create a new person in a specified large person group. To add face to this person, please call LargePersonGroup PersonFace - Add.",
        "description": "> [!NOTE]\n> * Free-tier subscription quota:\n>   * 1,000 persons in all large person groups.\n> * S0-tier subscription quota:\n>   * 1,000,000 persons per large person group.\n>   * 1,000,000 large person groups.\n>   * 1,000,000,000 persons in all large person groups. ",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFields"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/CreatePersonResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_CreateLargePersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_CreateLargePersonGroupPerson.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}/persons/{personId}": {
      "get": {
        "operationId": "PersonGroupOperations_GetLargePersonGroupPerson",
        "description": "Retrieve a person's name and userData, and the persisted faceIds representing the registered person face feature(s).",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/LargePersonGroupPerson"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetLargePersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_GetLargePersonGroupPerson.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonGroupOperations_UpdateLargePersonGroupPerson",
        "description": "Update name or userData of a person.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFieldsUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_UpdateLargePersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_UpdateLargePersonGroupPerson.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonGroupOperations_DeleteLargePersonGroupPerson",
        "description": "Delete an existing person from a large person group. The persistedFaceId, userData, person name and face feature(s) in the person entry will all be deleted.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_DeleteLargePersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_DeleteLargePersonGroupPerson.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}/persons/{personId}/persistedfaces": {
      "post": {
        "operationId": "PersonGroupOperations_AddLargePersonGroupPersonFace",
        "summary": "Add a face to a person into a large person group for face identification or verification.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until LargePersonGroup PersonFace - Delete, LargePersonGroup Person - Delete or LargePersonGroup - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.",
        "consumes": [
          "application/octet-stream"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "imageContent",
            "in": "body",
            "description": "The image to be analyzed",
            "required": true,
            "schema": {
              "type": "string",
              "format": "binary"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_AddLargePersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_AddLargePersonGroupPersonFaceFromStream.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}/persons/{personId}/persistedfaces/{persistedFaceId}": {
      "get": {
        "operationId": "PersonGroupOperations_GetLargePersonGroupPersonFace",
        "description": "Retrieve person face information. The persisted person face is specified by its largePersonGroupId, personId and persistedFaceId.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/LargePersonGroupPersonFace"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetLargePersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_GetLargePersonGroupPersonFace.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonGroupOperations_UpdateLargePersonGroupPersonFace",
        "description": "Update a person persisted face's userData field.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/LargePersonGroupPersonFaceUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_UpdateLargePersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_UpdateLargePersonGroupPersonFace.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonGroupOperations_DeleteLargePersonGroupPersonFace",
        "summary": "Delete a face from a person in a large person group by specified largePersonGroupId, personId and persistedFaceId.",
        "description": "Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_DeleteLargePersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_DeleteLargePersonGroupPersonFace.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}/train": {
      "post": {
        "operationId": "PersonGroupOperations_TrainLargePersonGroup",
        "summary": "Submit a large person group training task. Training is a crucial step that only a trained large person group can be used by Face - Identify.",
        "description": "The training task is an asynchronous task. Training time depends on the number of person entries, and their faces in a large person group. It could be in several seconds, or up to half a hour for 1,000,000 persons. To check training completion, please use LargePersonGroup - Get Training Status.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "202": {
            "description": "The request has been accepted for processing, but processing has not yet completed."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_TrainLargePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_TrainLargePersonGroup.json"
          }
        },
        "x-ms-long-running-operation": true
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}/training": {
      "get": {
        "operationId": "PersonGroupOperations_GetLargePersonGroupTrainingStatus",
        "summary": "To check large person group training status completed or still ongoing. LargePersonGroup Training is an asynchronous operation triggered by LargePersonGroup - Train API.",
        "description": "Training time depends on the number of person entries, and their faces in a large person group. It could be in seconds, or up to half an hour for 1,000,000 persons.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/CollectionTrainingStatus"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetLargePersonGroupTrainingStatus": {
            "$ref": "./examples/PersonGroupOperations_GetLargePersonGroupTrainingStatus.json"
          }
        }
      }
    },
    "/face/{apiVersion}/operations/{operationId}": {
      "get": {
        "operationId": "GetFaceOperationStatus",
        "description": "Get status of a long running operation.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "operationId",
            "in": "path",
            "description": "Operation ID of the operation.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/FaceOperationStatus"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "GetFaceOperationStatus": {
            "$ref": "./examples/GetFaceOperationStatus.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups": {
      "get": {
        "operationId": "PersonGroupOperations_GetPersonGroups",
        "summary": "List person groups' personGroupId, name, userData and recognitionModel.",
        "description": "* Person groups are stored in alphabetical order of personGroupId.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/PersonGroup"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetPersonGroups": {
            "$ref": "./examples/PersonGroupOperations_GetPersonGroups.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}": {
      "get": {
        "operationId": "PersonGroupOperations_GetPersonGroup",
        "description": "Retrieve person group name, userData and recognitionModel. To get person information under this personGroup, use PersonGroup Person - List.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ReturnRecognitionModelOptions"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/PersonGroup"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetPersonGroup": {
            "$ref": "./examples/PersonGroupOperations_GetPersonGroup.json"
          }
        }
      },
      "put": {
        "operationId": "PersonGroupOperations_CreatePersonGroup",
        "summary": "Create a new person group with specified personGroupId, name, user-provided userData and recognitionModel.",
        "description": "A person group is a container holding the uploaded person data, including face recognition features.\nAfter creation, use PersonGroup Person - Create to add persons into the group, and then call PersonGroup - Train to get this group ready for Face - Identify.\nNo image will be stored. Only the person's extracted face feature(s) and userData will be stored on server until PersonGroup Person - Delete or PersonGroup - Delete is called.\n\n'recognitionModel' should be specified to associate with this person group. The default value for 'recognitionModel' is 'recognition_01', if the latest model needed, please explicitly specify the model you need in this parameter. New faces that are added to an existing person group will use the recognition model that's already associated with the collection. Existing face feature(s) in a person group can't be updated to features extracted by another version of recognition model.\n\n> [!NOTE]\n> * Free-tier subscription quota: 1,000 person groups. Each holds up to 1,000 persons.\n> * S0-tier subscription quota: 1,000,000 person groups. Each holds up to 10,000 persons.\n> * to handle larger scale face identification problem, please consider using LargePersonGroup.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/PersonGroup"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_CreatePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_CreatePersonGroup.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonGroupOperations_UpdatePersonGroup",
        "description": "Update an existing person group's name and userData. The properties keep unchanged if they are not in request body.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFieldsUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_UpdatePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_UpdatePersonGroup.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonGroupOperations_DeletePersonGroup",
        "description": "Delete an existing person group with specified personGroupId. Persisted data in this person group will be deleted.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_DeletePersonGroup": {
            "$ref": "./examples/PersonGroupOperations_DeletePersonGroup.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}/persons": {
      "get": {
        "operationId": "PersonGroupOperations_GetPersonGroupPersons",
        "summary": "List all persons' information in the specified person group, including personId, name, userData and persistedFaceIds of registered person faces.",
        "description": "Persons are stored in alphabetical order of personId created in PersonGroup Person - Create.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/PersonGroupPerson"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetPersonGroupPersons": {
            "$ref": "./examples/PersonGroupOperations_GetPersonGroupPersons.json"
          }
        }
      },
      "post": {
        "operationId": "PersonGroupOperations_CreatePersonGroupPerson",
        "summary": "Create a new person in a specified person group. To add face to this person, please call PersonGroup PersonFace - Add.",
        "description": "> [!NOTE]\n> * Free-tier subscription quota:\n>   * 1,000 persons in all person groups.\n> * S0-tier subscription quota:\n>   * 10,000 persons per person group.\n>   * 1,000,000 person groups.\n>   * 100,000,000 persons in all person groups.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFields"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/CreatePersonResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_CreatePersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_CreatePersonGroupPerson.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}/persons/{personId}": {
      "get": {
        "operationId": "PersonGroupOperations_GetPersonGroupPerson",
        "description": "Retrieve a person's name and userData, and the persisted faceIds representing the registered person face feature(s).",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/PersonGroupPerson"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetPersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_GetPersonGroupPerson.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonGroupOperations_UpdatePersonGroupPerson",
        "description": "Update name or userData of a person.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFieldsUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_UpdatePersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_UpdatePersonGroupPerson.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonGroupOperations_DeletePersonGroupPerson",
        "description": "Delete an existing person from a person group. The persistedFaceId, userData, person name and face feature(s) in the person entry will all be deleted.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_DeletePersonGroupPerson": {
            "$ref": "./examples/PersonGroupOperations_DeletePersonGroupPerson.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}/persons/{personId}/persistedfaces": {
      "post": {
        "operationId": "PersonGroupOperations_AddPersonGroupPersonFace",
        "summary": "Add a face to a person into a person group for face identification or verification.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.",
        "consumes": [
          "application/octet-stream"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "imageContent",
            "in": "body",
            "description": "The image to be analyzed",
            "required": true,
            "schema": {
              "type": "string",
              "format": "binary"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_AddPersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_AddPersonGroupPersonFaceFromStream.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}/persons/{personId}/persistedfaces/{persistedFaceId}": {
      "get": {
        "operationId": "PersonGroupOperations_GetPersonGroupPersonFace",
        "description": "Retrieve person face information. The persisted person face is specified by its personGroupId, personId and persistedFaceId.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/PersonGroupPersonFace"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetPersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_GetPersonGroupPersonFace.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonGroupOperations_UpdatePersonGroupPersonFace",
        "description": "Update a person persisted face's userData field.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/PersonGroupPersonFaceUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_UpdatePersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_UpdatePersonGroupPersonFace.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonGroupOperations_DeletePersonGroupPersonFace",
        "summary": "Delete a face from a person in a person group by specified personGroupId, personId and persistedFaceId.",
        "description": "Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_DeletePersonGroupPersonFace": {
            "$ref": "./examples/PersonGroupOperations_DeletePersonGroupPersonFace.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}/train": {
      "post": {
        "operationId": "PersonGroupOperations_TrainPersonGroup",
        "summary": "Submit a person group training task. Training is a crucial step that only a trained person group can be used by Face - Identify.",
        "description": "The training task is an asynchronous task. Training time depends on the number of person entries, and their faces in a person group. It could be several seconds to minutes. To check training status, please use PersonGroup - Get Training Status.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "202": {
            "description": "The request has been accepted for processing, but processing has not yet completed."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_TrainPersonGroup": {
            "$ref": "./examples/PersonGroupOperations_TrainPersonGroup.json"
          }
        },
        "x-ms-long-running-operation": true
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}/training": {
      "get": {
        "operationId": "PersonGroupOperations_GetPersonGroupTrainingStatus",
        "description": "To check person group training status completed or still ongoing. PersonGroup Training is an asynchronous operation triggered by PersonGroup - Train API.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/CollectionTrainingStatus"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_GetPersonGroupTrainingStatus": {
            "$ref": "./examples/PersonGroupOperations_GetPersonGroupTrainingStatus.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persons": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetPersons",
        "summary": "List all persons' information in person directory, including personId, name, and userData.",
        "description": "* Persons are stored in alphabetical order of personId created in PersonDirectory Person - Create.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/PersonDirectoryPerson"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetPersons": {
            "$ref": "./examples/PersonDirectoryOperations_GetPersons.json"
          }
        }
      },
      "post": {
        "operationId": "PersonDirectoryOperations_CreatePerson",
        "description": "Creates a new person in a person directory. To add face to this person, please call PersonDirectory Person - Add Face.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/PersonDirectoryPerson"
            }
          }
        ],
        "responses": {
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours.",
            "schema": {
              "$ref": "#/definitions/CreatePersonResult"
            },
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              },
              "Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of PersonDirectoryPerson"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_CreatePerson": {
            "$ref": "./examples/PersonDirectoryOperations_CreatePerson.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persons/{personId}": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetPerson",
        "description": "Retrieve a person's name and userData from person directory.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/PersonDirectoryPerson"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetPerson": {
            "$ref": "./examples/PersonDirectoryOperations_GetPerson.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonDirectoryOperations_UpdatePerson",
        "description": "Update name or userData of a person.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/UserDefinedFieldsUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_UpdatePerson": {
            "$ref": "./examples/PersonDirectoryOperations_UpdatePerson.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonDirectoryOperations_DeletePerson",
        "description": "Delete an existing person from person directory. The persistedFaceId(s), userData, person name and face feature(s) in the person entry will all be deleted.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours.",
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_DeletePerson": {
            "$ref": "./examples/PersonDirectoryOperations_DeletePerson.json"
          }
        },
        "x-ms-long-running-operation": true
      }
    },
    "/face/{apiVersion}/persons/{personId}/dynamicPersonGroupReferences": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetDynamicPersonGroupReferences",
        "summary": "List all dynamic person groups a person has been referenced by in person directory.",
        "description": "* Dynamic person groups are stored in alphabetical order of dynamic person group id created in PersonDirectory DynamicPersonGroup - Create.\n* \"start\" parameter (string, optional) is a id value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry's personId of the current call.\n\n> [!TIP]\n> For example, total 5 items with their id: \"itemId1\", ..., \"itemId5\".\n> * \"start=&top=\" will return all 5 items.\n> * \"start=&top=2\" will return \"itemId1\", \"itemId2\".\n> * \"start=itemId2&top=3\" will return \"itemId3\", \"itemId4\", \"itemId5\".",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.start"
          },
          {
            "$ref": "#/parameters/ListRequestOptions.top"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/ListGroupReferenceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetDynamicPersonGroupReferences": {
            "$ref": "./examples/PersonDirectoryOperations_GetDynamicPersonGroupReferences.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persons/{personId}/recognitionModels/{recognitionModel}/persistedfaces": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetPersonFaces",
        "description": "Retrieve a person's persistedFaceIds representing the registered person face feature(s).",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "recognitionModel",
            "in": "path",
            "description": "The 'recognitionModel' associated with faces.",
            "required": true,
            "type": "string",
            "enum": [
              "recognition_01",
              "recognition_02",
              "recognition_03",
              "recognition_04"
            ],
            "x-ms-enum": {
              "name": "RecognitionModel",
              "modelAsString": true,
              "values": [
                {
                  "name": "recognition_01",
                  "value": "recognition_01",
                  "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
                },
                {
                  "name": "recognition_02",
                  "value": "recognition_02",
                  "description": "Recognition model released in 2019 March."
                },
                {
                  "name": "recognition_03",
                  "value": "recognition_03",
                  "description": "Recognition model released in 2020 May."
                },
                {
                  "name": "recognition_04",
                  "value": "recognition_04",
                  "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
                }
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/ListFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetPersonFaces": {
            "$ref": "./examples/PersonDirectoryOperations_GetPersonFaces.json"
          }
        }
      },
      "post": {
        "operationId": "PersonDirectoryOperations_AddPersonFace",
        "summary": "Add a face to a person (see PersonDirectory Person - Create) for face identification or verification.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonDirectory Person - Delete Face or PersonDirectory Person - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.\n* Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\n* This is a long running operation. Use Response Header \"Operation-Location\" to determine when the AddFace operation has successfully propagated for future requests to Face - Identify. For further information about Operation-Locations see Operations - Get Status.",
        "consumes": [
          "application/octet-stream"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "recognitionModel",
            "in": "path",
            "description": "The 'recognitionModel' associated with faces.",
            "required": true,
            "type": "string",
            "enum": [
              "recognition_01",
              "recognition_02",
              "recognition_03",
              "recognition_04"
            ],
            "x-ms-enum": {
              "name": "RecognitionModel",
              "modelAsString": true,
              "values": [
                {
                  "name": "recognition_01",
                  "value": "recognition_01",
                  "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
                },
                {
                  "name": "recognition_02",
                  "value": "recognition_02",
                  "description": "Recognition model released in 2019 March."
                },
                {
                  "name": "recognition_03",
                  "value": "recognition_03",
                  "description": "Recognition model released in 2020 May."
                },
                {
                  "name": "recognition_04",
                  "value": "recognition_04",
                  "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
                }
              ]
            }
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "imageContent",
            "in": "body",
            "description": "The image to be analyzed",
            "required": true,
            "schema": {
              "type": "string",
              "format": "binary"
            }
          }
        ],
        "responses": {
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            },
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              },
              "Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of PersonDirectoryPerson"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_AddPersonFace": {
            "$ref": "./examples/PersonDirectoryOperations_AddPersonFaceFromStream.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persons/{personId}/recognitionModels/{recognitionModel}/persistedfaces/{persistedFaceId}": {
      "get": {
        "operationId": "PersonDirectoryOperations_GetPersonFace",
        "description": "Retrieve person face information. The persisted person face is specified by its personId. recognitionModel, and persistedFaceId.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "recognitionModel",
            "in": "path",
            "description": "The 'recognitionModel' associated with faces.",
            "required": true,
            "type": "string",
            "enum": [
              "recognition_01",
              "recognition_02",
              "recognition_03",
              "recognition_04"
            ],
            "x-ms-enum": {
              "name": "RecognitionModel",
              "modelAsString": true,
              "values": [
                {
                  "name": "recognition_01",
                  "value": "recognition_01",
                  "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
                },
                {
                  "name": "recognition_02",
                  "value": "recognition_02",
                  "description": "Recognition model released in 2019 March."
                },
                {
                  "name": "recognition_03",
                  "value": "recognition_03",
                  "description": "Recognition model released in 2020 May."
                },
                {
                  "name": "recognition_04",
                  "value": "recognition_04",
                  "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
                }
              ]
            }
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/PersonDirectoryFace"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_GetPersonFace": {
            "$ref": "./examples/PersonDirectoryOperations_GetPersonFace.json"
          }
        }
      },
      "patch": {
        "operationId": "PersonDirectoryOperations_UpdatePersonFace",
        "description": "Update a person persisted face's userData field.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "recognitionModel",
            "in": "path",
            "description": "The 'recognitionModel' associated with faces.",
            "required": true,
            "type": "string",
            "enum": [
              "recognition_01",
              "recognition_02",
              "recognition_03",
              "recognition_04"
            ],
            "x-ms-enum": {
              "name": "RecognitionModel",
              "modelAsString": true,
              "values": [
                {
                  "name": "recognition_01",
                  "value": "recognition_01",
                  "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
                },
                {
                  "name": "recognition_02",
                  "value": "recognition_02",
                  "description": "Recognition model released in 2019 March."
                },
                {
                  "name": "recognition_03",
                  "value": "recognition_03",
                  "description": "Recognition model released in 2020 May."
                },
                {
                  "name": "recognition_04",
                  "value": "recognition_04",
                  "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
                }
              ]
            }
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          },
          {
            "name": "resource",
            "in": "body",
            "description": "The resource instance.",
            "required": true,
            "schema": {
              "$ref": "#/definitions/PersonDirectoryFaceUpdate"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded."
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_UpdatePersonFace": {
            "$ref": "./examples/PersonDirectoryOperations_UpdatePersonFace.json"
          }
        }
      },
      "delete": {
        "operationId": "PersonDirectoryOperations_DeletePersonFace",
        "summary": "Delete a face from a person in person directory by specified personId and persistedFaceId.",
        "description": "Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "recognitionModel",
            "in": "path",
            "description": "The 'recognitionModel' associated with faces.",
            "required": true,
            "type": "string",
            "enum": [
              "recognition_01",
              "recognition_02",
              "recognition_03",
              "recognition_04"
            ],
            "x-ms-enum": {
              "name": "RecognitionModel",
              "modelAsString": true,
              "values": [
                {
                  "name": "recognition_01",
                  "value": "recognition_01",
                  "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
                },
                {
                  "name": "recognition_02",
                  "value": "recognition_02",
                  "description": "Recognition model released in 2019 March."
                },
                {
                  "name": "recognition_03",
                  "value": "recognition_03",
                  "description": "Recognition model released in 2020 May."
                },
                {
                  "name": "recognition_04",
                  "value": "recognition_04",
                  "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
                }
              ]
            }
          },
          {
            "name": "persistedFaceId",
            "in": "path",
            "description": "Face ID of the face.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours.",
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_DeletePersonFace": {
            "$ref": "./examples/PersonDirectoryOperations_DeletePersonFace.json"
          }
        },
        "x-ms-long-running-operation": true
      }
    },
    "/face/{apiVersion}/verify": {
      "post": {
        "operationId": "FaceRecognitionOperations_VerifyFaceToFace",
        "summary": "Verify whether two faces belong to a same person.",
        "description": "> [!NOTE]\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * For the scenarios that are sensitive to accuracy please make your own judgment.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceId1": {
                  "type": "string",
                  "description": "faceId of one face, comes from Face - Detect."
                },
                "faceId2": {
                  "type": "string",
                  "description": "faceId of another face, comes from Face - Detect."
                }
              },
              "required": [
                "faceId1",
                "faceId2"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the verification result.",
            "schema": {
              "$ref": "#/definitions/FaceVerificationResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_VerifyFaceToFace": {
            "$ref": "./examples/FaceRecognitionOperations_VerifyFaceToFace.json"
          }
        }
      }
    }
  },
  "x-ms-paths": {
    "/face/{apiVersion}/detect?_overload=detectFromUrl": {
      "post": {
        "operationId": "FaceDetectionOperations_DetectFromUrl",
        "summary": "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.",
        "description": "> [!IMPORTANT]\n> To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. We will also retire the Snapshot API, which allowed biometric data transfer from one Face subscription to another. Existing customers have until 30 June 2023 to use the emotion, gender, age, smile, facial hair, hair, and makeup attributes and the Snapshot API through Face API before they are retired.\n\n* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.\n* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\n* For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces. Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.\n* Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.\n  * 'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\n  * 'recognition_02': Recognition model released in 2019 March.\n  * 'recognition_03': Recognition model released in 2020 May.\n  * 'recognition_04': Recognition model released in 2021 February. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnFaceId"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnFaceLandmarks"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnFaceAttributes"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.recognitionModel"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.returnRecognitionModel"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/FaceDetectionOptions.faceIdTimeToLive"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "url": {
                  "type": "string",
                  "format": "uri",
                  "description": "URL of input image."
                }
              },
              "required": [
                "url"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of face entries ranked by face rectangle size in descending order. An empty response indicates no faces detected.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceDetectionResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "Detect with Image URL": {
            "$ref": "./examples/DetectFromUrl.json"
          }
        }
      }
    },
    "/face/{apiVersion}/detectLivenessWithVerify/singleModal/sessions?_overload=createLivenessWithVerifySession": {
      "post": {
        "operationId": "LivenessSessionOperations_CreateLivenessWithVerifySession",
        "summary": "Create a new liveness session with verify. Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.",
        "description": "A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.\n\nPermissions includes...\n* Ability to call /detectLivenessWithVerify/singleModal for up to 3 reties.\n* A token lifetime of 10 minutes.\n\n> [!NOTE]\n> Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation. To retrieve a result, use the Get Liveness With Verify Session. To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.\n\nAlternative Option: Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.\n> [!NOTE]\n> Extra measures should be taken to validate that the client is sending the expected VerifyImage.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/LivenessSessionCreationContent"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call create a session for a client device and provide an authorization token for use by the client application for a limited purpose and time.",
            "schema": {
              "$ref": "#/definitions/LivenessSessionCreationResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "LivenessSessionOperations_CreateLivenessWithVerifySession": {
            "$ref": "./examples/LivenessSessionOperations_CreateLivenessWithVerifySession.json"
          }
        }
      }
    },
    "/face/{apiVersion}/facelists/{faceListId}/persistedfaces?_overload=addFaceListFaceFromUrl": {
      "post": {
        "operationId": "FaceListOperations_AddFaceListFaceFromUrl",
        "summary": "Add a face to a specified face list, up to 1,000 faces.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until FaceList - Delete Face or FaceList - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "faceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "url": {
                  "type": "string",
                  "format": "uri",
                  "description": "URL of input image."
                }
              },
              "required": [
                "url"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_AddFaceListFaceFromUrl": {
            "$ref": "./examples/FaceListOperations_AddFaceListFaceFromUrl.json"
          }
        }
      }
    },
    "/face/{apiVersion}/findsimilars?_overload=findSimilarFromFaceList": {
      "post": {
        "operationId": "FaceRecognitionOperations_FindSimilarFromFaceList",
        "summary": "Given query face's faceId, to search the similar-looking faces from a face list. A 'faceListId' is created by Create Face List.",
        "description": "Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.\n\nFind similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.\n\nThe 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceId": {
                  "type": "string",
                  "description": "faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call."
                },
                "maxNumOfCandidatesReturned": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20."
                },
                "mode": {
                  "$ref": "#/definitions/FindSimilarMatchMode",
                  "description": "Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'."
                },
                "faceListId": {
                  "type": "string",
                  "description": "An existing user-specified unique candidate face list, created in FaceList - Create. Face list contains a set of persistedFaceIds which are persisted and will never expire."
                }
              },
              "required": [
                "faceId",
                "faceListId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of the most similar faces represented in faceId if the input parameter is faceIds or persistedFaceId if the input parameter is faceListId or largeFaceListId.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceFindSimilarResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_FindSimilarFromFaceList": {
            "$ref": "./examples/FaceRecognitionOperations_FindSimilarFromFaceList.json"
          }
        }
      }
    },
    "/face/{apiVersion}/findsimilars?_overload=findSimilarFromLargeFaceList": {
      "post": {
        "operationId": "FaceRecognitionOperations_FindSimilarFromLargeFaceList",
        "summary": "Given query face's faceId, to search the similar-looking faces from a large face list. A 'largeFaceListId' is created by Create large Face List.",
        "description": "Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.\n\nFind similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.\n\nThe 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceId": {
                  "type": "string",
                  "description": "faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call."
                },
                "maxNumOfCandidatesReturned": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20."
                },
                "mode": {
                  "$ref": "#/definitions/FindSimilarMatchMode",
                  "description": "Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'."
                },
                "largeFaceListId": {
                  "type": "string",
                  "description": "An existing user-specified unique candidate large face list, created in LargeFaceList - Create. Large face list contains a set of persistedFaceIds which are persisted and will never expire."
                }
              },
              "required": [
                "faceId",
                "largeFaceListId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of the most similar faces represented in faceId if the input parameter is faceIds or persistedFaceId if the input parameter is faceListId or largeFaceListId.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceFindSimilarResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_FindSimilarFromLargeFaceList": {
            "$ref": "./examples/FaceRecognitionOperations_FindSimilarFromLargeFaceList.json"
          }
        }
      }
    },
    "/face/{apiVersion}/identify?_overload=identifyFromDynamicPersonGroup": {
      "post": {
        "operationId": "FaceRecognitionOperations_IdentifyFromDynamicPersonGroup",
        "summary": "1-to-many identification to find the closest matches of the specific query person face from a dynamic person group.",
        "description": "For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.\n\n> [!NOTE]\n> * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.\n> * Each person in the person group/large person group could have more than one face, but no more than 248 faces.\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.\n> * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceIds": {
                  "type": "array",
                  "description": "Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10].",
                  "minItems": 1,
                  "maxItems": 10,
                  "items": {
                    "type": "string"
                  }
                },
                "dynamicPersonGroupId": {
                  "type": "string",
                  "description": "DynamicPersonGroupId of the target PersonDirectory DynamicPersonGroup to match against."
                },
                "maxNumOfCandidatesReturned": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10).",
                  "minimum": 1,
                  "maximum": 100
                },
                "confidenceThreshold": {
                  "type": "number",
                  "format": "float",
                  "description": "Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates.",
                  "minimum": 0,
                  "maximum": 1
                }
              },
              "required": [
                "faceIds",
                "dynamicPersonGroupId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the identified candidate person(s) for each query face.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceIdentificationResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_IdentifyFromDynamicPersonGroup": {
            "$ref": "./examples/FaceRecognitionOperations_IdentifyFromDynamicPersonGroup.json"
          }
        }
      }
    },
    "/face/{apiVersion}/identify?_overload=identifyFromLargePersonGroup": {
      "post": {
        "operationId": "FaceRecognitionOperations_IdentifyFromLargePersonGroup",
        "summary": "1-to-many identification to find the closest matches of the specific query person face from a large person group.",
        "description": "For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.\n\n> [!NOTE]\n> * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.\n> * Each person in the person group/large person group could have more than one face, but no more than 248 faces.\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.\n> * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceIds": {
                  "type": "array",
                  "description": "Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10].",
                  "minItems": 1,
                  "maxItems": 10,
                  "items": {
                    "type": "string"
                  }
                },
                "largePersonGroupId": {
                  "type": "string",
                  "description": "largePersonGroupId of the target large person group, created by LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time."
                },
                "maxNumOfCandidatesReturned": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10).",
                  "minimum": 1,
                  "maximum": 100
                },
                "confidenceThreshold": {
                  "type": "number",
                  "format": "float",
                  "description": "Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates.",
                  "minimum": 0,
                  "maximum": 1
                }
              },
              "required": [
                "faceIds",
                "largePersonGroupId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the identified candidate person(s) for each query face.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceIdentificationResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_IdentifyFromLargePersonGroup": {
            "$ref": "./examples/FaceRecognitionOperations_IdentifyFromLargePersonGroup.json"
          }
        }
      }
    },
    "/face/{apiVersion}/identify?_overload=identifyFromPersonDirectory": {
      "post": {
        "operationId": "FaceRecognitionOperations_IdentifyFromPersonDirectory",
        "summary": "1-to-many identification to find the closest matches of the specific query person face from a person directory personIds array.",
        "description": "For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.\n\n> [!NOTE]\n> * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.\n> * Each person in the person group/large person group could have more than one face, but no more than 248 faces.\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.\n> * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceIds": {
                  "type": "array",
                  "description": "Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10].",
                  "minItems": 1,
                  "maxItems": 10,
                  "items": {
                    "type": "string"
                  }
                },
                "personIds": {
                  "type": "array",
                  "description": "Array of personIds created in PersonDirectory - PersonCreate. The valid number of personIds is between [1,30].",
                  "minItems": 1,
                  "maxItems": 30,
                  "items": {
                    "type": "string"
                  }
                },
                "maxNumOfCandidatesReturned": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10).",
                  "minimum": 1,
                  "maximum": 100
                },
                "confidenceThreshold": {
                  "type": "number",
                  "format": "float",
                  "description": "Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates.",
                  "minimum": 0,
                  "maximum": 1
                }
              },
              "required": [
                "faceIds",
                "personIds"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the identified candidate person(s) for each query face.",
            "schema": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/FaceIdentificationResult"
              },
              "x-ms-identifiers": []
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_IdentifyFromPersonDirectory": {
            "$ref": "./examples/FaceRecognitionOperations_IdentifyFromPersonDirectory.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largefacelists/{largeFaceListId}/persistedfaces?_overload=addLargeFaceListFaceFromUrl": {
      "post": {
        "operationId": "FaceListOperations_AddLargeFaceListFaceFromUrl",
        "summary": "Add a face to a specified large face list, up to 1,000,000 faces.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until LargeFaceList - Delete Face or LargeFaceList - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.\n\n> [!NOTE]\n> * Free-tier subscription quota: 1,000 faces per large face list.\n> * S0-tier subscription quota: 1,000,000 faces per large face list.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largeFaceListId",
            "in": "path",
            "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "url": {
                  "type": "string",
                  "format": "uri",
                  "description": "URL of input image."
                }
              },
              "required": [
                "url"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceListOperations_AddLargeFaceListFaceFromUrl": {
            "$ref": "./examples/FaceListOperations_AddLargeFaceListFaceFromUrl.json"
          }
        }
      }
    },
    "/face/{apiVersion}/largepersongroups/{largePersonGroupId}/persons/{personId}/persistedfaces?_overload=addLargePersonGroupPersonFaceFromUrl": {
      "post": {
        "operationId": "PersonGroupOperations_AddLargePersonGroupPersonFaceFromUrl",
        "summary": "Add a face to a person into a large person group for face identification or verification.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until LargePersonGroup PersonFace - Delete, LargePersonGroup Person - Delete or LargePersonGroup - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "largePersonGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "url": {
                  "type": "string",
                  "format": "uri",
                  "description": "URL of input image."
                }
              },
              "required": [
                "url"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_AddLargePersonGroupPersonFaceFromUrl": {
            "$ref": "./examples/PersonGroupOperations_AddLargePersonGroupPersonFaceFromUrl.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persongroups/{personGroupId}/persons/{personId}/persistedfaces?_overload=addPersonGroupPersonFaceFromUrl": {
      "post": {
        "operationId": "PersonGroupOperations_AddPersonGroupPersonFaceFromUrl",
        "summary": "Add a face to a person into a person group for face identification or verification.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personGroupId",
            "in": "path",
            "description": "ID of the container.",
            "required": true,
            "type": "string"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "url": {
                  "type": "string",
                  "format": "uri",
                  "description": "URL of input image."
                }
              },
              "required": [
                "url"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonGroupOperations_AddPersonGroupPersonFaceFromUrl": {
            "$ref": "./examples/PersonGroupOperations_AddPersonGroupPersonFaceFromUrl.json"
          }
        }
      }
    },
    "/face/{apiVersion}/persons/{personId}/recognitionModels/{recognitionModel}/persistedfaces?_overload=addPersonFaceFromUrl": {
      "post": {
        "operationId": "PersonDirectoryOperations_AddPersonFaceFromUrl",
        "summary": "Add a face to a person (see PersonDirectory Person - Create) for face identification or verification.",
        "description": "To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonDirectory Person - Delete Face or PersonDirectory Person - Delete is called.\nNote persistedFaceId is different from faceId generated by Face - Detect.\n\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there's no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model\n  * 'detection_01': The default detection model for PersonDirectory Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n  * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n  * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces.\n* Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\n* This is a long running operation. Use Response Header \"Operation-Location\" to determine when the AddFace operation has successfully propagated for future requests to Face - Identify. For further information about Operation-Locations see Operations - Get Status.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "personId",
            "in": "path",
            "description": "Person ID of the person.",
            "required": true,
            "type": "string"
          },
          {
            "name": "recognitionModel",
            "in": "path",
            "description": "The 'recognitionModel' associated with faces.",
            "required": true,
            "type": "string",
            "enum": [
              "recognition_01",
              "recognition_02",
              "recognition_03",
              "recognition_04"
            ],
            "x-ms-enum": {
              "name": "RecognitionModel",
              "modelAsString": true,
              "values": [
                {
                  "name": "recognition_01",
                  "value": "recognition_01",
                  "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
                },
                {
                  "name": "recognition_02",
                  "value": "recognition_02",
                  "description": "Recognition model released in 2019 March."
                },
                {
                  "name": "recognition_03",
                  "value": "recognition_03",
                  "description": "Recognition model released in 2020 May."
                },
                {
                  "name": "recognition_04",
                  "value": "recognition_04",
                  "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
                }
              ]
            }
          },
          {
            "$ref": "#/parameters/AddFaceOptions.targetFace"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.detectionModel"
          },
          {
            "$ref": "#/parameters/AddFaceOptions.userData"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "url": {
                  "type": "string",
                  "format": "uri",
                  "description": "URL of input image."
                }
              },
              "required": [
                "url"
              ]
            }
          }
        ],
        "responses": {
          "202": {
            "description": "A successful call returns an empty response body. The service has accepted the request and will start processing soon. The client can query the operation status and result using the URL specified in the 'Operation-Location' response header. The URL expires in 48 hours.",
            "schema": {
              "$ref": "#/definitions/AddFaceResult"
            },
            "headers": {
              "operation-Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of FaceOperationStatus"
              },
              "Location": {
                "type": "string",
                "format": "uri",
                "description": "The location of an instance of PersonDirectoryPerson"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "PersonDirectoryOperations_AddPersonFaceFromUrl": {
            "$ref": "./examples/PersonDirectoryOperations_AddPersonFaceFromUrl.json"
          }
        }
      }
    },
    "/face/{apiVersion}/verify?_overload=verifyFromLargePersonGroup": {
      "post": {
        "operationId": "FaceRecognitionOperations_VerifyFromLargePersonGroup",
        "summary": "Verify whether one face belongs to a person in large person group.",
        "description": "> [!NOTE]\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * For the scenarios that are sensitive to accuracy please make your own judgment.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceId": {
                  "type": "string",
                  "description": "faceId of the face, comes from Face - Detect."
                },
                "largePersonGroupId": {
                  "type": "string",
                  "description": "Using existing largePersonGroupId and personId for fast loading a specified person. largePersonGroupId is created in LargePersonGroup - Create."
                },
                "personId": {
                  "type": "string",
                  "description": "Specify a certain person in large person group."
                }
              },
              "required": [
                "faceId",
                "largePersonGroupId",
                "personId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the verification result.",
            "schema": {
              "$ref": "#/definitions/FaceVerificationResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_VerifyFromLargePersonGroup": {
            "$ref": "./examples/FaceRecognitionOperations_VerifyFromLargePersonGroup.json"
          }
        }
      }
    },
    "/face/{apiVersion}/verify?_overload=verifyFromPersonDirectory": {
      "post": {
        "operationId": "FaceRecognitionOperations_VerifyFromPersonDirectory",
        "summary": "Verify whether one face belongs to a person directory person.",
        "description": "> [!NOTE]\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * For the scenarios that are sensitive to accuracy please make your own judgment.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceId": {
                  "type": "string",
                  "description": "faceId of the face, comes from Face - Detect."
                },
                "personId": {
                  "type": "string",
                  "description": "Specify a certain person in PersonDirectory Person."
                }
              },
              "required": [
                "faceId",
                "personId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the verification result.",
            "schema": {
              "$ref": "#/definitions/FaceVerificationResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_VerifyFromPersonDirectory": {
            "$ref": "./examples/FaceRecognitionOperations_VerifyFromPersonDirectory.json"
          }
        }
      }
    },
    "/face/{apiVersion}/verify?_overload=verifyFromPersonGroup": {
      "post": {
        "operationId": "FaceRecognitionOperations_VerifyFromPersonGroup",
        "summary": "Verify whether one face belongs to a person in person group.",
        "description": "> [!NOTE]\n> * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n> * For the scenarios that are sensitive to accuracy please make your own judgment.\n> * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.",
        "parameters": [
          {
            "$ref": "#/parameters/ApiVersionPathParameter"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "faceId": {
                  "type": "string",
                  "description": "faceId of the face, comes from Face - Detect."
                },
                "personGroupId": {
                  "type": "string",
                  "description": "Using existing personGroupId and personId for fast loading a specified person. personGroupId is created in PersonGroup - Create."
                },
                "personId": {
                  "type": "string",
                  "description": "Specify a certain person in person group."
                }
              },
              "required": [
                "faceId",
                "personGroupId",
                "personId"
              ]
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the verification result.",
            "schema": {
              "$ref": "#/definitions/FaceVerificationResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-examples": {
          "FaceRecognitionOperations_VerifyFromPersonGroup": {
            "$ref": "./examples/FaceRecognitionOperations_VerifyFromPersonGroup.json"
          }
        }
      }
    }
  },
  "definitions": {
    "AccessoryItem": {
      "type": "object",
      "description": "Accessory item and corresponding confidence level.",
      "properties": {
        "type": {
          "$ref": "#/definitions/AccessoryType",
          "description": "Type of the accessory."
        },
        "confidence": {
          "type": "number",
          "format": "float",
          "description": "Confidence level of the accessory type. Range between [0,1].",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "type",
        "confidence"
      ]
    },
    "AccessoryType": {
      "type": "string",
      "description": "Type of the accessory.",
      "enum": [
        "headwear",
        "glasses",
        "mask"
      ],
      "x-ms-enum": {
        "name": "AccessoryType",
        "modelAsString": true,
        "values": [
          {
            "name": "headwear",
            "value": "headwear",
            "description": "Head wear"
          },
          {
            "name": "glasses",
            "value": "glasses",
            "description": "Glasses"
          },
          {
            "name": "mask",
            "value": "mask",
            "description": "Mask"
          }
        ]
      }
    },
    "AddFaceResult": {
      "type": "object",
      "description": "Response body for adding face.",
      "properties": {
        "persistedFaceId": {
          "type": "string",
          "description": "persistedFaceId of the added face, which is persisted and will not expire. Different from faceId which is created in Face - Detect and will expire in 24 hours after the detection call."
        }
      },
      "required": [
        "persistedFaceId"
      ]
    },
    "Azure.Core.Foundations.Error": {
      "type": "object",
      "description": "The error object.",
      "properties": {
        "code": {
          "type": "string",
          "description": "One of a server-defined set of error codes."
        },
        "message": {
          "type": "string",
          "description": "A human-readable representation of the error."
        },
        "target": {
          "type": "string",
          "description": "The target of the error."
        },
        "details": {
          "type": "array",
          "description": "An array of details about specific errors that led to this reported error.",
          "items": {
            "$ref": "#/definitions/Azure.Core.Foundations.Error"
          },
          "x-ms-identifiers": []
        },
        "innererror": {
          "$ref": "#/definitions/Azure.Core.Foundations.InnerError",
          "description": "An object containing more specific information than the current object about the error."
        }
      },
      "required": [
        "code",
        "message"
      ]
    },
    "Azure.Core.Foundations.ErrorResponse": {
      "type": "object",
      "description": "A response containing error details.",
      "properties": {
        "error": {
          "$ref": "#/definitions/Azure.Core.Foundations.Error",
          "description": "The error object."
        }
      },
      "required": [
        "error"
      ]
    },
    "Azure.Core.Foundations.InnerError": {
      "type": "object",
      "description": "An object containing more specific information about the error. As per Microsoft One API guidelines - https://github.com/Microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses.",
      "properties": {
        "code": {
          "type": "string",
          "description": "One of a server-defined set of error codes."
        },
        "innererror": {
          "$ref": "#/definitions/Azure.Core.Foundations.InnerError",
          "description": "Inner error."
        }
      }
    },
    "Azure.Core.Foundations.OperationState": {
      "type": "string",
      "description": "Enum describing allowed operation states.",
      "enum": [
        "NotStarted",
        "Running",
        "Succeeded",
        "Failed",
        "Canceled"
      ],
      "x-ms-enum": {
        "name": "OperationState",
        "modelAsString": true,
        "values": [
          {
            "name": "NotStarted",
            "value": "NotStarted",
            "description": "The operation has not started."
          },
          {
            "name": "Running",
            "value": "Running",
            "description": "The operation is in progress."
          },
          {
            "name": "Succeeded",
            "value": "Succeeded",
            "description": "The operation has completed successfully."
          },
          {
            "name": "Failed",
            "value": "Failed",
            "description": "The operation has failed."
          },
          {
            "name": "Canceled",
            "value": "Canceled",
            "description": "The operation has been canceled by the user."
          }
        ]
      }
    },
    "BlurLevel": {
      "type": "string",
      "description": "Indicates level of blurriness.",
      "enum": [
        "low",
        "medium",
        "high"
      ],
      "x-ms-enum": {
        "name": "BlurLevel",
        "modelAsString": true,
        "values": [
          {
            "name": "low",
            "value": "low",
            "description": "Low blur level."
          },
          {
            "name": "medium",
            "value": "medium",
            "description": "Medium blur level."
          },
          {
            "name": "high",
            "value": "high",
            "description": "High blur level."
          }
        ]
      }
    },
    "BlurProperties": {
      "type": "object",
      "description": "Properties describing any presence of blur within the image.",
      "properties": {
        "blurLevel": {
          "$ref": "#/definitions/BlurLevel",
          "description": "An enum value indicating level of blurriness."
        },
        "value": {
          "type": "number",
          "format": "float",
          "description": "A number indicating level of blurriness ranging from 0 to 1.",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "blurLevel",
        "value"
      ]
    },
    "CollectionTrainingStatus": {
      "type": "object",
      "description": "Training status of a container",
      "properties": {
        "status": {
          "$ref": "#/definitions/Azure.Core.Foundations.OperationState",
          "description": "Training status of the container."
        },
        "createdDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the created time of the person group, large person group or large face list."
        },
        "lastActionDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the last modify time of the person group, large person group or large face list, could be null value when the group is not successfully trained."
        },
        "lastSuccessfulTrainingDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the last successful training time of the person group, large person group or large face list."
        },
        "message": {
          "type": "string",
          "description": "Show failure message when training failed (omitted when training succeed)."
        }
      },
      "required": [
        "status",
        "createdDateTime",
        "lastActionDateTime",
        "lastSuccessfulTrainingDateTime"
      ]
    },
    "CreateDynamicPersonGroupContent": {
      "type": "object",
      "description": "Request of create dynamic person group.",
      "properties": {
        "addPersonIds": {
          "type": "array",
          "description": "Array of personIds created by PersonDirectory Person - Create to add.",
          "items": {
            "type": "string"
          }
        },
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        }
      },
      "required": [
        "name"
      ]
    },
    "CreatePersonResult": {
      "type": "object",
      "description": "Response of create person.",
      "properties": {
        "personId": {
          "type": "string",
          "description": "Person ID of the person."
        }
      },
      "required": [
        "personId"
      ]
    },
    "DynamicPersonGroup": {
      "type": "object",
      "description": "A container that references PersonDirectory Person - Create.",
      "properties": {
        "dynamicPersonGroupId": {
          "type": "string",
          "description": "ID of the dynamic person group.",
          "readOnly": true
        },
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        }
      },
      "required": [
        "dynamicPersonGroupId",
        "name"
      ]
    },
    "ExposureLevel": {
      "type": "string",
      "description": "Indicates level of exposure.",
      "enum": [
        "underExposure",
        "goodExposure",
        "overExposure"
      ],
      "x-ms-enum": {
        "name": "ExposureLevel",
        "modelAsString": true,
        "values": [
          {
            "name": "underExposure",
            "value": "underExposure",
            "description": "Low exposure level."
          },
          {
            "name": "goodExposure",
            "value": "goodExposure",
            "description": "Good exposure level."
          },
          {
            "name": "overExposure",
            "value": "overExposure",
            "description": "High exposure level."
          }
        ]
      }
    },
    "ExposureProperties": {
      "type": "object",
      "description": "Properties describing exposure level of the image.",
      "properties": {
        "exposureLevel": {
          "$ref": "#/definitions/ExposureLevel",
          "description": "An enum value indicating level of exposure."
        },
        "value": {
          "type": "number",
          "format": "float",
          "description": "A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure.",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "exposureLevel",
        "value"
      ]
    },
    "FaceAttributes": {
      "type": "object",
      "description": "Face attributes for the detected face.",
      "properties": {
        "age": {
          "type": "integer",
          "format": "int32",
          "description": "Age in years"
        },
        "smile": {
          "type": "number",
          "format": "float",
          "description": "Smile intensity, a number between [0,1]",
          "minimum": 0,
          "maximum": 1
        },
        "facialHair": {
          "$ref": "#/definitions/FacialHair",
          "description": "Properties describing facial hair attributes."
        },
        "glasses": {
          "$ref": "#/definitions/GlassesType",
          "description": "Glasses type if any of the face."
        },
        "headPose": {
          "$ref": "#/definitions/HeadPose",
          "description": "3-D roll/yaw/pitch angles for face direction."
        },
        "hair": {
          "$ref": "#/definitions/HairProperties",
          "description": "Properties describing hair attributes."
        },
        "occlusion": {
          "$ref": "#/definitions/OcclusionProperties",
          "description": "Properties describing occlusions on a given face."
        },
        "accessories": {
          "type": "array",
          "description": "Properties describing any accessories on a given face.",
          "items": {
            "$ref": "#/definitions/AccessoryItem"
          },
          "x-ms-identifiers": []
        },
        "blur": {
          "$ref": "#/definitions/BlurProperties",
          "description": "Properties describing any presence of blur within the image."
        },
        "exposure": {
          "$ref": "#/definitions/ExposureProperties",
          "description": "Properties describing exposure level of the image."
        },
        "noise": {
          "$ref": "#/definitions/NoiseProperties",
          "description": "Properties describing noise level of the image."
        },
        "mask": {
          "$ref": "#/definitions/MaskProperties",
          "description": "Properties describing the presence of a mask on a given face."
        },
        "qualityForRecognition": {
          "$ref": "#/definitions/QualityForRecognition",
          "description": "Properties describing the overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on."
        }
      }
    },
    "FaceDetectionResult": {
      "type": "object",
      "description": "Response for detect API.",
      "properties": {
        "faceId": {
          "type": "string",
          "description": "Unique faceId of the detected face, created by detection API and it will expire 24 hours after the detection call. To return this, it requires 'returnFaceId' parameter to be true."
        },
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel",
          "description": "The 'recognitionModel' associated with this faceId. This is only returned when 'returnRecognitionModel' is explicitly set as true."
        },
        "faceRectangle": {
          "$ref": "#/definitions/FaceRectangle",
          "description": "A rectangle area for the face location on image."
        },
        "faceLandmarks": {
          "$ref": "#/definitions/FaceLandmarks",
          "description": "An array of 27-point face landmarks pointing to the important positions of face components. To return this, it requires 'returnFaceLandmarks' parameter to be true."
        },
        "faceAttributes": {
          "$ref": "#/definitions/FaceAttributes",
          "description": "Face attributes for detected face."
        }
      },
      "required": [
        "faceId"
      ]
    },
    "FaceFindSimilarResult": {
      "type": "object",
      "description": "Response body for find similar face operation.",
      "properties": {
        "confidence": {
          "type": "number",
          "format": "float",
          "description": "Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1].",
          "minimum": 0,
          "maximum": 1
        },
        "faceId": {
          "type": "string",
          "description": "faceId of candidate face when find by faceIds. faceId is created by Face - Detect and will expire 24 hours after the detection call."
        },
        "persistedFaceId": {
          "type": "string",
          "description": "persistedFaceId of candidate face when find by faceListId or largeFaceListId. persistedFaceId in face list/large face list is persisted and will not expire."
        }
      },
      "required": [
        "confidence"
      ]
    },
    "FaceGroupingResult": {
      "type": "object",
      "description": "Response body for group face operation.",
      "properties": {
        "groups": {
          "type": "array",
          "description": "A partition of the original faces based on face similarity. Groups are ranked by number of faces.",
          "items": {
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "x-ms-identifiers": []
        },
        "messyGroup": {
          "type": "array",
          "description": "Face ids array of faces that cannot find any similar faces from original faces.",
          "items": {
            "type": "string"
          }
        }
      },
      "required": [
        "groups",
        "messyGroup"
      ]
    },
    "FaceIdentificationCandidate": {
      "type": "object",
      "description": "Candidate for identify call.",
      "properties": {
        "personId": {
          "type": "string",
          "description": "personId of candidate person."
        },
        "confidence": {
          "type": "number",
          "format": "float",
          "description": "Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1].",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "personId",
        "confidence"
      ]
    },
    "FaceIdentificationResult": {
      "type": "object",
      "description": "Identify result.",
      "properties": {
        "faceId": {
          "type": "string",
          "description": "faceId of the query face."
        },
        "candidates": {
          "type": "array",
          "description": "Identified person candidates for that face (ranked by confidence). Array size should be no larger than input maxNumOfCandidatesReturned. If no person is identified, will return an empty array.",
          "items": {
            "$ref": "#/definitions/FaceIdentificationCandidate"
          },
          "x-ms-identifiers": []
        }
      },
      "required": [
        "faceId",
        "candidates"
      ]
    },
    "FaceLandmarks": {
      "type": "object",
      "description": "A collection of 27-point face landmarks pointing to the important positions of face components.",
      "properties": {
        "pupilLeft": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "pupilRight": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "noseTip": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "mouthLeft": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "mouthRight": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyebrowLeftOuter": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyebrowLeftInner": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeLeftOuter": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeLeftTop": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeLeftBottom": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeLeftInner": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyebrowRightInner": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyebrowRightOuter": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeRightInner": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeRightTop": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeRightBottom": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "eyeRightOuter": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "noseRootLeft": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "noseRootRight": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "noseLeftAlarTop": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "noseRightAlarTop": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "noseLeftAlarOutTip": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "noseRightAlarOutTip": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "upperLipTop": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "upperLipBottom": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "underLipTop": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        },
        "underLipBottom": {
          "$ref": "#/definitions/LandmarkCoordinate",
          "description": "Coordinates within an image"
        }
      },
      "required": [
        "pupilLeft",
        "pupilRight",
        "noseTip",
        "mouthLeft",
        "mouthRight",
        "eyebrowLeftOuter",
        "eyebrowLeftInner",
        "eyeLeftOuter",
        "eyeLeftTop",
        "eyeLeftBottom",
        "eyeLeftInner",
        "eyebrowRightInner",
        "eyebrowRightOuter",
        "eyeRightInner",
        "eyeRightTop",
        "eyeRightBottom",
        "eyeRightOuter",
        "noseRootLeft",
        "noseRootRight",
        "noseLeftAlarTop",
        "noseRightAlarTop",
        "noseLeftAlarOutTip",
        "noseRightAlarOutTip",
        "upperLipTop",
        "upperLipBottom",
        "underLipTop",
        "underLipBottom"
      ]
    },
    "FaceList": {
      "type": "object",
      "description": "Face list is a list of faces, up to 1,000 faces.",
      "properties": {
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        },
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel",
          "description": "The 'recognitionModel' associated with this face list. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02, 'recognition_03', and 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
        },
        "faceListId": {
          "type": "string",
          "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
          "readOnly": true
        },
        "persistedFaces": {
          "type": "array",
          "description": "Face ids of registered faces in the face list.",
          "items": {
            "$ref": "#/definitions/FaceListFace"
          },
          "readOnly": true,
          "x-ms-identifiers": []
        }
      },
      "required": [
        "name",
        "faceListId"
      ]
    },
    "FaceListFace": {
      "type": "object",
      "description": "Face resource for face list.",
      "properties": {
        "persistedFaceId": {
          "type": "string",
          "description": "Face ID of the face.",
          "readOnly": true
        },
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      },
      "required": [
        "persistedFaceId"
      ]
    },
    "FaceListItem": {
      "type": "object",
      "description": "Face list item for list face list.",
      "properties": {
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        },
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel",
          "description": "The 'recognitionModel' associated with this face list. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02, 'recognition_03', and 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
        },
        "faceListId": {
          "type": "string",
          "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64."
        }
      },
      "required": [
        "name",
        "faceListId"
      ]
    },
    "FaceOperationStatus": {
      "type": "object",
      "description": "Long running operation resource for person directory.",
      "properties": {
        "operationId": {
          "type": "string",
          "description": "Operation ID of the operation.",
          "readOnly": true
        },
        "status": {
          "$ref": "#/definitions/Azure.Core.Foundations.OperationState",
          "description": "Current status of the operation."
        },
        "createdDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Date and time the operation was created."
        },
        "finishedDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Date and time the operation was finished."
        },
        "message": {
          "type": "string",
          "description": "Message for the operation."
        }
      },
      "required": [
        "operationId",
        "status",
        "createdDateTime"
      ]
    },
    "FaceRectangle": {
      "type": "object",
      "description": "A rectangle within which a face can be found.",
      "properties": {
        "top": {
          "type": "integer",
          "format": "int32",
          "description": "The distance from the top edge if the image to the top edge of the rectangle, in pixels."
        },
        "left": {
          "type": "integer",
          "format": "int32",
          "description": "The distance from the left edge if the image to the left edge of the rectangle, in pixels."
        },
        "width": {
          "type": "integer",
          "format": "int32",
          "description": "The width of the rectangle, in pixels."
        },
        "height": {
          "type": "integer",
          "format": "int32",
          "description": "The height of the rectangle, in pixels."
        }
      },
      "required": [
        "top",
        "left",
        "width",
        "height"
      ]
    },
    "FaceSessionStatus": {
      "type": "string",
      "description": "The current status of the session.",
      "enum": [
        "NotStarted",
        "Started",
        "ResultAvailable"
      ],
      "x-ms-enum": {
        "name": "FaceSessionStatus",
        "modelAsString": true,
        "values": [
          {
            "name": "NotStarted",
            "value": "NotStarted",
            "description": "Session has not started."
          },
          {
            "name": "Started",
            "value": "Started",
            "description": "Session has started."
          },
          {
            "name": "ResultAvailable",
            "value": "ResultAvailable",
            "description": "Session has available result."
          }
        ]
      }
    },
    "FaceVerificationResult": {
      "type": "object",
      "description": "Verify result.",
      "properties": {
        "isIdentical": {
          "type": "boolean",
          "description": "True if the two faces belong to the same person or the face belongs to the person, otherwise false."
        },
        "confidence": {
          "type": "number",
          "format": "float",
          "description": "\tA number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override 'isIdentical' and fine-tune the result on their own data.",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "isIdentical",
        "confidence"
      ]
    },
    "FacialHair": {
      "type": "object",
      "description": "Properties describing facial hair attributes.",
      "properties": {
        "moustache": {
          "type": "number",
          "format": "float",
          "description": "A number ranging from 0 to 1 indicating a level of confidence associated with a property.",
          "minimum": 0,
          "maximum": 1
        },
        "beard": {
          "type": "number",
          "format": "float",
          "description": "A number ranging from 0 to 1 indicating a level of confidence associated with a property.",
          "minimum": 0,
          "maximum": 1
        },
        "sideburns": {
          "type": "number",
          "format": "float",
          "description": "A number ranging from 0 to 1 indicating a level of confidence associated with a property.",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "moustache",
        "beard",
        "sideburns"
      ]
    },
    "FindSimilarMatchMode": {
      "type": "string",
      "description": "Similar face searching mode.",
      "enum": [
        "matchPerson",
        "matchFace"
      ],
      "x-ms-enum": {
        "name": "FindSimilarMatchMode",
        "modelAsString": true,
        "values": [
          {
            "name": "matchPerson",
            "value": "matchPerson",
            "description": "Match person."
          },
          {
            "name": "matchFace",
            "value": "matchFace",
            "description": "Match face."
          }
        ]
      }
    },
    "GlassesType": {
      "type": "string",
      "description": "Glasses type of the face.",
      "enum": [
        "noGlasses",
        "readingGlasses",
        "sunglasses",
        "swimmingGoggles"
      ],
      "x-ms-enum": {
        "name": "GlassesType",
        "modelAsString": true,
        "values": [
          {
            "name": "noGlasses",
            "value": "noGlasses",
            "description": "No glasses on the face."
          },
          {
            "name": "readingGlasses",
            "value": "readingGlasses",
            "description": "Normal glasses on the face."
          },
          {
            "name": "sunglasses",
            "value": "sunglasses",
            "description": "Sunglasses on the face."
          },
          {
            "name": "swimmingGoggles",
            "value": "swimmingGoggles",
            "description": "Swimming goggles on the face."
          }
        ]
      }
    },
    "HairColor": {
      "type": "object",
      "description": "An array of candidate colors and confidence level in the presence of each.",
      "properties": {
        "color": {
          "$ref": "#/definitions/HairColorType",
          "description": "Name of the hair color."
        },
        "confidence": {
          "type": "number",
          "format": "float",
          "description": "Confidence level of the color. Range between [0,1].",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "color",
        "confidence"
      ]
    },
    "HairColorType": {
      "type": "string",
      "description": "Name of the hair color.",
      "enum": [
        "unknown",
        "white",
        "gray",
        "blond",
        "brown",
        "red",
        "black",
        "other"
      ],
      "x-ms-enum": {
        "name": "HairColorType",
        "modelAsString": true,
        "values": [
          {
            "name": "unknownHairColor",
            "value": "unknown",
            "description": "Unknown"
          },
          {
            "name": "white",
            "value": "white",
            "description": "White"
          },
          {
            "name": "gray",
            "value": "gray",
            "description": "Gray"
          },
          {
            "name": "blond",
            "value": "blond",
            "description": "Blond"
          },
          {
            "name": "brown",
            "value": "brown",
            "description": "Brown"
          },
          {
            "name": "red",
            "value": "red",
            "description": "Red"
          },
          {
            "name": "black",
            "value": "black",
            "description": "Black"
          },
          {
            "name": "other",
            "value": "other",
            "description": "Other"
          }
        ]
      }
    },
    "HairProperties": {
      "type": "object",
      "description": "Properties describing hair attributes.",
      "properties": {
        "bald": {
          "type": "number",
          "format": "float",
          "description": "A number describing confidence level of whether the person is bald.",
          "minimum": 0,
          "maximum": 1
        },
        "invisible": {
          "type": "boolean",
          "description": "A boolean value describing whether the hair is visible in the image."
        },
        "hairColor": {
          "type": "array",
          "description": "An array of candidate colors and confidence level in the presence of each.",
          "items": {
            "$ref": "#/definitions/HairColor"
          },
          "x-ms-identifiers": []
        }
      },
      "required": [
        "bald",
        "invisible",
        "hairColor"
      ]
    },
    "HeadPose": {
      "type": "object",
      "description": "3-D roll/yaw/pitch angles for face direction.",
      "properties": {
        "pitch": {
          "type": "number",
          "format": "float",
          "description": "Value of angles."
        },
        "roll": {
          "type": "number",
          "format": "float",
          "description": "Value of angles."
        },
        "yaw": {
          "type": "number",
          "format": "float",
          "description": "Value of angles."
        }
      },
      "required": [
        "pitch",
        "roll",
        "yaw"
      ]
    },
    "LandmarkCoordinate": {
      "type": "object",
      "description": "Coordinates within an image.",
      "properties": {
        "x": {
          "type": "number",
          "format": "float",
          "description": "The horizontal component, in pixels."
        },
        "y": {
          "type": "number",
          "format": "float",
          "description": "The vertical component, in pixels."
        }
      },
      "required": [
        "x",
        "y"
      ]
    },
    "LargeFaceList": {
      "type": "object",
      "description": "Large face list is a list of faces, up to 1,000,000 faces.",
      "properties": {
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        },
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel",
          "description": "The 'recognitionModel' associated with this face list. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02, 'recognition_03', and 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
        },
        "largeFaceListId": {
          "type": "string",
          "description": "Valid character is letter in lower case or digit or '-' or '_', maximum length is 64.",
          "readOnly": true
        }
      },
      "required": [
        "name",
        "largeFaceListId"
      ]
    },
    "LargeFaceListFace": {
      "type": "object",
      "description": "Face resource for large face list.",
      "properties": {
        "persistedFaceId": {
          "type": "string",
          "description": "Face ID of the face.",
          "readOnly": true
        },
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      },
      "required": [
        "persistedFaceId"
      ]
    },
    "LargeFaceListFaceUpdate": {
      "type": "object",
      "description": "Face resource for large face list.",
      "properties": {
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      }
    },
    "LargePersonGroup": {
      "type": "object",
      "description": "The container of the uploaded person data, including face recognition feature, and up to 1,000,000 people.",
      "properties": {
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        },
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel",
          "description": "Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need."
        },
        "largePersonGroupId": {
          "type": "string",
          "description": "ID of the container.",
          "readOnly": true
        }
      },
      "required": [
        "name",
        "largePersonGroupId"
      ]
    },
    "LargePersonGroupPerson": {
      "type": "object",
      "description": "The person in a specified large person group. To add face to this person, please call LargePersonGroup PersonFace - Add.",
      "properties": {
        "personId": {
          "type": "string",
          "description": "ID of the person.",
          "readOnly": true
        },
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        },
        "persistedFaceIds": {
          "type": "array",
          "description": "Face ids of registered faces in the person.",
          "items": {
            "type": "string"
          },
          "readOnly": true
        }
      },
      "required": [
        "personId",
        "name"
      ]
    },
    "LargePersonGroupPersonFace": {
      "type": "object",
      "description": "Face resource for large person group person.",
      "properties": {
        "persistedFaceId": {
          "type": "string",
          "description": "Face ID of the face.",
          "readOnly": true
        },
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      },
      "required": [
        "persistedFaceId"
      ]
    },
    "LargePersonGroupPersonFaceUpdate": {
      "type": "object",
      "description": "Face resource for large person group person.",
      "properties": {
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      }
    },
    "ListFaceResult": {
      "type": "object",
      "description": "Response of list face of person.",
      "properties": {
        "personId": {
          "type": "string",
          "description": "Id of person."
        },
        "persistedFaceIds": {
          "type": "array",
          "description": "Array of persisted face ids.",
          "items": {
            "type": "string"
          }
        }
      },
      "required": [
        "personId",
        "persistedFaceIds"
      ]
    },
    "ListGroupReferenceResult": {
      "type": "object",
      "description": "Response of list dynamic person group of person.",
      "properties": {
        "dynamicPersonGroupIds": {
          "type": "array",
          "description": "Array of PersonDirectory DynamicPersonGroup ids.",
          "items": {
            "type": "string"
          }
        }
      },
      "required": [
        "dynamicPersonGroupIds"
      ]
    },
    "ListPersonResult": {
      "type": "object",
      "description": "Response of list dynamic person group person.",
      "properties": {
        "personIds": {
          "type": "array",
          "description": "Array of PersonDirectory Person ids.",
          "items": {
            "type": "string"
          }
        }
      },
      "required": [
        "personIds"
      ]
    },
    "LivenessSession": {
      "type": "object",
      "description": "Session result of detect liveness.",
      "properties": {
        "id": {
          "type": "string",
          "description": "Unique ID to reference this session.",
          "readOnly": true
        },
        "createdDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Session creation time in millisecond from epoch.",
          "readOnly": true
        },
        "sessionStartDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Session started time from session auth token.",
          "readOnly": true
        },
        "sessionExpired": {
          "type": "boolean",
          "description": "Whether or not the session is expired.",
          "readOnly": true
        },
        "deviceCorrelationId": {
          "type": "string",
          "description": "Device Correlation Id to use for linking multiple sessions together."
        },
        "authTokenTimeToLiveInSeconds": {
          "type": "integer",
          "format": "int32",
          "description": "Session length in seconds. Range is 60 to 86400 seconds."
        },
        "status": {
          "$ref": "#/definitions/FaceSessionStatus",
          "description": "The session status.",
          "readOnly": true
        },
        "result": {
          "$ref": "#/definitions/LivenessSessionAuditEntry",
          "description": "The last result of session.",
          "readOnly": true
        }
      },
      "required": [
        "id",
        "createdDateTime",
        "sessionExpired",
        "deviceCorrelationId",
        "status"
      ]
    },
    "LivenessSessionAuditEntry": {
      "type": "object",
      "description": "Audit entry for a request in session.",
      "properties": {
        "id": {
          "type": "integer",
          "format": "int64",
          "description": "ID of this audit entry."
        },
        "sessionId": {
          "type": "string",
          "description": "Session ID of this audit entry."
        },
        "requestId": {
          "type": "string",
          "description": "Request ID in the request header."
        },
        "clientRequestId": {
          "type": "string",
          "description": "Client request ID in the request header."
        },
        "receivedDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "The UTC date time of the request."
        },
        "request": {
          "$ref": "#/definitions/SessionAuditEntryRequestInfo",
          "description": "The request of this entry."
        },
        "response": {
          "$ref": "#/definitions/SessionAuditEntryResponseInfo",
          "description": "The response of this entry."
        },
        "digest": {
          "type": "string",
          "description": "The digest of the request body."
        }
      },
      "required": [
        "id",
        "sessionId",
        "requestId",
        "clientRequestId",
        "receivedDateTime",
        "request",
        "response",
        "digest"
      ]
    },
    "LivenessSessionCreationContent": {
      "type": "object",
      "description": "Request for creating liveness session.",
      "properties": {
        "livenessOperationMode": {
          "type": "string",
          "description": "The operation mode for the liveness modal."
        },
        "sendResultsToClient": {
          "type": "boolean",
          "description": "Whether or not send back the operation response to client."
        },
        "deviceCorrelationIdSetInClient": {
          "type": "boolean",
          "description": "Whether or not the device correlation id is set by the client."
        },
        "deviceCorrelationId": {
          "type": "string",
          "description": "Device Correlation Id to use for linking multiple sessions together."
        },
        "authTokenTimeToLiveInSeconds": {
          "type": "integer",
          "format": "int32",
          "description": "Session length in seconds. Range is 60 to 86400 seconds."
        }
      },
      "required": [
        "livenessOperationMode",
        "deviceCorrelationId"
      ]
    },
    "LivenessSessionCreationContentForMultipart": {
      "type": "object",
      "description": "Dedicated parameter model for multipart/form-data.",
      "properties": {
        "livenessOperationMode": {
          "type": "string",
          "description": "The operation mode for the liveness modal."
        },
        "sendResultsToClient": {
          "type": "boolean",
          "description": "Whether or not send back the operation response to client."
        },
        "deviceCorrelationIdSetInClient": {
          "type": "boolean",
          "description": "Whether or not the device correlation id is set by the client."
        },
        "deviceCorrelationId": {
          "type": "string",
          "description": "Device Correlation Id to use for linking multiple sessions together."
        },
        "authTokenTimeToLiveInSeconds": {
          "type": "integer",
          "format": "int32",
          "description": "Session length in seconds. Range is 60 to 86400 seconds."
        }
      },
      "required": [
        "livenessOperationMode",
        "deviceCorrelationId"
      ]
    },
    "LivenessSessionCreationResult": {
      "type": "object",
      "description": "Response of liveness session creation.",
      "properties": {
        "sessionId": {
          "type": "string",
          "description": "Unique ID to reference this session."
        },
        "authToken": {
          "type": "string",
          "description": "Authorization token for use by the client application"
        }
      },
      "required": [
        "sessionId",
        "authToken"
      ]
    },
    "LivenessSessionItem": {
      "type": "object",
      "description": "Session data returned for enumeration.",
      "properties": {
        "id": {
          "type": "string",
          "description": "Unique ID to reference this session.",
          "readOnly": true
        },
        "createdDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Session creation time in millisecond from epoch.",
          "readOnly": true
        },
        "sessionStartDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Session started time from session auth token.",
          "readOnly": true
        },
        "sessionExpired": {
          "type": "boolean",
          "description": "Whether or not the session is expired.",
          "readOnly": true
        },
        "deviceCorrelationId": {
          "type": "string",
          "description": "Device Correlation Id to use for linking multiple sessions together."
        },
        "authTokenTimeToLiveInSeconds": {
          "type": "integer",
          "format": "int32",
          "description": "Session length in seconds. Range is 60 to 86400 seconds."
        }
      },
      "required": [
        "id",
        "createdDateTime",
        "sessionExpired",
        "deviceCorrelationId"
      ]
    },
    "LivenessSessionWithVerifyImageCreationContent": {
      "type": "object",
      "description": "Request of liveness with verify session creation.",
      "properties": {
        "Parameters": {
          "$ref": "#/definitions/LivenessSessionCreationContentForMultipart",
          "description": "The parameters for creating session."
        },
        "VerifyImage": {
          "type": "string",
          "format": "byte",
          "description": "The image stream for verify."
        }
      },
      "required": [
        "Parameters",
        "VerifyImage"
      ]
    },
    "LivenessWithVerifySession": {
      "type": "object",
      "description": "Session result of detect liveness with verify.",
      "properties": {
        "id": {
          "type": "string",
          "description": "Unique ID to reference this session.",
          "readOnly": true
        },
        "createdDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Session creation time in millisecond from epoch.",
          "readOnly": true
        },
        "sessionStartDateTime": {
          "type": "string",
          "format": "date-time",
          "description": "Session started time from session auth token.",
          "readOnly": true
        },
        "sessionExpired": {
          "type": "boolean",
          "description": "Whether or not the session is expired.",
          "readOnly": true
        },
        "deviceCorrelationId": {
          "type": "string",
          "description": "Device Correlation Id to use for linking multiple sessions together."
        },
        "authTokenTimeToLiveInSeconds": {
          "type": "integer",
          "format": "int32",
          "description": "Session length in seconds. Range is 60 to 86400 seconds."
        },
        "status": {
          "$ref": "#/definitions/FaceSessionStatus",
          "description": "The session status.",
          "readOnly": true
        },
        "result": {
          "$ref": "#/definitions/LivenessSessionAuditEntry",
          "description": "The last result of session.",
          "readOnly": true
        }
      },
      "required": [
        "id",
        "createdDateTime",
        "sessionExpired",
        "deviceCorrelationId",
        "status"
      ]
    },
    "MaskProperties": {
      "type": "object",
      "description": "Properties describing the presence of a mask on a given face.",
      "properties": {
        "noseAndMouthCovered": {
          "type": "boolean",
          "description": "A boolean value indicating whether nose and mouth are covered."
        },
        "type": {
          "$ref": "#/definitions/MaskType",
          "description": "Mask type if any of the face"
        }
      },
      "required": [
        "noseAndMouthCovered",
        "type"
      ]
    },
    "MaskType": {
      "type": "string",
      "description": "Mask type if any of the face",
      "enum": [
        "faceMask",
        "noMask",
        "otherMaskOrOcclusion",
        "uncertain"
      ],
      "x-ms-enum": {
        "name": "MaskType",
        "modelAsString": true,
        "values": [
          {
            "name": "faceMask",
            "value": "faceMask",
            "description": "Face mask."
          },
          {
            "name": "noMask",
            "value": "noMask",
            "description": "No mask."
          },
          {
            "name": "otherMaskOrOcclusion",
            "value": "otherMaskOrOcclusion",
            "description": "Other types of mask or occlusion."
          },
          {
            "name": "uncertain",
            "value": "uncertain",
            "description": "Uncertain"
          }
        ]
      }
    },
    "NoiseLevel": {
      "type": "string",
      "description": "Indicates level of noise.",
      "enum": [
        "low",
        "medium",
        "high"
      ],
      "x-ms-enum": {
        "name": "NoiseLevel",
        "modelAsString": true,
        "values": [
          {
            "name": "low",
            "value": "low",
            "description": "Low noise level."
          },
          {
            "name": "medium",
            "value": "medium",
            "description": "Medium noise level."
          },
          {
            "name": "high",
            "value": "high",
            "description": "High noise level."
          }
        ]
      }
    },
    "NoiseProperties": {
      "type": "object",
      "description": "Properties describing noise level of the image.",
      "properties": {
        "noiseLevel": {
          "$ref": "#/definitions/NoiseLevel",
          "description": "An enum value indicating level of noise."
        },
        "value": {
          "type": "number",
          "format": "float",
          "description": "A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level.",
          "minimum": 0,
          "maximum": 1
        }
      },
      "required": [
        "noiseLevel",
        "value"
      ]
    },
    "OcclusionProperties": {
      "type": "object",
      "description": "Properties describing occlusions on a given face.",
      "properties": {
        "foreheadOccluded": {
          "type": "boolean",
          "description": "A boolean value indicating whether forehead is occluded."
        },
        "eyeOccluded": {
          "type": "boolean",
          "description": "A boolean value indicating whether eyes are occluded."
        },
        "mouthOccluded": {
          "type": "boolean",
          "description": "A boolean value indicating whether the mouth is occluded."
        }
      },
      "required": [
        "foreheadOccluded",
        "eyeOccluded",
        "mouthOccluded"
      ]
    },
    "PersonDirectoryFace": {
      "type": "object",
      "description": "Face resource for person directory person.",
      "properties": {
        "persistedFaceId": {
          "type": "string",
          "description": "Face ID of the face.",
          "readOnly": true
        },
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      },
      "required": [
        "persistedFaceId"
      ]
    },
    "PersonDirectoryFaceUpdate": {
      "type": "object",
      "description": "Face resource for person directory person.",
      "properties": {
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      }
    },
    "PersonDirectoryPerson": {
      "type": "object",
      "description": "Person resource for person directory",
      "properties": {
        "personId": {
          "type": "string",
          "description": "Person ID of the person.",
          "readOnly": true
        },
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        }
      },
      "required": [
        "personId",
        "name"
      ]
    },
    "PersonGroup": {
      "type": "object",
      "description": "The container of the uploaded person data, including face recognition feature, and up to 10,000 persons. To handle larger scale face identification problem, please consider using LargePersonGroup.",
      "properties": {
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        },
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel",
          "description": "Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need."
        },
        "personGroupId": {
          "type": "string",
          "description": "ID of the container.",
          "readOnly": true
        }
      },
      "required": [
        "name",
        "personGroupId"
      ]
    },
    "PersonGroupPerson": {
      "type": "object",
      "description": "The person in a specified person group. To add face to this person, please call LargePersonGroup PersonFace - Add.",
      "properties": {
        "personId": {
          "type": "string",
          "description": "ID of the person.",
          "readOnly": true
        },
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        },
        "persistedFaceIds": {
          "type": "array",
          "description": "Face ids of registered faces in the person.",
          "items": {
            "type": "string"
          },
          "readOnly": true
        }
      },
      "required": [
        "personId",
        "name"
      ]
    },
    "PersonGroupPersonFace": {
      "type": "object",
      "description": "Face resource for person group person.",
      "properties": {
        "persistedFaceId": {
          "type": "string",
          "description": "Face ID of the face.",
          "readOnly": true
        },
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      },
      "required": [
        "persistedFaceId"
      ]
    },
    "PersonGroupPersonFaceUpdate": {
      "type": "object",
      "description": "Face resource for person group person.",
      "properties": {
        "userData": {
          "type": "string",
          "description": "User-provided data attached to the face. The length limit is 1K.",
          "maxLength": 1024
        }
      }
    },
    "QualityForRecognition": {
      "type": "string",
      "description": "Indicates quality of image for recognition.",
      "enum": [
        "low",
        "medium",
        "high"
      ],
      "x-ms-enum": {
        "name": "QualityForRecognition",
        "modelAsString": true,
        "values": [
          {
            "name": "low",
            "value": "low",
            "description": "Low quality."
          },
          {
            "name": "medium",
            "value": "medium",
            "description": "Medium quality."
          },
          {
            "name": "high",
            "value": "high",
            "description": "High quality."
          }
        ]
      }
    },
    "RecognitionModel": {
      "type": "string",
      "description": "The recognition model for the face.",
      "enum": [
        "recognition_01",
        "recognition_02",
        "recognition_03",
        "recognition_04"
      ],
      "x-ms-enum": {
        "name": "RecognitionModel",
        "modelAsString": true,
        "values": [
          {
            "name": "recognition_01",
            "value": "recognition_01",
            "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
          },
          {
            "name": "recognition_02",
            "value": "recognition_02",
            "description": "Recognition model released in 2019 March."
          },
          {
            "name": "recognition_03",
            "value": "recognition_03",
            "description": "Recognition model released in 2020 May."
          },
          {
            "name": "recognition_04",
            "value": "recognition_04",
            "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
          }
        ]
      }
    },
    "SessionAuditEntryRequestInfo": {
      "type": "object",
      "description": "Audit entry for a request in the session.",
      "properties": {
        "url": {
          "type": "string",
          "description": "The relative URL of the liveness request."
        },
        "method": {
          "type": "string",
          "description": "The HTTP method of the request."
        },
        "contentLength": {
          "type": "integer",
          "format": "int64",
          "description": "The length of the request body in bytes."
        },
        "contentType": {
          "type": "string",
          "description": "The content type of the request."
        },
        "userAgent": {
          "type": "string",
          "description": "The user agent of the request."
        }
      },
      "required": [
        "url",
        "method",
        "contentType"
      ]
    },
    "SessionAuditEntryResponseInfo": {
      "type": "object",
      "description": "Audit entry for a response in the session.",
      "properties": {
        "body": {
          "type": "object",
          "description": "The response body.",
          "additionalProperties": {}
        },
        "statusCode": {
          "type": "integer",
          "format": "int32",
          "description": "The HTTP status code of the request."
        },
        "latencyInMilliseconds": {
          "type": "integer",
          "format": "int64",
          "description": "The latency of the request."
        }
      },
      "required": [
        "body",
        "statusCode",
        "latencyInMilliseconds"
      ]
    },
    "UpdateDynamicPersonGroupContent": {
      "type": "object",
      "description": "Request of update dynamic person group.",
      "properties": {
        "addPersonIds": {
          "type": "array",
          "description": "Array of personIds created by PersonDirectory Person - Create to add.",
          "items": {
            "type": "string"
          }
        },
        "removePersonIds": {
          "type": "array",
          "description": "Array of personIds created by PersonDirectory Person - Create to remove.",
          "items": {
            "type": "string"
          }
        },
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        }
      }
    },
    "UserDefinedFields": {
      "type": "object",
      "description": "Model for object name and user data.",
      "properties": {
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        }
      },
      "required": [
        "name"
      ]
    },
    "UserDefinedFieldsUpdate": {
      "type": "object",
      "description": "Model for object name and user data.",
      "properties": {
        "name": {
          "type": "string",
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128
        },
        "userData": {
          "type": "string",
          "description": "Optional user defined data. Length should not exceed 16K.",
          "maxLength": 16384
        }
      }
    }
  },
  "parameters": {
    "AddFaceOptions.detectionModel": {
      "name": "detectionModel",
      "in": "query",
      "description": "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'.",
      "required": false,
      "type": "string",
      "enum": [
        "detection_01",
        "detection_02",
        "detection_03"
      ],
      "x-ms-enum": {
        "name": "DetectionModel",
        "modelAsString": true,
        "values": [
          {
            "name": "detection_01",
            "value": "detection_01",
            "description": "The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected."
          },
          {
            "name": "detection_02",
            "value": "detection_02",
            "description": "Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."
          },
          {
            "name": "detection_03",
            "value": "detection_03",
            "description": "Detection model released in 2021 February with improved accuracy especially on small faces."
          }
        ]
      },
      "x-ms-parameter-location": "method"
    },
    "AddFaceOptions.targetFace": {
      "name": "targetFace",
      "in": "query",
      "description": "A face rectangle to specify the target face to be added to a person, in the format of 'targetFace=left,top,width,height'.",
      "required": false,
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "AddFaceOptions.userData": {
      "name": "userData",
      "in": "query",
      "description": "User-provided data attached to the face. The size limit is 1KB.",
      "required": false,
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "ApiVersionPathParameter": {
      "name": "apiVersion",
      "in": "path",
      "description": "The API version to use for this operation.",
      "required": true,
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "FaceDetectionOptions.detectionModel": {
      "name": "detectionModel",
      "in": "query",
      "description": "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'.",
      "required": false,
      "type": "string",
      "enum": [
        "detection_01",
        "detection_02",
        "detection_03"
      ],
      "x-ms-enum": {
        "name": "DetectionModel",
        "modelAsString": true,
        "values": [
          {
            "name": "detection_01",
            "value": "detection_01",
            "description": "The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected."
          },
          {
            "name": "detection_02",
            "value": "detection_02",
            "description": "Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."
          },
          {
            "name": "detection_03",
            "value": "detection_03",
            "description": "Detection model released in 2021 February with improved accuracy especially on small faces."
          }
        ]
      },
      "x-ms-parameter-location": "method"
    },
    "FaceDetectionOptions.faceIdTimeToLive": {
      "name": "faceIdTimeToLive",
      "in": "query",
      "description": "The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).",
      "required": false,
      "type": "integer",
      "format": "int32",
      "minimum": 60,
      "maximum": 86400,
      "x-ms-parameter-location": "method"
    },
    "FaceDetectionOptions.recognitionModel": {
      "name": "recognitionModel",
      "in": "query",
      "description": "The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.",
      "required": false,
      "type": "string",
      "enum": [
        "recognition_01",
        "recognition_02",
        "recognition_03",
        "recognition_04"
      ],
      "x-ms-enum": {
        "name": "RecognitionModel",
        "modelAsString": true,
        "values": [
          {
            "name": "recognition_01",
            "value": "recognition_01",
            "description": "The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model."
          },
          {
            "name": "recognition_02",
            "value": "recognition_02",
            "description": "Recognition model released in 2019 March."
          },
          {
            "name": "recognition_03",
            "value": "recognition_03",
            "description": "Recognition model released in 2020 May."
          },
          {
            "name": "recognition_04",
            "value": "recognition_04",
            "description": "Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy."
          }
        ]
      },
      "x-ms-parameter-location": "method"
    },
    "FaceDetectionOptions.returnFaceAttributes": {
      "name": "returnFaceAttributes",
      "in": "query",
      "description": "Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost.",
      "required": false,
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "FaceDetectionOptions.returnFaceId": {
      "name": "returnFaceId",
      "in": "query",
      "description": "Return faceIds of the detected faces or not. The default value is true.",
      "required": false,
      "type": "boolean",
      "x-ms-parameter-location": "method"
    },
    "FaceDetectionOptions.returnFaceLandmarks": {
      "name": "returnFaceLandmarks",
      "in": "query",
      "description": "Return face landmarks of the detected faces or not. The default value is false.",
      "required": false,
      "type": "boolean",
      "x-ms-parameter-location": "method"
    },
    "FaceDetectionOptions.returnRecognitionModel": {
      "name": "returnRecognitionModel",
      "in": "query",
      "description": "Return 'recognitionModel' or not. The default value is false.",
      "required": false,
      "type": "boolean",
      "x-ms-parameter-location": "method"
    },
    "ListRequestOptions.start": {
      "name": "start",
      "in": "query",
      "description": "List resources greater than the \"start\". It contains no more than 64 characters. Default is empty.",
      "required": false,
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "ListRequestOptions.top": {
      "name": "top",
      "in": "query",
      "description": "The number of items to list, ranging in [1, 1000]. Default is 1000.",
      "required": false,
      "type": "integer",
      "format": "int32",
      "minimum": 1,
      "maximum": 1000,
      "x-ms-parameter-location": "method"
    },
    "LivenessSessionWithVerifyImageCreationContent.Parameters": {
      "name": "Parameters",
      "in": "formData",
      "description": "The parameters for creating session.",
      "required": true,
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "LivenessSessionWithVerifyImageCreationContent.VerifyImage": {
      "name": "VerifyImage",
      "in": "formData",
      "description": "The image stream for verify.",
      "required": true,
      "type": "file",
      "x-ms-parameter-location": "method"
    },
    "ReturnRecognitionModelOptions": {
      "name": "returnRecognitionModel",
      "in": "query",
      "description": "Return 'recognitionModel' or not. The default value is false.",
      "required": false,
      "type": "boolean",
      "x-ms-parameter-location": "method"
    }
  }
}
