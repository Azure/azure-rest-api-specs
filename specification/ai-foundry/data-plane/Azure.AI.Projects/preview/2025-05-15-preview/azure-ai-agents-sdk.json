{
  "swagger": "2.0",
  "info": {
    "title": "Azure AI",
    "version": "2025-05-15-preview",
    "x-typespec-generated": [
      {
        "emitter": "@azure-tools/typespec-autorest"
      }
    ]
  },
  "schemes": [
    "https"
  ],
  "x-ms-parameterized-host": {
    "hostTemplate": "{endpoint}",
    "useSchemePrefix": false,
    "parameters": [
      {
        "name": "endpoint",
        "in": "path",
        "description": "Foundry Project endpoint in the form\n\"https://{ai-services-account-name}.services.ai.azure.com/api/projects/{project-name}\".\nIf you only have one Project in your Foundry Hub, or to target the default Project\nin your Hub, use the form\n\"https://{ai-services-account-name}.services.ai.azure.com/api/projects/_project\"",
        "required": true,
        "type": "string",
        "format": "uri",
        "x-ms-skip-url-encoding": true
      }
    ]
  },
  "produces": [
    "application/json"
  ],
  "consumes": [
    "application/json"
  ],
  "security": [
    {
      "OAuth2Auth": [
        "https://ai.azure.com/.default"
      ]
    }
  ],
  "securityDefinitions": {
    "OAuth2Auth": {
      "type": "oauth2",
      "flow": "implicit",
      "authorizationUrl": "https://login.microsoftonline.com/common/oauth2/v2.0/authorize",
      "scopes": {
        "https://ai.azure.com/.default": ""
      }
    }
  },
  "tags": [
    {
      "name": "Responses"
    }
  ],
  "paths": {
    "/openai/responses": {
      "get": {
        "operationId": "listResponses",
        "tags": [
          "Responses"
        ],
        "description": "Returns the list of all responses.",
        "parameters": [
          {
            "$ref": "#/parameters/Azure.Core.Foundations.ApiVersionParameter"
          },
          {
            "name": "limit",
            "in": "query",
            "description": "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the\ndefault is 20.",
            "required": false,
            "type": "integer",
            "format": "int32",
            "default": 20
          },
          {
            "name": "order",
            "in": "query",
            "description": "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`\nfor descending order.",
            "required": false,
            "type": "string",
            "enum": [
              "asc",
              "desc"
            ],
            "x-ms-enum": {
              "modelAsString": false
            }
          },
          {
            "name": "after",
            "in": "query",
            "description": "A cursor for use in pagination. `after` is an object ID that defines your place in the list.\nFor instance, if you make a list request and receive 100 objects, ending with obj_foo, your\nsubsequent call can include after=obj_foo in order to fetch the next page of the list.",
            "required": false,
            "type": "string"
          },
          {
            "name": "before",
            "in": "query",
            "description": "A cursor for use in pagination. `before` is an object ID that defines your place in the list.\nFor instance, if you make a list request and receive 100 objects, ending with obj_foo, your\nsubsequent call can include before=obj_foo in order to fetch the previous page of the list.",
            "required": false,
            "type": "string"
          },
          {
            "name": "agent_name",
            "in": "query",
            "description": "Filter by agent name. If provided, only items associated with the specified agent will be returned.",
            "required": false,
            "type": "string"
          },
          {
            "name": "agent_id",
            "in": "query",
            "description": "Filter by agent ID in the format `name:version`. If provided, only items associated with the specified agent ID will be returned.",
            "required": false,
            "type": "string"
          },
          {
            "name": "conversation_id",
            "in": "query",
            "description": "Filter by conversation ID. If provided, only responses associated with the specified conversation will be returned.",
            "required": false,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "object",
              "description": "The response data for a requested list of items.",
              "properties": {
                "data": {
                  "type": "array",
                  "description": "The requested list of items.",
                  "items": {
                    "$ref": "#/definitions/OpenAI.Response"
                  }
                },
                "first_id": {
                  "type": "string",
                  "description": "The first ID represented in this list."
                },
                "last_id": {
                  "type": "string",
                  "description": "The last ID represented in this list."
                },
                "has_more": {
                  "type": "boolean",
                  "description": "A value indicating whether there are additional values available not captured in this list."
                }
              },
              "required": [
                "data",
                "has_more"
              ]
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/ApiErrorResponse"
            }
          }
        }
      },
      "post": {
        "operationId": "createResponse",
        "tags": [
          "Responses"
        ],
        "description": "Creates a model response.",
        "parameters": [
          {
            "name": "api-version",
            "in": "query",
            "description": "The API version to use for this operation.",
            "required": true,
            "type": "string",
            "minLength": 1,
            "x-ms-client-name": "apiVersion"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "type": "object",
              "properties": {
                "metadata": {
                  "type": "object",
                  "description": "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.",
                  "additionalProperties": {
                    "type": "string"
                  },
                  "x-oaiTypeLabel": "map"
                },
                "temperature": {
                  "type": "number",
                  "format": "float",
                  "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.",
                  "default": 1,
                  "x-nullable": true
                },
                "top_p": {
                  "type": "number",
                  "format": "float",
                  "description": "An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.",
                  "default": 1,
                  "x-nullable": true
                },
                "user": {
                  "type": "string",
                  "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)."
                },
                "service_tier": {
                  "$ref": "#/definitions/OpenAI.ServiceTier",
                  "description": "Note: service_tier is not applicable to Azure OpenAI."
                },
                "top_logprobs": {
                  "type": "integer",
                  "format": "int32",
                  "description": "An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.",
                  "minimum": 0,
                  "maximum": 20
                },
                "previous_response_id": {
                  "type": "string",
                  "description": "The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](/docs/guides/conversation-state).",
                  "x-nullable": true
                },
                "model": {
                  "type": "string",
                  "description": "The model deployment to use for the creation of this response."
                },
                "reasoning": {
                  "$ref": "#/definitions/OpenAI.Reasoning",
                  "x-nullable": true
                },
                "background": {
                  "type": "boolean",
                  "description": "Whether to run the model response in the background.\n[Learn more](/docs/guides/background).",
                  "default": false,
                  "x-nullable": true
                },
                "max_output_tokens": {
                  "type": "integer",
                  "format": "int32",
                  "description": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).",
                  "x-nullable": true
                },
                "max_tool_calls": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.",
                  "x-nullable": true
                },
                "text": {
                  "type": "object",
                  "description": "Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Structured Outputs](/docs/guides/structured-outputs)",
                  "properties": {
                    "format": {
                      "$ref": "#/definitions/OpenAI.ResponseTextFormatConfiguration"
                    }
                  }
                },
                "tools": {
                  "type": "array",
                  "description": "An array of tools the model may call while generating a response. You \ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like file search.\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code.",
                  "items": {
                    "$ref": "#/definitions/OpenAI.Tool"
                  }
                },
                "tool_choice": {
                  "description": "How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call."
                },
                "prompt": {
                  "$ref": "#/definitions/OpenAI.Prompt",
                  "x-nullable": true
                },
                "truncation": {
                  "type": "string",
                  "description": "The truncation strategy to use for the model response.\n- `auto`: If the context of this response and previous ones exceeds\n  the model's context window size, the model will truncate the\n  response to fit the context window by dropping input items in the\n  middle of the conversation.\n- `disabled` (default): If a model response will exceed the context window\n  size for a model, the request will fail with a 400 error.",
                  "default": "disabled",
                  "enum": [
                    "auto",
                    "disabled"
                  ],
                  "x-ms-enum": {
                    "modelAsString": false
                  },
                  "x-nullable": true
                },
                "input": {
                  "description": "Text, image, or file inputs to the model, used to generate a response.\n\nLearn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Image inputs](/docs/guides/images)\n- [File inputs](/docs/guides/pdf-files)\n- [Conversation state](/docs/guides/conversation-state)\n- [Function calling](/docs/guides/function-calling)"
                },
                "include": {
                  "type": "array",
                  "description": "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program).",
                  "x-nullable": true,
                  "items": {
                    "$ref": "#/definitions/OpenAI.Includable"
                  }
                },
                "parallel_tool_calls": {
                  "type": "boolean",
                  "description": "Whether to allow the model to run tool calls in parallel.",
                  "default": true,
                  "x-nullable": true
                },
                "store": {
                  "type": "boolean",
                  "description": "Whether to store the generated model response for later retrieval via\nAPI.",
                  "default": true,
                  "x-nullable": true
                },
                "instructions": {
                  "type": "string",
                  "description": "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.",
                  "x-nullable": true
                },
                "stream": {
                  "type": "boolean",
                  "description": "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](/docs/api-reference/responses-streaming)\nfor more information.",
                  "default": false,
                  "x-nullable": true
                },
                "conversation": {},
                "agent": {
                  "$ref": "#/definitions/AgentReference",
                  "description": "The agent to use for generating the response."
                },
                "structured_inputs": {
                  "type": "object",
                  "description": "The structured inputs to the response that can participate in prompt template substitution or tool argument bindings.",
                  "additionalProperties": {}
                }
              }
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/OpenAI.Response"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/ApiErrorResponse"
            }
          }
        }
      }
    },
    "/openai/responses/{response_id}": {
      "get": {
        "operationId": "getResponse",
        "tags": [
          "Responses"
        ],
        "description": "Retrieves a model response with the given ID.",
        "parameters": [
          {
            "name": "api-version",
            "in": "query",
            "description": "The API version to use for this operation.",
            "required": true,
            "type": "string",
            "minLength": 1,
            "x-ms-client-name": "apiVersion"
          },
          {
            "name": "response_id",
            "in": "path",
            "required": true,
            "type": "string"
          },
          {
            "name": "include[]",
            "in": "query",
            "required": false,
            "type": "array",
            "items": {
              "type": "string",
              "enum": [
                "code_interpreter_call.outputs",
                "computer_call_output.output.image_url",
                "file_search_call.results",
                "message.input_image.image_url",
                "message.output_text.logprobs",
                "reasoning.encrypted_content",
                "web_search_call.results",
                "web_search_call.action.sources",
                "memory_search_call.results"
              ],
              "x-ms-enum": {
                "name": "Includable",
                "modelAsString": false
              }
            },
            "collectionFormat": "multi",
            "default": [],
            "x-ms-client-name": "includables"
          },
          {
            "name": "stream",
            "in": "query",
            "required": false,
            "type": "boolean",
            "default": false
          },
          {
            "name": "starting_after",
            "in": "query",
            "required": false,
            "type": "integer",
            "format": "int32"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/OpenAI.Response"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/ApiErrorResponse"
            }
          }
        }
      },
      "delete": {
        "operationId": "deleteResponse",
        "tags": [
          "Responses"
        ],
        "description": "Deletes a model response.",
        "parameters": [
          {
            "name": "api-version",
            "in": "query",
            "description": "The API version to use for this operation.",
            "required": true,
            "type": "string",
            "minLength": 1,
            "x-ms-client-name": "apiVersion"
          },
          {
            "name": "response_id",
            "in": "path",
            "description": "The ID of the response to delete.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/DeleteResponseResult"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/ApiErrorResponse"
            }
          }
        }
      }
    },
    "/openai/responses/{response_id}/cancel": {
      "post": {
        "operationId": "cancelResponse",
        "tags": [
          "Responses"
        ],
        "description": "Cancels a model response.",
        "parameters": [
          {
            "name": "api-version",
            "in": "query",
            "description": "The API version to use for this operation.",
            "required": true,
            "type": "string",
            "minLength": 1,
            "x-ms-client-name": "apiVersion"
          },
          {
            "name": "response_id",
            "in": "path",
            "description": "The ID of the response to cancel.",
            "required": true,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/OpenAI.Response"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/ApiErrorResponse"
            }
          }
        }
      }
    },
    "/openai/responses/{response_id}/input_items": {
      "get": {
        "operationId": "listInputItems",
        "tags": [
          "Responses"
        ],
        "description": "Returns a list of input items for a given response.",
        "parameters": [
          {
            "$ref": "#/parameters/Azure.Core.Foundations.ApiVersionParameter"
          },
          {
            "name": "response_id",
            "in": "path",
            "required": true,
            "type": "string"
          },
          {
            "name": "limit",
            "in": "query",
            "description": "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the\ndefault is 20.",
            "required": false,
            "type": "integer",
            "format": "int32",
            "default": 20
          },
          {
            "name": "order",
            "in": "query",
            "description": "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`\nfor descending order.",
            "required": false,
            "type": "string",
            "enum": [
              "asc",
              "desc"
            ],
            "x-ms-enum": {
              "modelAsString": false
            }
          },
          {
            "name": "after",
            "in": "query",
            "description": "A cursor for use in pagination. `after` is an object ID that defines your place in the list.\nFor instance, if you make a list request and receive 100 objects, ending with obj_foo, your\nsubsequent call can include after=obj_foo in order to fetch the next page of the list.",
            "required": false,
            "type": "string"
          },
          {
            "name": "before",
            "in": "query",
            "description": "A cursor for use in pagination. `before` is an object ID that defines your place in the list.\nFor instance, if you make a list request and receive 100 objects, ending with obj_foo, your\nsubsequent call can include before=obj_foo in order to fetch the previous page of the list.",
            "required": false,
            "type": "string"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "type": "object",
              "description": "The response data for a requested list of items.",
              "properties": {
                "data": {
                  "type": "array",
                  "description": "The requested list of items.",
                  "items": {
                    "$ref": "#/definitions/OpenAI.ItemResource"
                  }
                },
                "first_id": {
                  "type": "string",
                  "description": "The first ID represented in this list."
                },
                "last_id": {
                  "type": "string",
                  "description": "The last ID represented in this list."
                },
                "has_more": {
                  "type": "boolean",
                  "description": "A value indicating whether there are additional values available not captured in this list."
                }
              },
              "required": [
                "data",
                "has_more"
              ]
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/ApiErrorResponse"
            }
          }
        }
      }
    }
  },
  "x-ms-paths": {
    "/openai/responses/{response_id}?_overload=getResponseStream": {
      "get": {
        "operationId": "getResponseStream",
        "tags": [
          "Responses"
        ],
        "description": "Retrieves a model response with the given ID (streaming response).",
        "produces": [
          "text/event-stream"
        ],
        "parameters": [
          {
            "name": "response_id",
            "in": "path",
            "description": "The ID of the response to retrieve.",
            "required": true,
            "type": "string"
          },
          {
            "name": "include[]",
            "in": "query",
            "required": false,
            "type": "array",
            "items": {
              "type": "string",
              "enum": [
                "code_interpreter_call.outputs",
                "computer_call_output.output.image_url",
                "file_search_call.results",
                "message.input_image.image_url",
                "message.output_text.logprobs",
                "reasoning.encrypted_content",
                "web_search_call.results",
                "web_search_call.action.sources",
                "memory_search_call.results"
              ],
              "x-ms-enum": {
                "name": "Includable",
                "modelAsString": false
              }
            },
            "collectionFormat": "multi",
            "default": [],
            "x-ms-client-name": "includables"
          },
          {
            "name": "accept",
            "in": "header",
            "required": true,
            "type": "string",
            "enum": [
              "text/event-stream"
            ],
            "x-ms-enum": {
              "modelAsString": false
            }
          },
          {
            "name": "starting_after",
            "in": "query",
            "description": "The sequence number of the event after which to start streaming.",
            "required": false,
            "type": "integer",
            "format": "int32"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
            }
          }
        }
      }
    },
    "/openai/responses?_overload=createResponseStream": {
      "post": {
        "operationId": "createResponseStream",
        "tags": [
          "Responses"
        ],
        "description": "Creates a model response (streaming response).",
        "produces": [
          "text/event-stream"
        ],
        "parameters": [
          {
            "name": "request",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/OpenAI.CreateResponse"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
            }
          }
        }
      }
    }
  },
  "definitions": {
    "AISearchIndexResource": {
      "type": "object",
      "description": "A AI Search Index resource.",
      "properties": {
        "project_connection_id": {
          "type": "string",
          "description": "An index connection ID in an IndexResource attached to this agent."
        },
        "indexName": {
          "type": "string",
          "description": "The name of an index in an IndexResource attached to this agent."
        },
        "queryType": {
          "$ref": "#/definitions/AzureAISearchQueryType",
          "description": "Type of query in an AIIndexResource attached to this agent."
        },
        "topK": {
          "type": "integer",
          "format": "int32",
          "description": "Number of documents to retrieve from search and present to the model."
        },
        "filter": {
          "type": "string",
          "description": "filter string for search resource. Learn more from here: https://learn.microsoft.com/azure/search/search-filters"
        },
        "indexAssetId": {
          "type": "string",
          "description": "Index asset id for search resource."
        }
      },
      "required": [
        "project_connection_id"
      ]
    },
    "AgentId": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": [
            "agent_id"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "name": {
          "type": "string",
          "description": "The name of the agent.",
          "maxLength": 256
        },
        "version": {
          "type": "string",
          "description": "The version identifier of the agent."
        }
      },
      "required": [
        "type",
        "name",
        "version"
      ]
    },
    "AgentReference": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": [
            "agent_reference"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "name": {
          "type": "string",
          "description": "The name of the agent.",
          "maxLength": 256
        },
        "version": {
          "type": "string",
          "description": "The version identifier of the agent."
        }
      },
      "required": [
        "type",
        "name"
      ]
    },
    "ApiError": {
      "type": "object",
      "properties": {
        "code": {
          "type": "string",
          "description": "The error code."
        },
        "message": {
          "type": "string",
          "description": "A human-readable description of the error."
        },
        "target": {
          "type": "string",
          "description": "The target of the error, if applicable."
        },
        "details": {
          "type": "array",
          "description": "Additional details about the error.",
          "items": {
            "$ref": "#/definitions/ApiError"
          }
        },
        "innererror": {
          "$ref": "#/definitions/ApiInnerError",
          "description": "The inner error, if any."
        }
      },
      "required": [
        "code",
        "message",
        "details"
      ]
    },
    "ApiErrorResponse": {
      "type": "object",
      "description": "Error response for API failures.",
      "properties": {
        "error": {
          "$ref": "#/definitions/ApiError"
        }
      },
      "required": [
        "error"
      ]
    },
    "ApiInnerError": {
      "type": "object",
      "properties": {
        "code": {
          "type": "string",
          "description": "The error code."
        },
        "innererror": {
          "$ref": "#/definitions/ApiInnerError",
          "description": "The inner error, if any."
        }
      },
      "required": [
        "code"
      ]
    },
    "AzureAISearchAgentTool": {
      "type": "object",
      "description": "The input definition information for an Azure AI search tool as used to configure an agent.",
      "properties": {
        "azure_ai_search": {
          "$ref": "#/definitions/AzureAISearchToolResource",
          "description": "The azure ai search index resource."
        }
      },
      "required": [
        "azure_ai_search"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "azure_ai_search"
    },
    "AzureAISearchQueryType": {
      "type": "string",
      "description": "Available query types for Azure AI Search tool.",
      "enum": [
        "simple",
        "semantic",
        "vector",
        "vector_simple_hybrid",
        "vector_semantic_hybrid"
      ],
      "x-ms-enum": {
        "name": "AzureAISearchQueryType",
        "modelAsString": true,
        "values": [
          {
            "name": "simple",
            "value": "simple",
            "description": "Query type `simple`"
          },
          {
            "name": "semantic",
            "value": "semantic",
            "description": "Query type `semantic`"
          },
          {
            "name": "vector",
            "value": "vector",
            "description": "Query type `vector`"
          },
          {
            "name": "vector_simple_hybrid",
            "value": "vector_simple_hybrid",
            "description": "Query type `vector_simple_hybrid`"
          },
          {
            "name": "vector_semantic_hybrid",
            "value": "vector_semantic_hybrid",
            "description": "Query type `vector_semantic_hybrid`"
          }
        ]
      }
    },
    "AzureAISearchToolResource": {
      "type": "object",
      "description": "A set of index resources used by the `azure_ai_search` tool.",
      "properties": {
        "indexes": {
          "type": "array",
          "description": "The indices attached to this agent. There can be a maximum of 1 index\nresource attached to the agent.",
          "maxItems": 1,
          "items": {
            "$ref": "#/definitions/AISearchIndexResource"
          }
        }
      }
    },
    "AzureFunctionAgentTool": {
      "type": "object",
      "description": "The input definition information for an Azure Function Tool, as used to configure an Agent.",
      "properties": {
        "azure_function": {
          "$ref": "#/definitions/AzureFunctionDefinition",
          "description": "The Azure Function Tool definition."
        }
      },
      "required": [
        "azure_function"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "azure_function"
    },
    "AzureFunctionBinding": {
      "type": "object",
      "description": "The structure for keeping storage queue name and URI.",
      "properties": {
        "type": {
          "type": "string",
          "description": "The type of binding, which is always 'storage_queue'.",
          "enum": [
            "storage_queue"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "storage_queue": {
          "$ref": "#/definitions/AzureFunctionStorageQueue",
          "description": "Storage queue."
        }
      },
      "required": [
        "type",
        "storage_queue"
      ]
    },
    "AzureFunctionDefinition": {
      "type": "object",
      "description": "The definition of Azure function.",
      "properties": {
        "function": {
          "type": "object",
          "description": "The definition of azure function and its parameters.",
          "properties": {
            "name": {
              "type": "string",
              "description": "The name of the function to be called."
            },
            "description": {
              "type": "string",
              "description": "A description of what the function does, used by the model to choose when and how to call the function."
            },
            "parameters": {
              "description": "The parameters the functions accepts, described as a JSON Schema object."
            }
          },
          "required": [
            "name",
            "parameters"
          ]
        },
        "input_binding": {
          "$ref": "#/definitions/AzureFunctionBinding",
          "description": "Input storage queue. The queue storage trigger runs a function as messages are added to it."
        },
        "output_binding": {
          "$ref": "#/definitions/AzureFunctionBinding",
          "description": "Output storage queue. The function writes output to this queue when the input items are processed."
        }
      },
      "required": [
        "function",
        "input_binding",
        "output_binding"
      ]
    },
    "AzureFunctionStorageQueue": {
      "type": "object",
      "description": "The structure for keeping storage queue name and URI.",
      "properties": {
        "queue_service_endpoint": {
          "type": "string",
          "description": "URI to the Azure Storage Queue service allowing you to manipulate a queue."
        },
        "queue_name": {
          "type": "string",
          "description": "The name of an Azure function storage queue."
        }
      },
      "required": [
        "queue_service_endpoint",
        "queue_name"
      ]
    },
    "BingCustomSearchAgentTool": {
      "type": "object",
      "description": "The input definition information for a Bing custom search tool as used to configure an agent.",
      "properties": {
        "bing_custom_search_preview": {
          "$ref": "#/definitions/BingCustomSearchToolParameters",
          "description": "The bing custom search tool parameters."
        }
      },
      "required": [
        "bing_custom_search_preview"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "bing_custom_search_preview"
    },
    "BingCustomSearchConfiguration": {
      "type": "object",
      "description": "A bing custom search configuration.",
      "properties": {
        "project_connection_id": {
          "type": "string",
          "description": "Project connection id for grounding with bing search"
        },
        "instance_name": {
          "type": "string",
          "description": "Name of the custom configuration instance given to config."
        },
        "market": {
          "type": "string",
          "description": "The market where the results come from."
        },
        "set_lang": {
          "type": "string",
          "description": "The language to use for user interface strings when calling Bing API."
        },
        "count": {
          "type": "integer",
          "format": "int64",
          "description": "The number of search results to return in the bing api response"
        },
        "freshness": {
          "type": "string",
          "description": "Filter search results by a specific time range. Accepted values: https://learn.microsoft.com/bing/search-apis/bing-web-search/reference/query-parameters"
        }
      },
      "required": [
        "project_connection_id",
        "instance_name"
      ]
    },
    "BingCustomSearchToolParameters": {
      "type": "object",
      "description": "The bing custom search tool parameters.",
      "properties": {
        "search_configurations": {
          "type": "array",
          "description": "The project connections attached to this tool. There can be a maximum of 1 connection\nresource attached to the tool.",
          "maxItems": 1,
          "items": {
            "$ref": "#/definitions/BingCustomSearchConfiguration"
          }
        }
      },
      "required": [
        "search_configurations"
      ]
    },
    "BingGroundingAgentTool": {
      "type": "object",
      "description": "The input definition information for a bing grounding search tool as used to configure an agent.",
      "properties": {
        "bing_grounding": {
          "$ref": "#/definitions/BingGroundingSearchToolParameters",
          "description": "The bing grounding search tool parameters."
        }
      },
      "required": [
        "bing_grounding"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "bing_grounding"
    },
    "BingGroundingSearchConfiguration": {
      "type": "object",
      "description": "Search configuration for Bing Grounding",
      "properties": {
        "project_connection_id": {
          "type": "string",
          "description": "Project connection id for grounding with bing search"
        },
        "market": {
          "type": "string",
          "description": "The market where the results come from."
        },
        "set_lang": {
          "type": "string",
          "description": "The language to use for user interface strings when calling Bing API."
        },
        "count": {
          "type": "integer",
          "format": "int64",
          "description": "The number of search results to return in the bing api response"
        },
        "freshness": {
          "type": "string",
          "description": "Filter search results by a specific time range. Accepted values: https://learn.microsoft.com/bing/search-apis/bing-web-search/reference/query-parameters"
        }
      },
      "required": [
        "project_connection_id"
      ]
    },
    "BingGroundingSearchToolParameters": {
      "type": "object",
      "description": "The bing grounding search tool parameters.",
      "properties": {
        "search_configurations": {
          "type": "array",
          "description": "The search configurations attached to this tool. There can be a maximum of 1\nsearch configuration resource attached to the tool.",
          "maxItems": 1,
          "items": {
            "$ref": "#/definitions/BingGroundingSearchConfiguration"
          }
        }
      },
      "required": [
        "search_configurations"
      ]
    },
    "BrowserAutomationAgentTool": {
      "type": "object",
      "description": "The input definition information for a Browser Automation Tool, as used to configure an Agent.",
      "properties": {
        "browser_automation_preview": {
          "$ref": "#/definitions/BrowserAutomationToolParameters",
          "description": "The Browser Automation Tool parameters."
        }
      },
      "required": [
        "browser_automation_preview"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "browser_automation_preview"
    },
    "BrowserAutomationToolConnectionParameters": {
      "type": "object",
      "description": "Definition of input parameters for the connection used by the Browser Automation Tool.",
      "properties": {
        "id": {
          "type": "string",
          "description": "The ID of the project connection to your Azure Playwright resource."
        }
      },
      "required": [
        "id"
      ]
    },
    "BrowserAutomationToolParameters": {
      "type": "object",
      "description": "Definition of input parameters for the Browser Automation Tool.",
      "properties": {
        "project_connection": {
          "$ref": "#/definitions/BrowserAutomationToolConnectionParameters",
          "description": "The project connection parameters associated with the Browser Automation Tool."
        }
      },
      "required": [
        "project_connection"
      ]
    },
    "CaptureStructuredOutputsTool": {
      "type": "object",
      "description": "A tool for capturing structured outputs",
      "properties": {
        "outputs": {
          "$ref": "#/definitions/StructuredOutputDefinition",
          "description": "The structured outputs to capture from the model."
        }
      },
      "required": [
        "outputs"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "capture_structured_outputs"
    },
    "CreatedBy": {
      "type": "object",
      "properties": {
        "agent": {
          "$ref": "#/definitions/AgentId",
          "description": "The agent that created the item."
        },
        "response_id": {
          "type": "string",
          "description": "The response on which the item is created."
        }
      }
    },
    "DeleteResponseResult": {
      "type": "object",
      "description": "The result of a delete response operation.",
      "properties": {
        "id": {
          "type": "string",
          "description": "The operation ID."
        },
        "object": {
          "type": "string",
          "description": "Always return 'response'.",
          "enum": [
            "response"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "deleted": {
          "type": "boolean",
          "description": "Always return true",
          "enum": [
            true
          ]
        }
      },
      "required": [
        "id",
        "object",
        "deleted"
      ]
    },
    "FabricDataAgentToolParameters": {
      "type": "object",
      "description": "The fabric data agent tool parameters.",
      "properties": {
        "project_connections": {
          "type": "array",
          "description": "The project connections attached to this tool. There can be a maximum of 1 connection\nresource attached to the tool.",
          "maxItems": 1,
          "items": {
            "$ref": "#/definitions/ToolProjectConnection"
          }
        }
      }
    },
    "InvokeAzureAgentWorkflowActionOutputItemResource": {
      "type": "object",
      "description": "Details about an agent invocation as part of a workflow action.",
      "properties": {
        "agent": {
          "$ref": "#/definitions/AgentId",
          "description": "Agent id."
        },
        "conversation_id": {
          "type": "string",
          "description": "ID of the conversation for the agent invocation."
        },
        "response_id": {
          "type": "string",
          "description": "The response id for the agent invocation."
        }
      },
      "required": [
        "agent",
        "response_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/WorkflowActionOutputItemResource"
        }
      ],
      "x-ms-discriminator-value": "InvokeAzureAgent"
    },
    "MicrosoftFabricAgentTool": {
      "type": "object",
      "description": "The input definition information for a Microsoft Fabric tool as used to configure an agent.",
      "properties": {
        "fabric_dataagent_preview": {
          "$ref": "#/definitions/FabricDataAgentToolParameters",
          "description": "The fabric data agent tool parameters."
        }
      },
      "required": [
        "fabric_dataagent_preview"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "fabric_dataagent_preview"
    },
    "OAuthConsentRequestItemResource": {
      "type": "object",
      "description": "Request from the service for the user to perform OAuth consent.",
      "properties": {
        "id": {
          "type": "string"
        },
        "consent_link": {
          "type": "string",
          "description": "The link the user can use to perform OAuth consent."
        },
        "server_label": {
          "type": "string",
          "description": "The server label for the OAuth consent request."
        }
      },
      "required": [
        "id",
        "consent_link",
        "server_label"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "oauth_consent_request"
    },
    "OpenAI.Annotation": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.AnnotationType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.AnnotationFileCitation": {
      "type": "object",
      "description": "A citation to a file.",
      "properties": {
        "file_id": {
          "type": "string",
          "description": "The ID of the file."
        },
        "index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the file in the list of files."
        },
        "filename": {
          "type": "string",
          "description": "The filename of the file cited."
        }
      },
      "required": [
        "file_id",
        "index",
        "filename"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Annotation"
        }
      ],
      "x-ms-discriminator-value": "file_citation"
    },
    "OpenAI.AnnotationFilePath": {
      "type": "object",
      "description": "A path to a file.",
      "properties": {
        "file_id": {
          "type": "string",
          "description": "The ID of the file."
        },
        "index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the file in the list of files."
        }
      },
      "required": [
        "file_id",
        "index"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Annotation"
        }
      ],
      "x-ms-discriminator-value": "file_path"
    },
    "OpenAI.AnnotationType": {
      "type": "string",
      "enum": [
        "file_citation",
        "url_citation",
        "file_path",
        "container_file_citation"
      ],
      "x-ms-enum": {
        "name": "AnnotationType",
        "modelAsString": true,
        "values": [
          {
            "name": "file_citation",
            "value": "file_citation"
          },
          {
            "name": "url_citation",
            "value": "url_citation"
          },
          {
            "name": "file_path",
            "value": "file_path"
          },
          {
            "name": "container_file_citation",
            "value": "container_file_citation"
          }
        ]
      }
    },
    "OpenAI.AnnotationUrlCitation": {
      "type": "object",
      "description": "A citation for a web resource used to generate a model response.",
      "properties": {
        "url": {
          "type": "string",
          "format": "uri",
          "description": "The URL of the web resource."
        },
        "start_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the first character of the URL citation in the message."
        },
        "end_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the last character of the URL citation in the message."
        },
        "title": {
          "type": "string",
          "description": "The title of the web resource."
        }
      },
      "required": [
        "url",
        "start_index",
        "end_index",
        "title"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Annotation"
        }
      ],
      "x-ms-discriminator-value": "url_citation"
    },
    "OpenAI.ApproximateLocation": {
      "type": "object",
      "properties": {
        "country": {
          "type": "string",
          "x-nullable": true
        },
        "region": {
          "type": "string",
          "x-nullable": true
        },
        "city": {
          "type": "string",
          "x-nullable": true
        },
        "timezone": {
          "type": "string",
          "x-nullable": true
        }
      },
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Location"
        }
      ],
      "x-ms-discriminator-value": "approximate"
    },
    "OpenAI.CodeInterpreterOutput": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.CodeInterpreterOutputType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.CodeInterpreterOutputImage": {
      "type": "object",
      "description": "The image output from the code interpreter.",
      "properties": {
        "url": {
          "type": "string",
          "format": "uri",
          "description": "The URL of the image output from the code interpreter."
        }
      },
      "required": [
        "url"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.CodeInterpreterOutput"
        }
      ],
      "x-ms-discriminator-value": "image"
    },
    "OpenAI.CodeInterpreterOutputLogs": {
      "type": "object",
      "description": "The logs output from the code interpreter.",
      "properties": {
        "logs": {
          "type": "string",
          "description": "The logs output from the code interpreter."
        }
      },
      "required": [
        "logs"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.CodeInterpreterOutput"
        }
      ],
      "x-ms-discriminator-value": "logs"
    },
    "OpenAI.CodeInterpreterOutputType": {
      "type": "string",
      "enum": [
        "logs",
        "image"
      ],
      "x-ms-enum": {
        "name": "CodeInterpreterOutputType",
        "modelAsString": false,
        "values": [
          {
            "name": "logs",
            "value": "logs"
          },
          {
            "name": "image",
            "value": "image"
          }
        ]
      }
    },
    "OpenAI.CodeInterpreterTool": {
      "type": "object",
      "description": "A tool that runs Python code to help generate a response to a prompt.",
      "properties": {
        "container": {
          "description": "The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code."
        }
      },
      "required": [
        "container"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "code_interpreter"
    },
    "OpenAI.CodeInterpreterToolCallItemParam": {
      "type": "object",
      "description": "A tool call to run code.\n",
      "properties": {
        "container_id": {
          "type": "string",
          "description": "The ID of the container used to run the code."
        },
        "code": {
          "type": "string",
          "description": "The code to run, or null if not available.",
          "x-nullable": true
        },
        "outputs": {
          "type": "array",
          "description": "The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.",
          "x-nullable": true,
          "items": {
            "$ref": "#/definitions/OpenAI.CodeInterpreterOutput"
          }
        }
      },
      "required": [
        "container_id",
        "code",
        "outputs"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "code_interpreter_call"
    },
    "OpenAI.CodeInterpreterToolCallItemResource": {
      "type": "object",
      "description": "A tool call to run code.\n",
      "properties": {
        "status": {
          "type": "string",
          "enum": [
            "in_progress",
            "completed",
            "incomplete",
            "interpreting",
            "failed"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "container_id": {
          "type": "string",
          "description": "The ID of the container used to run the code."
        },
        "code": {
          "type": "string",
          "description": "The code to run, or null if not available.",
          "x-nullable": true
        },
        "outputs": {
          "type": "array",
          "description": "The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.",
          "x-nullable": true,
          "items": {
            "$ref": "#/definitions/OpenAI.CodeInterpreterOutput"
          }
        }
      },
      "required": [
        "status",
        "container_id",
        "code",
        "outputs"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "code_interpreter_call"
    },
    "OpenAI.ComputerAction": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ComputerActionType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.ComputerActionClick": {
      "type": "object",
      "description": "A click action.",
      "properties": {
        "button": {
          "type": "string",
          "description": "Indicates which mouse button was pressed during the click. One of `left`, `right`, `wheel`, `back`, or `forward`.",
          "enum": [
            "left",
            "right",
            "wheel",
            "back",
            "forward"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "x": {
          "type": "integer",
          "format": "int32",
          "description": "The x-coordinate where the click occurred."
        },
        "y": {
          "type": "integer",
          "format": "int32",
          "description": "The y-coordinate where the click occurred."
        }
      },
      "required": [
        "button",
        "x",
        "y"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "click"
    },
    "OpenAI.ComputerActionDoubleClick": {
      "type": "object",
      "description": "A double click action.",
      "properties": {
        "x": {
          "type": "integer",
          "format": "int32",
          "description": "The x-coordinate where the double click occurred."
        },
        "y": {
          "type": "integer",
          "format": "int32",
          "description": "The y-coordinate where the double click occurred."
        }
      },
      "required": [
        "x",
        "y"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "double_click"
    },
    "OpenAI.ComputerActionDrag": {
      "type": "object",
      "description": "A drag action.",
      "properties": {
        "path": {
          "type": "array",
          "description": "An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```",
          "items": {
            "$ref": "#/definitions/OpenAI.Coordinate"
          }
        }
      },
      "required": [
        "path"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "drag"
    },
    "OpenAI.ComputerActionKeyPress": {
      "type": "object",
      "description": "A collection of keypresses the model would like to perform.",
      "properties": {
        "keys": {
          "type": "array",
          "description": "The combination of keys the model is requesting to be pressed. This is an\narray of strings, each representing a key.",
          "items": {
            "type": "string"
          }
        }
      },
      "required": [
        "keys"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "keypress"
    },
    "OpenAI.ComputerActionMove": {
      "type": "object",
      "description": "A mouse move action.",
      "properties": {
        "x": {
          "type": "integer",
          "format": "int32",
          "description": "The x-coordinate to move to."
        },
        "y": {
          "type": "integer",
          "format": "int32",
          "description": "The y-coordinate to move to."
        }
      },
      "required": [
        "x",
        "y"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "move"
    },
    "OpenAI.ComputerActionScreenshot": {
      "type": "object",
      "description": "A screenshot action.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "screenshot"
    },
    "OpenAI.ComputerActionScroll": {
      "type": "object",
      "description": "A scroll action.",
      "properties": {
        "x": {
          "type": "integer",
          "format": "int32",
          "description": "The x-coordinate where the scroll occurred."
        },
        "y": {
          "type": "integer",
          "format": "int32",
          "description": "The y-coordinate where the scroll occurred."
        },
        "scroll_x": {
          "type": "integer",
          "format": "int32",
          "description": "The horizontal scroll distance."
        },
        "scroll_y": {
          "type": "integer",
          "format": "int32",
          "description": "The vertical scroll distance."
        }
      },
      "required": [
        "x",
        "y",
        "scroll_x",
        "scroll_y"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "scroll"
    },
    "OpenAI.ComputerActionType": {
      "type": "string",
      "enum": [
        "screenshot",
        "click",
        "double_click",
        "scroll",
        "type",
        "wait",
        "keypress",
        "drag",
        "move"
      ],
      "x-ms-enum": {
        "name": "ComputerActionType",
        "modelAsString": false,
        "values": [
          {
            "name": "screenshot",
            "value": "screenshot"
          },
          {
            "name": "click",
            "value": "click"
          },
          {
            "name": "double_click",
            "value": "double_click"
          },
          {
            "name": "scroll",
            "value": "scroll"
          },
          {
            "name": "type",
            "value": "type"
          },
          {
            "name": "wait",
            "value": "wait"
          },
          {
            "name": "keypress",
            "value": "keypress"
          },
          {
            "name": "drag",
            "value": "drag"
          },
          {
            "name": "move",
            "value": "move"
          }
        ]
      }
    },
    "OpenAI.ComputerActionTypeKeys": {
      "type": "object",
      "description": "An action to type in text.",
      "properties": {
        "text": {
          "type": "string",
          "description": "The text to type."
        }
      },
      "required": [
        "text"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "type"
    },
    "OpenAI.ComputerActionWait": {
      "type": "object",
      "description": "A wait action.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        }
      ],
      "x-ms-discriminator-value": "wait"
    },
    "OpenAI.ComputerToolCallItemParam": {
      "type": "object",
      "description": "A tool call to a computer use tool. See the\n[computer use guide](/docs/guides/tools-computer-use) for more information.\n",
      "properties": {
        "call_id": {
          "type": "string",
          "description": "An identifier used when responding to the tool call with output."
        },
        "action": {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        },
        "pending_safety_checks": {
          "type": "array",
          "description": "The pending safety checks for the computer call.",
          "items": {
            "$ref": "#/definitions/OpenAI.ComputerToolCallSafetyCheck"
          }
        }
      },
      "required": [
        "call_id",
        "action",
        "pending_safety_checks"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "computer_call"
    },
    "OpenAI.ComputerToolCallItemResource": {
      "type": "object",
      "description": "A tool call to a computer use tool. See the\n[computer use guide](/docs/guides/tools-computer-use) for more information.\n",
      "properties": {
        "status": {
          "type": "string",
          "description": "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.",
          "enum": [
            "in_progress",
            "completed",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "call_id": {
          "type": "string",
          "description": "An identifier used when responding to the tool call with output."
        },
        "action": {
          "$ref": "#/definitions/OpenAI.ComputerAction"
        },
        "pending_safety_checks": {
          "type": "array",
          "description": "The pending safety checks for the computer call.",
          "items": {
            "$ref": "#/definitions/OpenAI.ComputerToolCallSafetyCheck"
          }
        }
      },
      "required": [
        "status",
        "call_id",
        "action",
        "pending_safety_checks"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "computer_call"
    },
    "OpenAI.ComputerToolCallOutputItemOutput": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ComputerToolCallOutputItemOutputType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.ComputerToolCallOutputItemOutputComputerScreenshot": {
      "type": "object",
      "properties": {
        "image_url": {
          "type": "string"
        },
        "file_id": {
          "type": "string"
        }
      },
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ComputerToolCallOutputItemOutput"
        }
      ],
      "x-ms-discriminator-value": "computer_screenshot"
    },
    "OpenAI.ComputerToolCallOutputItemOutputType": {
      "type": "string",
      "description": "A computer screenshot image used with the computer use tool.",
      "enum": [
        "computer_screenshot"
      ],
      "x-ms-enum": {
        "name": "ComputerToolCallOutputItemOutputType",
        "modelAsString": true,
        "values": [
          {
            "name": "screenshot",
            "value": "computer_screenshot"
          }
        ]
      }
    },
    "OpenAI.ComputerToolCallOutputItemParam": {
      "type": "object",
      "description": "The output of a computer tool call.\n",
      "properties": {
        "call_id": {
          "type": "string",
          "description": "The ID of the computer tool call that produced the output."
        },
        "acknowledged_safety_checks": {
          "type": "array",
          "description": "The safety checks reported by the API that have been acknowledged by the\ndeveloper.",
          "items": {
            "$ref": "#/definitions/OpenAI.ComputerToolCallSafetyCheck"
          }
        },
        "output": {
          "$ref": "#/definitions/OpenAI.ComputerToolCallOutputItemOutput"
        }
      },
      "required": [
        "call_id",
        "output"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "computer_call_output"
    },
    "OpenAI.ComputerToolCallOutputItemResource": {
      "type": "object",
      "description": "The output of a computer tool call.\n",
      "properties": {
        "status": {
          "type": "string",
          "description": "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.",
          "enum": [
            "in_progress",
            "completed",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "call_id": {
          "type": "string",
          "description": "The ID of the computer tool call that produced the output."
        },
        "acknowledged_safety_checks": {
          "type": "array",
          "description": "The safety checks reported by the API that have been acknowledged by the\ndeveloper.",
          "items": {
            "$ref": "#/definitions/OpenAI.ComputerToolCallSafetyCheck"
          }
        },
        "output": {
          "$ref": "#/definitions/OpenAI.ComputerToolCallOutputItemOutput"
        }
      },
      "required": [
        "status",
        "call_id",
        "output"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "computer_call_output"
    },
    "OpenAI.ComputerToolCallSafetyCheck": {
      "type": "object",
      "description": "A pending safety check for the computer call.",
      "properties": {
        "id": {
          "type": "string",
          "description": "The ID of the pending safety check."
        },
        "code": {
          "type": "string",
          "description": "The type of the pending safety check."
        },
        "message": {
          "type": "string",
          "description": "Details about the pending safety check."
        }
      },
      "required": [
        "id",
        "code",
        "message"
      ]
    },
    "OpenAI.ComputerUsePreviewTool": {
      "type": "object",
      "description": "A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).",
      "properties": {
        "environment": {
          "type": "string",
          "description": "The type of computer environment to control.",
          "enum": [
            "windows",
            "mac",
            "linux",
            "ubuntu",
            "browser"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "display_width": {
          "type": "integer",
          "format": "int32",
          "description": "The width of the computer display."
        },
        "display_height": {
          "type": "integer",
          "format": "int32",
          "description": "The height of the computer display."
        }
      },
      "required": [
        "environment",
        "display_width",
        "display_height"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "computer_use_preview"
    },
    "OpenAI.Coordinate": {
      "type": "object",
      "description": "An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.",
      "properties": {
        "x": {
          "type": "integer",
          "format": "int32",
          "description": "The x-coordinate."
        },
        "y": {
          "type": "integer",
          "format": "int32",
          "description": "The y-coordinate."
        }
      },
      "required": [
        "x",
        "y"
      ]
    },
    "OpenAI.CreateResponse": {
      "type": "object",
      "properties": {
        "metadata": {
          "type": "object",
          "description": "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.",
          "additionalProperties": {
            "type": "string"
          },
          "x-oaiTypeLabel": "map"
        },
        "temperature": {
          "type": "number",
          "format": "float",
          "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.",
          "default": 1,
          "x-nullable": true
        },
        "top_p": {
          "type": "number",
          "format": "float",
          "description": "An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.",
          "default": 1,
          "x-nullable": true
        },
        "user": {
          "type": "string",
          "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)."
        },
        "service_tier": {
          "$ref": "#/definitions/OpenAI.ServiceTier",
          "description": "Note: service_tier is not applicable to Azure OpenAI."
        },
        "top_logprobs": {
          "type": "integer",
          "format": "int32",
          "description": "An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.",
          "minimum": 0,
          "maximum": 20
        },
        "previous_response_id": {
          "type": "string",
          "description": "The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](/docs/guides/conversation-state).",
          "x-nullable": true
        },
        "model": {
          "type": "string",
          "description": "The model deployment to use for the creation of this response."
        },
        "reasoning": {
          "$ref": "#/definitions/OpenAI.Reasoning",
          "x-nullable": true
        },
        "background": {
          "type": "boolean",
          "description": "Whether to run the model response in the background.\n[Learn more](/docs/guides/background).",
          "default": false,
          "x-nullable": true
        },
        "max_output_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).",
          "x-nullable": true
        },
        "max_tool_calls": {
          "type": "integer",
          "format": "int32",
          "description": "The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.",
          "x-nullable": true
        },
        "text": {
          "type": "object",
          "description": "Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Structured Outputs](/docs/guides/structured-outputs)",
          "properties": {
            "format": {
              "$ref": "#/definitions/OpenAI.ResponseTextFormatConfiguration"
            }
          }
        },
        "tools": {
          "type": "array",
          "description": "An array of tools the model may call while generating a response. You \ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like file search.\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code.",
          "items": {
            "$ref": "#/definitions/OpenAI.Tool"
          }
        },
        "tool_choice": {
          "description": "How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call."
        },
        "prompt": {
          "$ref": "#/definitions/OpenAI.Prompt",
          "x-nullable": true
        },
        "truncation": {
          "type": "string",
          "description": "The truncation strategy to use for the model response.\n- `auto`: If the context of this response and previous ones exceeds\n  the model's context window size, the model will truncate the\n  response to fit the context window by dropping input items in the\n  middle of the conversation.\n- `disabled` (default): If a model response will exceed the context window\n  size for a model, the request will fail with a 400 error.",
          "default": "disabled",
          "enum": [
            "auto",
            "disabled"
          ],
          "x-ms-enum": {
            "modelAsString": false
          },
          "x-nullable": true
        },
        "input": {
          "description": "Text, image, or file inputs to the model, used to generate a response.\n\nLearn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Image inputs](/docs/guides/images)\n- [File inputs](/docs/guides/pdf-files)\n- [Conversation state](/docs/guides/conversation-state)\n- [Function calling](/docs/guides/function-calling)"
        },
        "include": {
          "type": "array",
          "description": "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program).",
          "x-nullable": true,
          "items": {
            "$ref": "#/definitions/OpenAI.Includable"
          }
        },
        "parallel_tool_calls": {
          "type": "boolean",
          "description": "Whether to allow the model to run tool calls in parallel.",
          "default": true,
          "x-nullable": true
        },
        "store": {
          "type": "boolean",
          "description": "Whether to store the generated model response for later retrieval via\nAPI.",
          "default": true,
          "x-nullable": true
        },
        "instructions": {
          "type": "string",
          "description": "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.",
          "x-nullable": true
        },
        "stream": {
          "type": "boolean",
          "description": "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](/docs/api-reference/responses-streaming)\nfor more information.",
          "default": false,
          "x-nullable": true
        },
        "conversation": {},
        "agent": {
          "$ref": "#/definitions/AgentReference",
          "description": "The agent to use for generating the response."
        },
        "structured_inputs": {
          "type": "object",
          "description": "The structured inputs to the response that can participate in prompt template substitution or tool argument bindings.",
          "additionalProperties": {}
        }
      }
    },
    "OpenAI.FileSearchTool": {
      "type": "object",
      "description": "A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).",
      "properties": {
        "vector_store_ids": {
          "type": "array",
          "description": "The IDs of the vector stores to search.",
          "items": {
            "type": "string"
          }
        },
        "max_num_results": {
          "type": "integer",
          "format": "int32",
          "description": "The maximum number of results to return. This number should be between 1 and 50 inclusive."
        },
        "ranking_options": {
          "$ref": "#/definitions/OpenAI.RankingOptions",
          "description": "Ranking options for search."
        },
        "filters": {
          "$ref": "#/definitions/OpenAI.Filters",
          "description": "A filter to apply.",
          "x-nullable": true
        }
      },
      "required": [
        "vector_store_ids"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "file_search"
    },
    "OpenAI.FileSearchToolCallItemParam": {
      "type": "object",
      "description": "The results of a file search tool call. See the\n[file search guide](/docs/guides/tools-file-search) for more information.\n",
      "properties": {
        "queries": {
          "type": "array",
          "description": "The queries used to search for files.",
          "items": {
            "type": "string"
          }
        },
        "results": {
          "type": "array",
          "description": "The results of the file search tool call.",
          "x-nullable": true,
          "items": {
            "type": "object",
            "properties": {
              "file_id": {
                "type": "string",
                "description": "The unique ID of the file."
              },
              "text": {
                "type": "string",
                "description": "The text that was retrieved from the file."
              },
              "filename": {
                "type": "string",
                "description": "The name of the file."
              },
              "attributes": {
                "$ref": "#/definitions/OpenAI.VectorStoreFileAttributes"
              },
              "score": {
                "type": "number",
                "format": "float",
                "description": "The relevance score of the file - a value between 0 and 1."
              }
            }
          }
        }
      },
      "required": [
        "queries"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "file_search_call"
    },
    "OpenAI.FileSearchToolCallItemResource": {
      "type": "object",
      "description": "The results of a file search tool call. See the\n[file search guide](/docs/guides/tools-file-search) for more information.\n",
      "properties": {
        "status": {
          "type": "string",
          "description": "The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,",
          "enum": [
            "in_progress",
            "searching",
            "completed",
            "incomplete",
            "failed"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "queries": {
          "type": "array",
          "description": "The queries used to search for files.",
          "items": {
            "type": "string"
          }
        },
        "results": {
          "type": "array",
          "description": "The results of the file search tool call.",
          "x-nullable": true,
          "items": {
            "type": "object",
            "properties": {
              "file_id": {
                "type": "string",
                "description": "The unique ID of the file."
              },
              "text": {
                "type": "string",
                "description": "The text that was retrieved from the file."
              },
              "filename": {
                "type": "string",
                "description": "The name of the file."
              },
              "attributes": {
                "$ref": "#/definitions/OpenAI.VectorStoreFileAttributes"
              },
              "score": {
                "type": "number",
                "format": "float",
                "description": "The relevance score of the file - a value between 0 and 1."
              }
            }
          }
        }
      },
      "required": [
        "status",
        "queries"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "file_search_call"
    },
    "OpenAI.Filters": {},
    "OpenAI.FunctionTool": {
      "type": "object",
      "description": "Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).",
      "properties": {
        "name": {
          "type": "string",
          "description": "The name of the function to call."
        },
        "description": {
          "type": "string",
          "description": "A description of the function. Used by the model to determine whether or not to call the function.",
          "x-nullable": true
        },
        "parameters": {
          "description": "A JSON schema object describing the parameters of the function.",
          "x-nullable": true
        },
        "strict": {
          "type": "boolean",
          "description": "Whether to enforce strict parameter validation. Default `true`.",
          "x-nullable": true
        }
      },
      "required": [
        "name",
        "parameters",
        "strict"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "function"
    },
    "OpenAI.FunctionToolCallItemParam": {
      "type": "object",
      "description": "A tool call to run a function. See the\n[function calling guide](/docs/guides/function-calling) for more information.\n",
      "properties": {
        "call_id": {
          "type": "string",
          "description": "The unique ID of the function tool call generated by the model."
        },
        "name": {
          "type": "string",
          "description": "The name of the function to run."
        },
        "arguments": {
          "type": "string",
          "description": "A JSON string of the arguments to pass to the function."
        }
      },
      "required": [
        "call_id",
        "name",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "function_call"
    },
    "OpenAI.FunctionToolCallItemResource": {
      "type": "object",
      "description": "A tool call to run a function. See the\n[function calling guide](/docs/guides/function-calling) for more information.\n",
      "properties": {
        "status": {
          "type": "string",
          "description": "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.",
          "enum": [
            "in_progress",
            "completed",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "call_id": {
          "type": "string",
          "description": "The unique ID of the function tool call generated by the model."
        },
        "name": {
          "type": "string",
          "description": "The name of the function to run."
        },
        "arguments": {
          "type": "string",
          "description": "A JSON string of the arguments to pass to the function."
        }
      },
      "required": [
        "status",
        "call_id",
        "name",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "function_call"
    },
    "OpenAI.FunctionToolCallOutputItemParam": {
      "type": "object",
      "description": "The output of a function tool call.\n",
      "properties": {
        "call_id": {
          "type": "string",
          "description": "The unique ID of the function tool call generated by the model."
        },
        "output": {
          "type": "string",
          "description": "A JSON string of the output of the function tool call."
        }
      },
      "required": [
        "call_id",
        "output"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "function_call_output"
    },
    "OpenAI.FunctionToolCallOutputItemResource": {
      "type": "object",
      "description": "The output of a function tool call.\n",
      "properties": {
        "status": {
          "type": "string",
          "description": "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.",
          "enum": [
            "in_progress",
            "completed",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "call_id": {
          "type": "string",
          "description": "The unique ID of the function tool call generated by the model."
        },
        "output": {
          "type": "string",
          "description": "A JSON string of the output of the function tool call."
        }
      },
      "required": [
        "status",
        "call_id",
        "output"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "function_call_output"
    },
    "OpenAI.ImageGenTool": {
      "type": "object",
      "description": "A tool that generates images using a model like `gpt-image-1`.",
      "properties": {
        "model": {
          "type": "string",
          "description": "The image generation model to use. Default: `gpt-image-1`.",
          "default": "gpt-image-1",
          "enum": [
            "gpt-image-1"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "quality": {
          "type": "string",
          "description": "The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.",
          "default": "auto",
          "enum": [
            "low",
            "medium",
            "high",
            "auto"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "size": {
          "type": "string",
          "description": "The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.",
          "default": "auto",
          "enum": [
            "1024x1024",
            "1024x1536",
            "1536x1024",
            "auto"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "output_format": {
          "type": "string",
          "description": "The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.",
          "default": "png",
          "enum": [
            "png",
            "webp",
            "jpeg"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "output_compression": {
          "type": "integer",
          "format": "int32",
          "description": "Compression level for the output image. Default: 100.",
          "default": 100,
          "minimum": 0,
          "maximum": 100
        },
        "moderation": {
          "type": "string",
          "description": "Moderation level for the generated image. Default: `auto`.",
          "default": "auto",
          "enum": [
            "auto",
            "low"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "background": {
          "type": "string",
          "description": "Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.",
          "default": "auto",
          "enum": [
            "transparent",
            "opaque",
            "auto"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "input_image_mask": {
          "type": "object",
          "description": "Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).",
          "properties": {
            "image_url": {
              "type": "string",
              "description": "Base64-encoded mask image."
            },
            "file_id": {
              "type": "string",
              "description": "File ID for the mask image."
            }
          }
        },
        "partial_images": {
          "type": "integer",
          "format": "int32",
          "description": "Number of partial images to generate in streaming mode, from 0 (default value) to 3.",
          "default": 0,
          "minimum": 0,
          "maximum": 3
        }
      },
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "image_generation"
    },
    "OpenAI.ImageGenToolCallItemParam": {
      "type": "object",
      "description": "An image generation request made by the model.\n",
      "properties": {
        "result": {
          "type": "string",
          "description": "The generated image encoded in base64.",
          "x-nullable": true
        }
      },
      "required": [
        "result"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "image_generation_call"
    },
    "OpenAI.ImageGenToolCallItemResource": {
      "type": "object",
      "description": "An image generation request made by the model.\n",
      "properties": {
        "status": {
          "type": "string",
          "enum": [
            "in_progress",
            "completed",
            "generating",
            "failed"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "result": {
          "type": "string",
          "description": "The generated image encoded in base64.",
          "x-nullable": true
        }
      },
      "required": [
        "status",
        "result"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "image_generation_call"
    },
    "OpenAI.Includable": {
      "type": "string",
      "description": "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program).",
      "enum": [
        "code_interpreter_call.outputs",
        "computer_call_output.output.image_url",
        "file_search_call.results",
        "message.input_image.image_url",
        "message.output_text.logprobs",
        "reasoning.encrypted_content",
        "web_search_call.results",
        "web_search_call.action.sources",
        "memory_search_call.results"
      ],
      "x-ms-enum": {
        "name": "Includable",
        "modelAsString": false
      }
    },
    "OpenAI.ItemContent": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ItemContentType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.ItemContentInputAudio": {
      "type": "object",
      "description": "An audio input to the model.",
      "properties": {
        "data": {
          "type": "string",
          "description": "Base64-encoded audio data."
        },
        "format": {
          "type": "string",
          "description": "The format of the audio data. Currently supported formats are `mp3` and\n`wav`.",
          "enum": [
            "mp3",
            "wav"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        }
      },
      "required": [
        "data",
        "format"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemContent"
        }
      ],
      "x-ms-discriminator-value": "input_audio"
    },
    "OpenAI.ItemContentInputFile": {
      "type": "object",
      "description": "A file input to the model.",
      "properties": {
        "file_id": {
          "type": "string",
          "description": "The ID of the file to be sent to the model.",
          "x-nullable": true
        },
        "filename": {
          "type": "string",
          "description": "The name of the file to be sent to the model."
        },
        "file_data": {
          "type": "string",
          "description": "The content of the file to be sent to the model."
        }
      },
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemContent"
        }
      ],
      "x-ms-discriminator-value": "input_file"
    },
    "OpenAI.ItemContentInputImage": {
      "type": "object",
      "description": "An image input to the model. Learn about [image inputs](/docs/guides/vision).",
      "properties": {
        "image_url": {
          "type": "string",
          "description": "The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.",
          "x-nullable": true
        },
        "file_id": {
          "type": "string",
          "description": "The ID of the file to be sent to the model.",
          "x-nullable": true
        },
        "detail": {
          "type": "string",
          "description": "The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.",
          "default": "auto",
          "enum": [
            "low",
            "high",
            "auto"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        }
      },
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemContent"
        }
      ],
      "x-ms-discriminator-value": "input_image"
    },
    "OpenAI.ItemContentInputText": {
      "type": "object",
      "description": "A text input to the model.",
      "properties": {
        "text": {
          "type": "string",
          "description": "The text input to the model."
        }
      },
      "required": [
        "text"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemContent"
        }
      ],
      "x-ms-discriminator-value": "input_text"
    },
    "OpenAI.ItemContentOutputAudio": {
      "type": "object",
      "description": "An audio output from the model.",
      "properties": {
        "data": {
          "type": "string",
          "description": "Base64-encoded audio data from the model."
        },
        "transcript": {
          "type": "string",
          "description": "The transcript of the audio data from the model."
        }
      },
      "required": [
        "data",
        "transcript"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemContent"
        }
      ],
      "x-ms-discriminator-value": "output_audio"
    },
    "OpenAI.ItemContentOutputText": {
      "type": "object",
      "description": "A text output from the model.",
      "properties": {
        "text": {
          "type": "string",
          "description": "The text output from the model."
        },
        "annotations": {
          "type": "array",
          "description": "The annotations of the text output.",
          "items": {
            "$ref": "#/definitions/OpenAI.Annotation"
          }
        },
        "logprobs": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/OpenAI.LogProb"
          }
        }
      },
      "required": [
        "text",
        "annotations"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemContent"
        }
      ],
      "x-ms-discriminator-value": "output_text"
    },
    "OpenAI.ItemContentRefusal": {
      "type": "object",
      "description": "A refusal from the model.",
      "properties": {
        "refusal": {
          "type": "string",
          "description": "The refusal explanationfrom the model."
        }
      },
      "required": [
        "refusal"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemContent"
        }
      ],
      "x-ms-discriminator-value": "refusal"
    },
    "OpenAI.ItemContentType": {
      "type": "string",
      "description": "Multi-modal input and output contents.",
      "enum": [
        "input_text",
        "input_audio",
        "input_image",
        "input_file",
        "output_text",
        "output_audio",
        "refusal"
      ],
      "x-ms-enum": {
        "name": "ItemContentType",
        "modelAsString": false,
        "values": [
          {
            "name": "input_text",
            "value": "input_text"
          },
          {
            "name": "input_audio",
            "value": "input_audio"
          },
          {
            "name": "input_image",
            "value": "input_image"
          },
          {
            "name": "input_file",
            "value": "input_file"
          },
          {
            "name": "output_text",
            "value": "output_text"
          },
          {
            "name": "output_audio",
            "value": "output_audio"
          },
          {
            "name": "refusal",
            "value": "refusal"
          }
        ]
      }
    },
    "OpenAI.ItemParam": {
      "type": "object",
      "description": "Content item used to generate a response.",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ItemType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.ItemReferenceItemParam": {
      "type": "object",
      "description": "An internal identifier for an item to reference.",
      "properties": {
        "id": {
          "type": "string",
          "description": "The service-originated ID of the previously generated response item being referenced."
        }
      },
      "required": [
        "id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "item_reference"
    },
    "OpenAI.ItemResource": {
      "type": "object",
      "description": "Content item used to generate a response.",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ItemType"
        },
        "id": {
          "type": "string"
        },
        "created_by": {
          "$ref": "#/definitions/CreatedBy",
          "description": "The information about the creator of the item"
        }
      },
      "discriminator": "type",
      "required": [
        "type",
        "id"
      ]
    },
    "OpenAI.ItemType": {
      "type": "string",
      "enum": [
        "message",
        "file_search_call",
        "function_call",
        "function_call_output",
        "computer_call",
        "computer_call_output",
        "web_search_call",
        "reasoning",
        "item_reference",
        "image_generation_call",
        "code_interpreter_call",
        "local_shell_call",
        "local_shell_call_output",
        "mcp_list_tools",
        "mcp_approval_request",
        "mcp_approval_response",
        "mcp_call",
        "structured_outputs",
        "workflow_action",
        "memory_search_call",
        "oauth_consent_request"
      ],
      "x-ms-enum": {
        "name": "ItemType",
        "modelAsString": true,
        "values": [
          {
            "name": "message",
            "value": "message"
          },
          {
            "name": "file_search_call",
            "value": "file_search_call"
          },
          {
            "name": "function_call",
            "value": "function_call"
          },
          {
            "name": "function_call_output",
            "value": "function_call_output"
          },
          {
            "name": "computer_call",
            "value": "computer_call"
          },
          {
            "name": "computer_call_output",
            "value": "computer_call_output"
          },
          {
            "name": "web_search_call",
            "value": "web_search_call"
          },
          {
            "name": "reasoning",
            "value": "reasoning"
          },
          {
            "name": "item_reference",
            "value": "item_reference"
          },
          {
            "name": "image_generation_call",
            "value": "image_generation_call"
          },
          {
            "name": "code_interpreter_call",
            "value": "code_interpreter_call"
          },
          {
            "name": "local_shell_call",
            "value": "local_shell_call"
          },
          {
            "name": "local_shell_call_output",
            "value": "local_shell_call_output"
          },
          {
            "name": "mcp_list_tools",
            "value": "mcp_list_tools"
          },
          {
            "name": "mcp_approval_request",
            "value": "mcp_approval_request"
          },
          {
            "name": "mcp_approval_response",
            "value": "mcp_approval_response"
          },
          {
            "name": "mcp_call",
            "value": "mcp_call"
          },
          {
            "name": "structured_outputs",
            "value": "structured_outputs"
          },
          {
            "name": "workflow_action",
            "value": "workflow_action"
          },
          {
            "name": "memory_search_call",
            "value": "memory_search_call"
          },
          {
            "name": "oauth_consent_request",
            "value": "oauth_consent_request"
          }
        ]
      }
    },
    "OpenAI.LocalShellExecAction": {
      "type": "object",
      "description": "Execute a shell command on the server.",
      "properties": {
        "type": {
          "type": "string",
          "description": "The type of the local shell action. Always `exec`.",
          "enum": [
            "exec"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "command": {
          "type": "array",
          "description": "The command to run.",
          "items": {
            "type": "string"
          }
        },
        "timeout_ms": {
          "type": "integer",
          "format": "int32",
          "description": "Optional timeout in milliseconds for the command.",
          "x-nullable": true
        },
        "working_directory": {
          "type": "string",
          "description": "Optional working directory to run the command in.",
          "x-nullable": true
        },
        "env": {
          "type": "object",
          "description": "Environment variables to set for the command.",
          "additionalProperties": {
            "type": "string"
          }
        },
        "user": {
          "type": "string",
          "description": "Optional user to run the command as.",
          "x-nullable": true
        }
      },
      "required": [
        "type",
        "command",
        "env"
      ]
    },
    "OpenAI.LocalShellTool": {
      "type": "object",
      "description": "A tool that allows the model to execute shell commands in a local environment.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "local_shell"
    },
    "OpenAI.LocalShellToolCallItemParam": {
      "type": "object",
      "description": "A tool call to run a command on the local shell.\n",
      "properties": {
        "call_id": {
          "type": "string",
          "description": "The unique ID of the local shell tool call generated by the model."
        },
        "action": {
          "$ref": "#/definitions/OpenAI.LocalShellExecAction"
        }
      },
      "required": [
        "call_id",
        "action"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "local_shell_call"
    },
    "OpenAI.LocalShellToolCallItemResource": {
      "type": "object",
      "description": "A tool call to run a command on the local shell.\n",
      "properties": {
        "status": {
          "type": "string",
          "enum": [
            "in_progress",
            "completed",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "call_id": {
          "type": "string",
          "description": "The unique ID of the local shell tool call generated by the model."
        },
        "action": {
          "$ref": "#/definitions/OpenAI.LocalShellExecAction"
        }
      },
      "required": [
        "status",
        "call_id",
        "action"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "local_shell_call"
    },
    "OpenAI.LocalShellToolCallOutputItemParam": {
      "type": "object",
      "description": "The output of a local shell tool call.\n",
      "properties": {
        "output": {
          "type": "string",
          "description": "A JSON string of the output of the local shell tool call."
        }
      },
      "required": [
        "output"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "local_shell_call_output"
    },
    "OpenAI.LocalShellToolCallOutputItemResource": {
      "type": "object",
      "description": "The output of a local shell tool call.\n",
      "properties": {
        "status": {
          "type": "string",
          "enum": [
            "in_progress",
            "completed",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "output": {
          "type": "string",
          "description": "A JSON string of the output of the local shell tool call."
        }
      },
      "required": [
        "status",
        "output"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "local_shell_call_output"
    },
    "OpenAI.Location": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.LocationType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.LocationType": {
      "type": "string",
      "enum": [
        "approximate"
      ],
      "x-ms-enum": {
        "name": "LocationType",
        "modelAsString": true,
        "values": [
          {
            "name": "approximate",
            "value": "approximate"
          }
        ]
      }
    },
    "OpenAI.LogProb": {
      "type": "object",
      "description": "The log probability of a token.",
      "properties": {
        "token": {
          "type": "string"
        },
        "logprob": {
          "type": "number",
          "format": "float"
        },
        "bytes": {
          "type": "array",
          "items": {
            "type": "integer",
            "format": "int32"
          }
        },
        "top_logprobs": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/OpenAI.TopLogProb"
          }
        }
      },
      "required": [
        "token",
        "logprob",
        "bytes",
        "top_logprobs"
      ]
    },
    "OpenAI.MCPApprovalRequestItemParam": {
      "type": "object",
      "description": "A request for human approval of a tool invocation.\n",
      "properties": {
        "server_label": {
          "type": "string",
          "description": "The label of the MCP server making the request."
        },
        "name": {
          "type": "string",
          "description": "The name of the tool to run."
        },
        "arguments": {
          "type": "string",
          "description": "A JSON string of arguments for the tool."
        }
      },
      "required": [
        "server_label",
        "name",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "mcp_approval_request"
    },
    "OpenAI.MCPApprovalRequestItemResource": {
      "type": "object",
      "description": "A request for human approval of a tool invocation.\n",
      "properties": {
        "server_label": {
          "type": "string",
          "description": "The label of the MCP server making the request."
        },
        "name": {
          "type": "string",
          "description": "The name of the tool to run."
        },
        "arguments": {
          "type": "string",
          "description": "A JSON string of arguments for the tool."
        }
      },
      "required": [
        "server_label",
        "name",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "mcp_approval_request"
    },
    "OpenAI.MCPApprovalResponseItemParam": {
      "type": "object",
      "description": "A response to an MCP approval request.\n",
      "properties": {
        "approval_request_id": {
          "type": "string",
          "description": "The ID of the approval request being answered."
        },
        "approve": {
          "type": "boolean",
          "description": "Whether the request was approved."
        },
        "reason": {
          "type": "string",
          "description": "Optional reason for the decision.",
          "x-nullable": true
        }
      },
      "required": [
        "approval_request_id",
        "approve"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "mcp_approval_response"
    },
    "OpenAI.MCPApprovalResponseItemResource": {
      "type": "object",
      "description": "A response to an MCP approval request.\n",
      "properties": {
        "approval_request_id": {
          "type": "string",
          "description": "The ID of the approval request being answered."
        },
        "approve": {
          "type": "boolean",
          "description": "Whether the request was approved."
        },
        "reason": {
          "type": "string",
          "description": "Optional reason for the decision.",
          "x-nullable": true
        }
      },
      "required": [
        "approval_request_id",
        "approve"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "mcp_approval_response"
    },
    "OpenAI.MCPCallItemParam": {
      "type": "object",
      "description": "An invocation of a tool on an MCP server.\n",
      "properties": {
        "server_label": {
          "type": "string",
          "description": "The label of the MCP server running the tool."
        },
        "name": {
          "type": "string",
          "description": "The name of the tool that was run."
        },
        "arguments": {
          "type": "string",
          "description": "A JSON string of the arguments passed to the tool."
        },
        "output": {
          "type": "string",
          "description": "The output from the tool call.",
          "x-nullable": true
        },
        "error": {
          "type": "string",
          "description": "The error from the tool call, if any.",
          "x-nullable": true
        }
      },
      "required": [
        "server_label",
        "name",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "mcp_call"
    },
    "OpenAI.MCPCallItemResource": {
      "type": "object",
      "description": "An invocation of a tool on an MCP server.\n",
      "properties": {
        "server_label": {
          "type": "string",
          "description": "The label of the MCP server running the tool."
        },
        "name": {
          "type": "string",
          "description": "The name of the tool that was run."
        },
        "arguments": {
          "type": "string",
          "description": "A JSON string of the arguments passed to the tool."
        },
        "output": {
          "type": "string",
          "description": "The output from the tool call.",
          "x-nullable": true
        },
        "error": {
          "type": "string",
          "description": "The error from the tool call, if any.",
          "x-nullable": true
        }
      },
      "required": [
        "server_label",
        "name",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "mcp_call"
    },
    "OpenAI.MCPListToolsItemParam": {
      "type": "object",
      "description": "A list of tools available on an MCP server.\n",
      "properties": {
        "server_label": {
          "type": "string",
          "description": "The label of the MCP server."
        },
        "tools": {
          "type": "array",
          "description": "The tools available on the server.",
          "items": {
            "$ref": "#/definitions/OpenAI.MCPListToolsTool"
          }
        },
        "error": {
          "type": "string",
          "description": "Error message if the server could not list tools.",
          "x-nullable": true
        }
      },
      "required": [
        "server_label",
        "tools"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "mcp_list_tools"
    },
    "OpenAI.MCPListToolsItemResource": {
      "type": "object",
      "description": "A list of tools available on an MCP server.\n",
      "properties": {
        "server_label": {
          "type": "string",
          "description": "The label of the MCP server."
        },
        "tools": {
          "type": "array",
          "description": "The tools available on the server.",
          "items": {
            "$ref": "#/definitions/OpenAI.MCPListToolsTool"
          }
        },
        "error": {
          "type": "string",
          "description": "Error message if the server could not list tools.",
          "x-nullable": true
        }
      },
      "required": [
        "server_label",
        "tools"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "mcp_list_tools"
    },
    "OpenAI.MCPListToolsTool": {
      "type": "object",
      "description": "A tool available on an MCP server.",
      "properties": {
        "name": {
          "type": "string",
          "description": "The name of the tool."
        },
        "description": {
          "type": "string",
          "description": "The description of the tool.",
          "x-nullable": true
        },
        "input_schema": {
          "description": "The JSON schema describing the tool's input."
        },
        "annotations": {
          "description": "Additional annotations about the tool.",
          "x-nullable": true
        }
      },
      "required": [
        "name",
        "input_schema"
      ]
    },
    "OpenAI.MCPTool": {
      "type": "object",
      "description": "Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](/docs/guides/tools-remote-mcp).",
      "properties": {
        "server_label": {
          "type": "string",
          "description": "A label for this MCP server, used to identify it in tool calls."
        },
        "server_url": {
          "type": "string",
          "description": "The URL for the MCP server."
        },
        "headers": {
          "type": "object",
          "description": "Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.",
          "x-nullable": true,
          "additionalProperties": {
            "type": "string"
          }
        },
        "allowed_tools": {
          "description": "List of allowed tool names or a filter object."
        },
        "require_approval": {
          "description": "Specify which of the MCP server's tools require approval.",
          "default": "always"
        }
      },
      "required": [
        "server_label",
        "server_url"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "mcp"
    },
    "OpenAI.Prompt": {
      "type": "object",
      "description": "Reference to a prompt template and its variables.\n[Learn more](/docs/guides/text?api-mode=responses#reusable-prompts).",
      "properties": {
        "id": {
          "type": "string",
          "description": "The unique identifier of the prompt template to use."
        },
        "version": {
          "type": "string",
          "description": "Optional version of the prompt template.",
          "x-nullable": true
        },
        "variables": {
          "$ref": "#/definitions/OpenAI.ResponsePromptVariables",
          "x-nullable": true
        }
      },
      "required": [
        "id"
      ]
    },
    "OpenAI.RankingOptions": {
      "type": "object",
      "properties": {
        "ranker": {
          "type": "string",
          "description": "The ranker to use for the file search.",
          "enum": [
            "auto",
            "default-2024-11-15"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "score_threshold": {
          "type": "number",
          "format": "float",
          "description": "The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results."
        }
      }
    },
    "OpenAI.Reasoning": {
      "type": "object",
      "description": "**o-series models only**\n\nConfiguration options for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).",
      "properties": {
        "effort": {
          "type": "string",
          "default": "medium",
          "enum": [
            "low",
            "medium",
            "high"
          ],
          "x-ms-enum": {
            "modelAsString": false
          },
          "x-nullable": true
        },
        "summary": {
          "type": "string",
          "description": "A summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model's reasoning process.\nOne of `auto`, `concise`, or `detailed`.",
          "enum": [
            "auto",
            "concise",
            "detailed"
          ],
          "x-ms-enum": {
            "modelAsString": false
          },
          "x-nullable": true
        },
        "generate_summary": {
          "type": "string",
          "description": "**Deprecated:** use `summary` instead.\n\nA summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model's reasoning process.\nOne of `auto`, `concise`, or `detailed`.",
          "default": null,
          "enum": [
            "auto",
            "concise",
            "detailed"
          ],
          "x-ms-enum": {
            "modelAsString": false
          },
          "x-nullable": true
        }
      }
    },
    "OpenAI.ReasoningItemParam": {
      "type": "object",
      "description": "A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](/docs/guides/conversation-state).\n",
      "properties": {
        "encrypted_content": {
          "type": "string",
          "description": "The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.",
          "x-nullable": true
        },
        "summary": {
          "type": "array",
          "description": "Reasoning text contents.",
          "items": {
            "$ref": "#/definitions/OpenAI.ReasoningItemSummaryPart"
          }
        }
      },
      "required": [
        "summary"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "reasoning"
    },
    "OpenAI.ReasoningItemResource": {
      "type": "object",
      "description": "A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](/docs/guides/conversation-state).\n",
      "properties": {
        "encrypted_content": {
          "type": "string",
          "description": "The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.",
          "x-nullable": true
        },
        "summary": {
          "type": "array",
          "description": "Reasoning text contents.",
          "items": {
            "$ref": "#/definitions/OpenAI.ReasoningItemSummaryPart"
          }
        }
      },
      "required": [
        "summary"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "reasoning"
    },
    "OpenAI.ReasoningItemSummaryPart": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ReasoningItemSummaryPartType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.ReasoningItemSummaryPartType": {
      "type": "string",
      "enum": [
        "summary_text"
      ],
      "x-ms-enum": {
        "name": "ReasoningItemSummaryPartType",
        "modelAsString": true,
        "values": [
          {
            "name": "summary_text",
            "value": "summary_text"
          }
        ]
      }
    },
    "OpenAI.ReasoningItemSummaryTextPart": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string"
        }
      },
      "required": [
        "text"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ReasoningItemSummaryPart"
        }
      ],
      "x-ms-discriminator-value": "summary_text"
    },
    "OpenAI.Response": {
      "type": "object",
      "properties": {
        "metadata": {
          "type": "object",
          "description": "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.",
          "x-nullable": true,
          "additionalProperties": {
            "type": "string"
          },
          "x-oaiTypeLabel": "map"
        },
        "temperature": {
          "type": "number",
          "format": "float",
          "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.",
          "x-nullable": true
        },
        "top_p": {
          "type": "number",
          "format": "float",
          "description": "An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.",
          "x-nullable": true
        },
        "user": {
          "type": "string",
          "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).",
          "x-nullable": true
        },
        "service_tier": {
          "$ref": "#/definitions/OpenAI.ServiceTier",
          "description": "Note: service_tier is not applicable to Azure OpenAI."
        },
        "top_logprobs": {
          "type": "integer",
          "format": "int32",
          "description": "An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.",
          "x-nullable": true
        },
        "previous_response_id": {
          "type": "string",
          "description": "The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](/docs/guides/conversation-state).",
          "x-nullable": true
        },
        "model": {
          "type": "string",
          "description": "The model deployment to use for the creation of this response."
        },
        "reasoning": {
          "$ref": "#/definitions/OpenAI.Reasoning",
          "x-nullable": true
        },
        "background": {
          "type": "boolean",
          "description": "Whether to run the model response in the background.\n[Learn more](/docs/guides/background).",
          "default": false,
          "x-nullable": true
        },
        "max_output_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).",
          "x-nullable": true
        },
        "max_tool_calls": {
          "type": "integer",
          "format": "int32",
          "description": "The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.",
          "x-nullable": true
        },
        "text": {
          "type": "object",
          "description": "Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Structured Outputs](/docs/guides/structured-outputs)",
          "properties": {
            "format": {
              "$ref": "#/definitions/OpenAI.ResponseTextFormatConfiguration"
            }
          }
        },
        "tools": {
          "type": "array",
          "description": "An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like [web search](/docs/guides/tools-web-search)\n  or [file search](/docs/guides/tools-file-search). Learn more about\n  [built-in tools](/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](/docs/guides/function-calling).",
          "items": {
            "$ref": "#/definitions/OpenAI.Tool"
          }
        },
        "tool_choice": {
          "description": "How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call."
        },
        "prompt": {
          "$ref": "#/definitions/OpenAI.Prompt",
          "x-nullable": true
        },
        "truncation": {
          "type": "string",
          "description": "The truncation strategy to use for the model response.\n- `auto`: If the context of this response and previous ones exceeds\n  the model's context window size, the model will truncate the\n  response to fit the context window by dropping input items in the\n  middle of the conversation.\n- `disabled` (default): If a model response will exceed the context window\n  size for a model, the request will fail with a 400 error.",
          "default": "disabled",
          "enum": [
            "auto",
            "disabled"
          ],
          "x-ms-enum": {
            "modelAsString": false
          },
          "x-nullable": true
        },
        "id": {
          "type": "string",
          "description": "Unique identifier for this Response."
        },
        "object": {
          "type": "string",
          "description": "The object type of this resource - always set to `response`.",
          "enum": [
            "response"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "status": {
          "type": "string",
          "description": "The status of the response generation. One of `completed`, `failed`,\n`in_progress`, `cancelled`, `queued`, or `incomplete`.",
          "enum": [
            "completed",
            "failed",
            "in_progress",
            "cancelled",
            "queued",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "created_at": {
          "type": "integer",
          "format": "unixtime",
          "description": "Unix timestamp (in seconds) of when this Response was created."
        },
        "error": {
          "$ref": "#/definitions/OpenAI.ResponseError",
          "x-nullable": true
        },
        "incomplete_details": {
          "type": "object",
          "description": "Details about why the response is incomplete.",
          "properties": {
            "reason": {
              "type": "string",
              "description": "The reason why the response is incomplete.",
              "enum": [
                "max_output_tokens",
                "content_filter"
              ],
              "x-ms-enum": {
                "modelAsString": false
              }
            }
          },
          "x-nullable": true
        },
        "output": {
          "type": "array",
          "description": "An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model's response.\n- Rather than accessing the first item in the `output` array and\n  assuming it's an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs.",
          "items": {
            "$ref": "#/definitions/OpenAI.ItemResource"
          }
        },
        "instructions": {
          "description": "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses."
        },
        "output_text": {
          "type": "string",
          "description": "SDK-only convenience property that contains the aggregated text output\nfrom all `output_text` items in the `output` array, if any are present.\nSupported in the Python and JavaScript SDKs.",
          "x-nullable": true
        },
        "usage": {
          "$ref": "#/definitions/OpenAI.ResponseUsage"
        },
        "parallel_tool_calls": {
          "type": "boolean",
          "description": "Whether to allow the model to run tool calls in parallel.",
          "default": true
        },
        "conversation": {
          "type": "object",
          "properties": {
            "id": {
              "type": "string"
            }
          },
          "required": [
            "id"
          ],
          "x-nullable": true
        },
        "agent": {
          "$ref": "#/definitions/AgentId",
          "description": "The agent used for this response"
        },
        "structured_inputs": {
          "type": "object",
          "description": "The structured inputs to the response that can participate in prompt template substitution or tool argument bindings.",
          "additionalProperties": {}
        }
      },
      "required": [
        "metadata",
        "temperature",
        "top_p",
        "user",
        "id",
        "object",
        "created_at",
        "error",
        "incomplete_details",
        "output",
        "instructions",
        "parallel_tool_calls",
        "conversation"
      ]
    },
    "OpenAI.ResponseCodeInterpreterCallCodeDeltaEvent": {
      "type": "object",
      "description": "Emitted when a partial code snippet is streamed by the code interpreter.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response for which the code is being streamed."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the code interpreter tool call item."
        },
        "delta": {
          "type": "string",
          "description": "The partial code snippet being streamed by the code interpreter."
        }
      },
      "required": [
        "output_index",
        "item_id",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.code_interpreter_call_code.delta"
    },
    "OpenAI.ResponseCodeInterpreterCallCodeDoneEvent": {
      "type": "object",
      "description": "Emitted when the code snippet is finalized by the code interpreter.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response for which the code is finalized."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the code interpreter tool call item."
        },
        "code": {
          "type": "string",
          "description": "The final code snippet output by the code interpreter."
        }
      },
      "required": [
        "output_index",
        "item_id",
        "code"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.code_interpreter_call_code.done"
    },
    "OpenAI.ResponseCodeInterpreterCallCompletedEvent": {
      "type": "object",
      "description": "Emitted when the code interpreter call is completed.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response for which the code interpreter call is completed."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the code interpreter tool call item."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.code_interpreter_call.completed"
    },
    "OpenAI.ResponseCodeInterpreterCallInProgressEvent": {
      "type": "object",
      "description": "Emitted when a code interpreter call is in progress.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response for which the code interpreter call is in progress."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the code interpreter tool call item."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.code_interpreter_call.in_progress"
    },
    "OpenAI.ResponseCodeInterpreterCallInterpretingEvent": {
      "type": "object",
      "description": "Emitted when the code interpreter is actively interpreting the code snippet.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response for which the code interpreter is interpreting code."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the code interpreter tool call item."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.code_interpreter_call.interpreting"
    },
    "OpenAI.ResponseCompletedEvent": {
      "type": "object",
      "description": "Emitted when the model response is complete.",
      "properties": {
        "response": {
          "$ref": "#/definitions/OpenAI.Response",
          "description": "Properties of the completed response."
        }
      },
      "required": [
        "response"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.completed"
    },
    "OpenAI.ResponseContentPartAddedEvent": {
      "type": "object",
      "description": "Emitted when a new content part is added.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the content part was added to."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the content part was added to."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the content part that was added."
        },
        "part": {
          "$ref": "#/definitions/OpenAI.ItemContent",
          "description": "The content part that was added."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "part"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.content_part.added"
    },
    "OpenAI.ResponseContentPartDoneEvent": {
      "type": "object",
      "description": "Emitted when a content part is done.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the content part was added to."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the content part was added to."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the content part that is done."
        },
        "part": {
          "$ref": "#/definitions/OpenAI.ItemContent",
          "description": "The content part that is done."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "part"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.content_part.done"
    },
    "OpenAI.ResponseCreatedEvent": {
      "type": "object",
      "description": "An event that is emitted when a response is created.",
      "properties": {
        "response": {
          "$ref": "#/definitions/OpenAI.Response",
          "description": "The response that was created."
        }
      },
      "required": [
        "response"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.created"
    },
    "OpenAI.ResponseError": {
      "type": "object",
      "description": "An error object returned when the model fails to generate a Response.",
      "properties": {
        "code": {
          "$ref": "#/definitions/OpenAI.ResponseErrorCode"
        },
        "message": {
          "type": "string",
          "description": "A human-readable description of the error."
        }
      },
      "required": [
        "code",
        "message"
      ]
    },
    "OpenAI.ResponseErrorCode": {
      "type": "string",
      "description": "The error code for the response.",
      "enum": [
        "server_error",
        "rate_limit_exceeded",
        "invalid_prompt",
        "vector_store_timeout",
        "invalid_image",
        "invalid_image_format",
        "invalid_base64_image",
        "invalid_image_url",
        "image_too_large",
        "image_too_small",
        "image_parse_error",
        "image_content_policy_violation",
        "invalid_image_mode",
        "image_file_too_large",
        "unsupported_image_media_type",
        "empty_image_file",
        "failed_to_download_image",
        "image_file_not_found"
      ],
      "x-ms-enum": {
        "name": "ResponseErrorCode",
        "modelAsString": false
      }
    },
    "OpenAI.ResponseErrorEvent": {
      "type": "object",
      "description": "Emitted when an error occurs.",
      "properties": {
        "code": {
          "type": "string",
          "description": "The error code.",
          "x-nullable": true
        },
        "message": {
          "type": "string",
          "description": "The error message."
        },
        "param": {
          "type": "string",
          "description": "The error parameter.",
          "x-nullable": true
        }
      },
      "required": [
        "code",
        "message",
        "param"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "error"
    },
    "OpenAI.ResponseFailedEvent": {
      "type": "object",
      "description": "An event that is emitted when a response fails.",
      "properties": {
        "response": {
          "$ref": "#/definitions/OpenAI.Response",
          "description": "The response that failed."
        }
      },
      "required": [
        "response"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.failed"
    },
    "OpenAI.ResponseFileSearchCallCompletedEvent": {
      "type": "object",
      "description": "Emitted when a file search call is completed (results found).",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the file search call is initiated."
        },
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the file search call is initiated."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.file_search_call.completed"
    },
    "OpenAI.ResponseFileSearchCallInProgressEvent": {
      "type": "object",
      "description": "Emitted when a file search call is initiated.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the file search call is initiated."
        },
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the file search call is initiated."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.file_search_call.in_progress"
    },
    "OpenAI.ResponseFileSearchCallSearchingEvent": {
      "type": "object",
      "description": "Emitted when a file search is currently searching.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the file search call is searching."
        },
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the file search call is initiated."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.file_search_call.searching"
    },
    "OpenAI.ResponseFormatJsonSchemaSchema": {
      "type": "object",
      "description": "The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).",
      "additionalProperties": {}
    },
    "OpenAI.ResponseFunctionCallArgumentsDeltaEvent": {
      "type": "object",
      "description": "Emitted when there is a partial function-call arguments delta.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the function-call arguments delta is added to."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the function-call arguments delta is added to."
        },
        "delta": {
          "type": "string",
          "description": "The function-call arguments delta that is added."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.function_call_arguments.delta"
    },
    "OpenAI.ResponseFunctionCallArgumentsDoneEvent": {
      "type": "object",
      "description": "Emitted when function-call arguments are finalized.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the item."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item."
        },
        "arguments": {
          "type": "string",
          "description": "The function-call arguments."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.function_call_arguments.done"
    },
    "OpenAI.ResponseImageGenCallCompletedEvent": {
      "type": "object",
      "description": "Emitted when an image generation tool call has completed and the final image is available.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the image generation item being processed."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.image_generation_call.completed"
    },
    "OpenAI.ResponseImageGenCallGeneratingEvent": {
      "type": "object",
      "description": "Emitted when an image generation tool call is actively generating an image (intermediate state).",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the image generation item being processed."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.image_generation_call.generating"
    },
    "OpenAI.ResponseImageGenCallInProgressEvent": {
      "type": "object",
      "description": "Emitted when an image generation tool call is in progress.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the image generation item being processed."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.image_generation_call.in_progress"
    },
    "OpenAI.ResponseImageGenCallPartialImageEvent": {
      "type": "object",
      "description": "Emitted when a partial image is available during image generation streaming.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the image generation item being processed."
        },
        "partial_image_index": {
          "type": "integer",
          "format": "int32",
          "description": "0-based index for the partial image (backend is 1-based, but this is 0-based for the user)."
        },
        "partial_image_b64": {
          "type": "string",
          "description": "Base64-encoded partial image data, suitable for rendering as an image."
        }
      },
      "required": [
        "output_index",
        "item_id",
        "partial_image_index",
        "partial_image_b64"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.image_generation_call.partial_image"
    },
    "OpenAI.ResponseInProgressEvent": {
      "type": "object",
      "description": "Emitted when the response is in progress.",
      "properties": {
        "response": {
          "$ref": "#/definitions/OpenAI.Response",
          "description": "The response that is in progress."
        }
      },
      "required": [
        "response"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.in_progress"
    },
    "OpenAI.ResponseIncompleteEvent": {
      "type": "object",
      "description": "An event that is emitted when a response finishes as incomplete.",
      "properties": {
        "response": {
          "$ref": "#/definitions/OpenAI.Response",
          "description": "The response that was incomplete."
        }
      },
      "required": [
        "response"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.incomplete"
    },
    "OpenAI.ResponseMCPCallArgumentsDeltaEvent": {
      "type": "object",
      "description": "Emitted when there is a delta (partial update) to the arguments of an MCP tool call.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the MCP tool call item being processed."
        },
        "delta": {
          "description": "The partial update to the arguments for the MCP tool call."
        }
      },
      "required": [
        "output_index",
        "item_id",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_call.arguments_delta"
    },
    "OpenAI.ResponseMCPCallArgumentsDoneEvent": {
      "type": "object",
      "description": "Emitted when the arguments for an MCP tool call are finalized.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the MCP tool call item being processed."
        },
        "arguments": {
          "description": "The finalized arguments for the MCP tool call."
        }
      },
      "required": [
        "output_index",
        "item_id",
        "arguments"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_call.arguments_done"
    },
    "OpenAI.ResponseMCPCallCompletedEvent": {
      "type": "object",
      "description": "Emitted when an MCP  tool call has completed successfully.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_call.completed"
    },
    "OpenAI.ResponseMCPCallFailedEvent": {
      "type": "object",
      "description": "Emitted when an MCP  tool call has failed.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_call.failed"
    },
    "OpenAI.ResponseMCPCallInProgressEvent": {
      "type": "object",
      "description": "Emitted when an MCP  tool call is in progress.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the MCP tool call item being processed."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_call.in_progress"
    },
    "OpenAI.ResponseMCPListToolsCompletedEvent": {
      "type": "object",
      "description": "Emitted when the list of available MCP tools has been successfully retrieved.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_list_tools.completed"
    },
    "OpenAI.ResponseMCPListToolsFailedEvent": {
      "type": "object",
      "description": "Emitted when the attempt to list available MCP tools has failed.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_list_tools.failed"
    },
    "OpenAI.ResponseMCPListToolsInProgressEvent": {
      "type": "object",
      "description": "Emitted when the system is in the process of retrieving the list of available MCP tools.",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.mcp_list_tools.in_progress"
    },
    "OpenAI.ResponseOutputItemAddedEvent": {
      "type": "object",
      "description": "Emitted when a new output item is added.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that was added."
        },
        "item": {
          "$ref": "#/definitions/OpenAI.ItemResource",
          "description": "The output item that was added."
        }
      },
      "required": [
        "output_index",
        "item"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.output_item.added"
    },
    "OpenAI.ResponseOutputItemDoneEvent": {
      "type": "object",
      "description": "Emitted when an output item is marked done.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that was marked done."
        },
        "item": {
          "$ref": "#/definitions/OpenAI.ItemResource",
          "description": "The output item that was marked done."
        }
      },
      "required": [
        "output_index",
        "item"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.output_item.done"
    },
    "OpenAI.ResponsePromptVariables": {
      "type": "object",
      "description": "Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.",
      "additionalProperties": {
        "$ref": "#/definitions/OpenAI.ItemParam"
      },
      "x-oaiExpandable": true,
      "x-oaiTypeLabel": "map"
    },
    "OpenAI.ResponseQueuedEvent": {
      "type": "object",
      "description": "Emitted when a response is queued and waiting to be processed.",
      "properties": {
        "response": {
          "$ref": "#/definitions/OpenAI.Response",
          "description": "The full response object that is queued."
        }
      },
      "required": [
        "response"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.queued"
    },
    "OpenAI.ResponseReasoningDeltaEvent": {
      "type": "object",
      "description": "Emitted when there is a delta (partial update) to the reasoning content.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the item for which reasoning is being updated."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the reasoning content part within the output item."
        },
        "delta": {
          "description": "The partial update to the reasoning content."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning.delta"
    },
    "OpenAI.ResponseReasoningDoneEvent": {
      "type": "object",
      "description": "Emitted when the reasoning content is finalized for an item.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the item for which reasoning is finalized."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the reasoning content part within the output item."
        },
        "text": {
          "type": "string",
          "description": "The finalized reasoning text."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "text"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning.done"
    },
    "OpenAI.ResponseReasoningSummaryDeltaEvent": {
      "type": "object",
      "description": "Emitted when there is a delta (partial update) to the reasoning summary content.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the item for which the reasoning summary is being updated."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "summary_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the summary part within the output item."
        },
        "delta": {
          "description": "The partial update to the reasoning summary content."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "summary_index",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning_summary.delta"
    },
    "OpenAI.ResponseReasoningSummaryDoneEvent": {
      "type": "object",
      "description": "Emitted when the reasoning summary content is finalized for an item.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The unique identifier of the item for which the reasoning summary is finalized."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item in the response's output array."
        },
        "summary_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the summary part within the output item."
        },
        "text": {
          "type": "string",
          "description": "The finalized reasoning summary text."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "summary_index",
        "text"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning_summary.done"
    },
    "OpenAI.ResponseReasoningSummaryPartAddedEvent": {
      "type": "object",
      "description": "Emitted when a new reasoning summary part is added.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the item this summary part is associated with."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item this summary part is associated with."
        },
        "summary_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the summary part within the reasoning summary."
        },
        "part": {
          "$ref": "#/definitions/OpenAI.ReasoningItemSummaryPart",
          "description": "The summary part that was added."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "summary_index",
        "part"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning_summary_part.added"
    },
    "OpenAI.ResponseReasoningSummaryPartDoneEvent": {
      "type": "object",
      "description": "Emitted when a reasoning summary part is completed.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the item this summary part is associated with."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item this summary part is associated with."
        },
        "summary_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the summary part within the reasoning summary."
        },
        "part": {
          "$ref": "#/definitions/OpenAI.ReasoningItemSummaryPart",
          "description": "The completed summary part."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "summary_index",
        "part"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning_summary_part.done"
    },
    "OpenAI.ResponseReasoningSummaryTextDeltaEvent": {
      "type": "object",
      "description": "Emitted when a delta is added to a reasoning summary text.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the item this summary text delta is associated with."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item this summary text delta is associated with."
        },
        "summary_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the summary part within the reasoning summary."
        },
        "delta": {
          "type": "string",
          "description": "The text delta that was added to the summary."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "summary_index",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning_summary_text.delta"
    },
    "OpenAI.ResponseReasoningSummaryTextDoneEvent": {
      "type": "object",
      "description": "Emitted when a reasoning summary text is completed.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the item this summary text is associated with."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item this summary text is associated with."
        },
        "summary_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the summary part within the reasoning summary."
        },
        "text": {
          "type": "string",
          "description": "The full text of the completed reasoning summary."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "summary_index",
        "text"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.reasoning_summary_text.done"
    },
    "OpenAI.ResponseRefusalDeltaEvent": {
      "type": "object",
      "description": "Emitted when there is a partial refusal text.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the refusal text is added to."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the refusal text is added to."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the content part that the refusal text is added to."
        },
        "delta": {
          "type": "string",
          "description": "The refusal text that is added."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.refusal.delta"
    },
    "OpenAI.ResponseRefusalDoneEvent": {
      "type": "object",
      "description": "Emitted when refusal text is finalized.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the refusal text is finalized."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the refusal text is finalized."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the content part that the refusal text is finalized."
        },
        "refusal": {
          "type": "string",
          "description": "The refusal text that is finalized."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "refusal"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.refusal.done"
    },
    "OpenAI.ResponseStreamEvent": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ResponseStreamEventType"
        },
        "sequence_number": {
          "type": "integer",
          "format": "int32",
          "description": "The sequence number for this event."
        }
      },
      "discriminator": "type",
      "required": [
        "type",
        "sequence_number"
      ]
    },
    "OpenAI.ResponseStreamEventType": {
      "type": "string",
      "enum": [
        "response.audio.delta",
        "response.audio.done",
        "response.audio_transcript.delta",
        "response.audio_transcript.done",
        "response.code_interpreter_call_code.delta",
        "response.code_interpreter_call_code.done",
        "response.code_interpreter_call.completed",
        "response.code_interpreter_call.in_progress",
        "response.code_interpreter_call.interpreting",
        "response.completed",
        "response.content_part.added",
        "response.content_part.done",
        "response.created",
        "error",
        "response.file_search_call.completed",
        "response.file_search_call.in_progress",
        "response.file_search_call.searching",
        "response.function_call_arguments.delta",
        "response.function_call_arguments.done",
        "response.in_progress",
        "response.failed",
        "response.incomplete",
        "response.output_item.added",
        "response.output_item.done",
        "response.refusal.delta",
        "response.refusal.done",
        "response.output_text.annotation.added",
        "response.output_text.delta",
        "response.output_text.done",
        "response.reasoning_summary_part.added",
        "response.reasoning_summary_part.done",
        "response.reasoning_summary_text.delta",
        "response.reasoning_summary_text.done",
        "response.web_search_call.completed",
        "response.web_search_call.in_progress",
        "response.web_search_call.searching",
        "response.image_generation_call.completed",
        "response.image_generation_call.generating",
        "response.image_generation_call.in_progress",
        "response.image_generation_call.partial_image",
        "response.mcp_call.arguments_delta",
        "response.mcp_call.arguments_done",
        "response.mcp_call.completed",
        "response.mcp_call.failed",
        "response.mcp_call.in_progress",
        "response.mcp_list_tools.completed",
        "response.mcp_list_tools.failed",
        "response.mcp_list_tools.in_progress",
        "response.queued",
        "response.reasoning.delta",
        "response.reasoning.done",
        "response.reasoning_summary.delta",
        "response.reasoning_summary.done"
      ],
      "x-ms-enum": {
        "name": "ResponseStreamEventType",
        "modelAsString": true,
        "values": [
          {
            "name": "response_audio_delta",
            "value": "response.audio.delta"
          },
          {
            "name": "response_audio_done",
            "value": "response.audio.done"
          },
          {
            "name": "response_audio_transcript_delta",
            "value": "response.audio_transcript.delta"
          },
          {
            "name": "response_audio_transcript_done",
            "value": "response.audio_transcript.done"
          },
          {
            "name": "response_code_interpreter_call_code_delta",
            "value": "response.code_interpreter_call_code.delta"
          },
          {
            "name": "response_code_interpreter_call_code_done",
            "value": "response.code_interpreter_call_code.done"
          },
          {
            "name": "response_code_interpreter_call_completed",
            "value": "response.code_interpreter_call.completed"
          },
          {
            "name": "response_code_interpreter_call_in_progress",
            "value": "response.code_interpreter_call.in_progress"
          },
          {
            "name": "response_code_interpreter_call_interpreting",
            "value": "response.code_interpreter_call.interpreting"
          },
          {
            "name": "response_completed",
            "value": "response.completed"
          },
          {
            "name": "response_content_part_added",
            "value": "response.content_part.added"
          },
          {
            "name": "response_content_part_done",
            "value": "response.content_part.done"
          },
          {
            "name": "response_created",
            "value": "response.created"
          },
          {
            "name": "error",
            "value": "error"
          },
          {
            "name": "response_file_search_call_completed",
            "value": "response.file_search_call.completed"
          },
          {
            "name": "response_file_search_call_in_progress",
            "value": "response.file_search_call.in_progress"
          },
          {
            "name": "response_file_search_call_searching",
            "value": "response.file_search_call.searching"
          },
          {
            "name": "response_function_call_arguments_delta",
            "value": "response.function_call_arguments.delta"
          },
          {
            "name": "response_function_call_arguments_done",
            "value": "response.function_call_arguments.done"
          },
          {
            "name": "response_in_progress",
            "value": "response.in_progress"
          },
          {
            "name": "response_failed",
            "value": "response.failed"
          },
          {
            "name": "response_incomplete",
            "value": "response.incomplete"
          },
          {
            "name": "response_output_item_added",
            "value": "response.output_item.added"
          },
          {
            "name": "response_output_item_done",
            "value": "response.output_item.done"
          },
          {
            "name": "response_refusal_delta",
            "value": "response.refusal.delta"
          },
          {
            "name": "response_refusal_done",
            "value": "response.refusal.done"
          },
          {
            "name": "response_output_text_annotation_added",
            "value": "response.output_text.annotation.added"
          },
          {
            "name": "response_output_text_delta",
            "value": "response.output_text.delta"
          },
          {
            "name": "response_output_text_done",
            "value": "response.output_text.done"
          },
          {
            "name": "response_reasoning_summary_part_added",
            "value": "response.reasoning_summary_part.added"
          },
          {
            "name": "response_reasoning_summary_part_done",
            "value": "response.reasoning_summary_part.done"
          },
          {
            "name": "response_reasoning_summary_text_delta",
            "value": "response.reasoning_summary_text.delta"
          },
          {
            "name": "response_reasoning_summary_text_done",
            "value": "response.reasoning_summary_text.done"
          },
          {
            "name": "response_web_search_call_completed",
            "value": "response.web_search_call.completed"
          },
          {
            "name": "response_web_search_call_in_progress",
            "value": "response.web_search_call.in_progress"
          },
          {
            "name": "response_web_search_call_searching",
            "value": "response.web_search_call.searching"
          },
          {
            "name": "response_image_generation_call_completed",
            "value": "response.image_generation_call.completed"
          },
          {
            "name": "response_image_generation_call_generating",
            "value": "response.image_generation_call.generating"
          },
          {
            "name": "response_image_generation_call_in_progress",
            "value": "response.image_generation_call.in_progress"
          },
          {
            "name": "response_image_generation_call_partial_image",
            "value": "response.image_generation_call.partial_image"
          },
          {
            "name": "response_mcp_call_arguments_delta",
            "value": "response.mcp_call.arguments_delta"
          },
          {
            "name": "response_mcp_call_arguments_done",
            "value": "response.mcp_call.arguments_done"
          },
          {
            "name": "response_mcp_call_completed",
            "value": "response.mcp_call.completed"
          },
          {
            "name": "response_mcp_call_failed",
            "value": "response.mcp_call.failed"
          },
          {
            "name": "response_mcp_call_in_progress",
            "value": "response.mcp_call.in_progress"
          },
          {
            "name": "response_mcp_list_tools_completed",
            "value": "response.mcp_list_tools.completed"
          },
          {
            "name": "response_mcp_list_tools_failed",
            "value": "response.mcp_list_tools.failed"
          },
          {
            "name": "response_mcp_list_tools_in_progress",
            "value": "response.mcp_list_tools.in_progress"
          },
          {
            "name": "response_queued",
            "value": "response.queued"
          },
          {
            "name": "response_reasoning_delta",
            "value": "response.reasoning.delta"
          },
          {
            "name": "response_reasoning_done",
            "value": "response.reasoning.done"
          },
          {
            "name": "response_reasoning_summary_delta",
            "value": "response.reasoning_summary.delta"
          },
          {
            "name": "response_reasoning_summary_done",
            "value": "response.reasoning_summary.done"
          }
        ]
      }
    },
    "OpenAI.ResponseTextDeltaEvent": {
      "type": "object",
      "description": "Emitted when there is an additional text delta.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the text delta was added to."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the text delta was added to."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the content part that the text delta was added to."
        },
        "delta": {
          "type": "string",
          "description": "The text delta that was added."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "delta"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.output_text.delta"
    },
    "OpenAI.ResponseTextDoneEvent": {
      "type": "object",
      "description": "Emitted when text content is finalized.",
      "properties": {
        "item_id": {
          "type": "string",
          "description": "The ID of the output item that the text content is finalized."
        },
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the text content is finalized."
        },
        "content_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the content part that the text content is finalized."
        },
        "text": {
          "type": "string",
          "description": "The text content that is finalized."
        }
      },
      "required": [
        "item_id",
        "output_index",
        "content_index",
        "text"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.output_text.done"
    },
    "OpenAI.ResponseTextFormatConfiguration": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ResponseTextFormatConfigurationType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.ResponseTextFormatConfigurationJsonObject": {
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseTextFormatConfiguration"
        }
      ],
      "x-ms-discriminator-value": "json_object"
    },
    "OpenAI.ResponseTextFormatConfigurationJsonSchema": {
      "type": "object",
      "description": "JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](/docs/guides/structured-outputs).",
      "properties": {
        "description": {
          "type": "string",
          "description": "A description of what the response format is for, used by the model to\ndetermine how to respond in the format."
        },
        "name": {
          "type": "string",
          "description": "The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64."
        },
        "schema": {
          "$ref": "#/definitions/OpenAI.ResponseFormatJsonSchemaSchema"
        },
        "strict": {
          "type": "boolean",
          "description": "Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](/docs/guides/structured-outputs).",
          "default": false,
          "x-nullable": true
        }
      },
      "required": [
        "name",
        "schema"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseTextFormatConfiguration"
        }
      ],
      "x-ms-discriminator-value": "json_schema"
    },
    "OpenAI.ResponseTextFormatConfigurationText": {
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseTextFormatConfiguration"
        }
      ],
      "x-ms-discriminator-value": "text"
    },
    "OpenAI.ResponseTextFormatConfigurationType": {
      "type": "string",
      "description": "An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.",
      "enum": [
        "text",
        "json_schema",
        "json_object"
      ],
      "x-ms-enum": {
        "name": "ResponseTextFormatConfigurationType",
        "modelAsString": true,
        "values": [
          {
            "name": "text",
            "value": "text"
          },
          {
            "name": "json_schema",
            "value": "json_schema"
          },
          {
            "name": "json_object",
            "value": "json_object"
          }
        ]
      }
    },
    "OpenAI.ResponseUsage": {
      "type": "object",
      "description": "Represents token usage details including input tokens, output tokens,\na breakdown of output tokens, and the total tokens used.",
      "properties": {
        "input_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "The number of input tokens."
        },
        "input_tokens_details": {
          "type": "object",
          "description": "A detailed breakdown of the input tokens.",
          "properties": {
            "cached_tokens": {
              "type": "integer",
              "format": "int32",
              "description": "The number of tokens that were retrieved from the cache.\n[More on prompt caching](/docs/guides/prompt-caching)."
            }
          },
          "required": [
            "cached_tokens"
          ]
        },
        "output_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "The number of output tokens."
        },
        "output_tokens_details": {
          "type": "object",
          "description": "A detailed breakdown of the output tokens.",
          "properties": {
            "reasoning_tokens": {
              "type": "integer",
              "format": "int32",
              "description": "The number of reasoning tokens."
            }
          },
          "required": [
            "reasoning_tokens"
          ]
        },
        "total_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "The total number of tokens used."
        }
      },
      "required": [
        "input_tokens",
        "input_tokens_details",
        "output_tokens",
        "output_tokens_details",
        "total_tokens"
      ]
    },
    "OpenAI.ResponseWebSearchCallCompletedEvent": {
      "type": "object",
      "description": "Note: web_search is not yet available via Azure OpenAI.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the web search call is associated with."
        },
        "item_id": {
          "type": "string",
          "description": "Unique ID for the output item associated with the web search call."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.web_search_call.completed"
    },
    "OpenAI.ResponseWebSearchCallInProgressEvent": {
      "type": "object",
      "description": "Note: web_search is not yet available via Azure OpenAI.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the web search call is associated with."
        },
        "item_id": {
          "type": "string",
          "description": "Unique ID for the output item associated with the web search call."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.web_search_call.in_progress"
    },
    "OpenAI.ResponseWebSearchCallSearchingEvent": {
      "type": "object",
      "description": "Note: web_search is not yet available via Azure OpenAI.",
      "properties": {
        "output_index": {
          "type": "integer",
          "format": "int32",
          "description": "The index of the output item that the web search call is associated with."
        },
        "item_id": {
          "type": "string",
          "description": "Unique ID for the output item associated with the web search call."
        }
      },
      "required": [
        "output_index",
        "item_id"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponseStreamEvent"
        }
      ],
      "x-ms-discriminator-value": "response.web_search_call.searching"
    },
    "OpenAI.ResponsesAssistantMessageItemParam": {
      "type": "object",
      "description": "A message parameter item with the `assistant` role.",
      "properties": {
        "content": {
          "description": "The content associated with the message."
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemParam"
        }
      ],
      "x-ms-discriminator-value": "assistant"
    },
    "OpenAI.ResponsesAssistantMessageItemResource": {
      "type": "object",
      "description": "A message resource item with the `assistant` role.",
      "properties": {
        "content": {
          "type": "array",
          "description": "The content associated with the message.",
          "items": {
            "$ref": "#/definitions/OpenAI.ItemContent"
          }
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemResource"
        }
      ],
      "x-ms-discriminator-value": "assistant"
    },
    "OpenAI.ResponsesDeveloperMessageItemParam": {
      "type": "object",
      "description": "A message parameter item with the `developer` role.",
      "properties": {
        "content": {
          "description": "The content associated with the message."
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemParam"
        }
      ],
      "x-ms-discriminator-value": "developer"
    },
    "OpenAI.ResponsesDeveloperMessageItemResource": {
      "type": "object",
      "description": "A message resource item with the `developer` role.",
      "properties": {
        "content": {
          "type": "array",
          "description": "The content associated with the message.",
          "items": {
            "$ref": "#/definitions/OpenAI.ItemContent"
          }
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemResource"
        }
      ],
      "x-ms-discriminator-value": "developer"
    },
    "OpenAI.ResponsesMessageItemParam": {
      "type": "object",
      "description": "A response message item, representing a role and content, as provided as client request parameters.",
      "properties": {
        "role": {
          "$ref": "#/definitions/OpenAI.ResponsesMessageRole",
          "description": "The role associated with the message."
        }
      },
      "discriminator": "role",
      "required": [
        "role"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "message"
    },
    "OpenAI.ResponsesMessageItemResource": {
      "type": "object",
      "description": "A response message resource item, representing a role and content, as provided on service responses.",
      "properties": {
        "status": {
          "type": "string",
          "description": "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.",
          "enum": [
            "in_progress",
            "completed",
            "incomplete"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "role": {
          "$ref": "#/definitions/OpenAI.ResponsesMessageRole",
          "description": "The role associated with the message."
        }
      },
      "discriminator": "role",
      "required": [
        "status",
        "role"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "message"
    },
    "OpenAI.ResponsesMessageRole": {
      "type": "string",
      "description": "The collection of valid roles for responses message items.",
      "enum": [
        "system",
        "developer",
        "user",
        "assistant"
      ],
      "x-ms-enum": {
        "name": "ResponsesMessageRole",
        "modelAsString": false,
        "values": [
          {
            "name": "system",
            "value": "system"
          },
          {
            "name": "developer",
            "value": "developer"
          },
          {
            "name": "user",
            "value": "user"
          },
          {
            "name": "assistant",
            "value": "assistant"
          }
        ]
      }
    },
    "OpenAI.ResponsesSystemMessageItemParam": {
      "type": "object",
      "description": "A message parameter item with the `system` role.",
      "properties": {
        "content": {
          "description": "The content associated with the message."
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemParam"
        }
      ],
      "x-ms-discriminator-value": "system"
    },
    "OpenAI.ResponsesSystemMessageItemResource": {
      "type": "object",
      "description": "A message resource item with the `system` role.",
      "properties": {
        "content": {
          "type": "array",
          "description": "The content associated with the message.",
          "items": {
            "$ref": "#/definitions/OpenAI.ItemContent"
          }
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemResource"
        }
      ],
      "x-ms-discriminator-value": "system"
    },
    "OpenAI.ResponsesUserMessageItemParam": {
      "type": "object",
      "description": "A message parameter item with the `user` role.",
      "properties": {
        "content": {
          "description": "The content associated with the message."
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemParam"
        }
      ],
      "x-ms-discriminator-value": "user"
    },
    "OpenAI.ResponsesUserMessageItemResource": {
      "type": "object",
      "description": "A message resource item with the `user` role.",
      "properties": {
        "content": {
          "type": "array",
          "description": "The content associated with the message.",
          "items": {
            "$ref": "#/definitions/OpenAI.ItemContent"
          }
        }
      },
      "required": [
        "content"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ResponsesMessageItemResource"
        }
      ],
      "x-ms-discriminator-value": "user"
    },
    "OpenAI.ServiceTier": {
      "type": "string",
      "description": "Specifies the processing type used for serving the request.\n  - If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.\n  - If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.\n  - If set to '[flex](/docs/guides/flex-processing)' or 'priority', then the request will be processed with the corresponding service tier. [Contact sales](https://openai.com/contact-sales) to learn more about Priority processing.\n  - When not set, the default behavior is 'auto'.\n\n  When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.",
      "enum": [
        "auto",
        "default",
        "flex",
        "scale",
        "priority"
      ],
      "x-ms-enum": {
        "name": "ServiceTier",
        "modelAsString": false
      }
    },
    "OpenAI.Tool": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.ToolType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.ToolType": {
      "type": "string",
      "description": "A tool that can be used to generate a response.",
      "enum": [
        "file_search",
        "function",
        "computer_use_preview",
        "web_search_preview",
        "mcp",
        "code_interpreter",
        "image_generation",
        "local_shell",
        "bing_grounding",
        "browser_automation_preview",
        "fabric_dataagent_preview",
        "sharepoint_grounding_preview",
        "azure_ai_search",
        "openapi",
        "bing_custom_search_preview",
        "capture_structured_outputs",
        "a2a_preview",
        "azure_function"
      ],
      "x-ms-enum": {
        "name": "ToolType",
        "modelAsString": true,
        "values": [
          {
            "name": "file_search",
            "value": "file_search"
          },
          {
            "name": "function",
            "value": "function"
          },
          {
            "name": "computer_use_preview",
            "value": "computer_use_preview"
          },
          {
            "name": "web_search_preview",
            "value": "web_search_preview"
          },
          {
            "name": "mcp",
            "value": "mcp"
          },
          {
            "name": "code_interpreter",
            "value": "code_interpreter"
          },
          {
            "name": "image_generation",
            "value": "image_generation"
          },
          {
            "name": "local_shell",
            "value": "local_shell"
          },
          {
            "name": "bing_grounding",
            "value": "bing_grounding"
          },
          {
            "name": "browser_automation_preview",
            "value": "browser_automation_preview"
          },
          {
            "name": "fabric_dataagent_preview",
            "value": "fabric_dataagent_preview"
          },
          {
            "name": "sharepoint_grounding_preview",
            "value": "sharepoint_grounding_preview"
          },
          {
            "name": "azure_ai_search",
            "value": "azure_ai_search"
          },
          {
            "name": "openapi",
            "value": "openapi"
          },
          {
            "name": "bing_custom_search_preview",
            "value": "bing_custom_search_preview"
          },
          {
            "name": "capture_structured_outputs",
            "value": "capture_structured_outputs"
          },
          {
            "name": "a2a_preview",
            "value": "a2a_preview"
          },
          {
            "name": "azure_function",
            "value": "azure_function"
          }
        ]
      }
    },
    "OpenAI.TopLogProb": {
      "type": "object",
      "description": "The top log probability of a token.",
      "properties": {
        "token": {
          "type": "string"
        },
        "logprob": {
          "type": "number",
          "format": "float"
        },
        "bytes": {
          "type": "array",
          "items": {
            "type": "integer",
            "format": "int32"
          }
        }
      },
      "required": [
        "token",
        "logprob",
        "bytes"
      ]
    },
    "OpenAI.VectorStoreFileAttributes": {
      "type": "object",
      "description": "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.",
      "additionalProperties": {},
      "x-oaiTypeLabel": "map"
    },
    "OpenAI.WebSearchAction": {
      "type": "object",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenAI.WebSearchActionType"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenAI.WebSearchActionFind": {
      "type": "object",
      "description": "Action type \"find\": Searches for a pattern within a loaded page.",
      "properties": {
        "url": {
          "type": "string",
          "format": "uri",
          "description": "The URL of the page searched for the pattern."
        },
        "pattern": {
          "type": "string",
          "description": "The pattern or text to search for within the page."
        }
      },
      "required": [
        "url",
        "pattern"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.WebSearchAction"
        }
      ],
      "x-ms-discriminator-value": "find"
    },
    "OpenAI.WebSearchActionOpenPage": {
      "type": "object",
      "description": "Action type \"open_page\" - Opens a specific URL from search results.",
      "properties": {
        "url": {
          "type": "string",
          "format": "uri",
          "description": "The URL opened by the model."
        }
      },
      "required": [
        "url"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.WebSearchAction"
        }
      ],
      "x-ms-discriminator-value": "open_page"
    },
    "OpenAI.WebSearchActionSearch": {
      "type": "object",
      "description": "Action type \"search\" - Performs a web search query.",
      "properties": {
        "query": {
          "type": "string",
          "description": "The search query."
        }
      },
      "required": [
        "query"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.WebSearchAction"
        }
      ],
      "x-ms-discriminator-value": "search"
    },
    "OpenAI.WebSearchActionType": {
      "type": "string",
      "enum": [
        "search",
        "open_page",
        "find"
      ],
      "x-ms-enum": {
        "name": "WebSearchActionType",
        "modelAsString": false,
        "values": [
          {
            "name": "search",
            "value": "search"
          },
          {
            "name": "open_page",
            "value": "open_page"
          },
          {
            "name": "find",
            "value": "find"
          }
        ]
      }
    },
    "OpenAI.WebSearchPreviewTool": {
      "type": "object",
      "description": "Note: web_search is not yet available via Azure OpenAI.",
      "properties": {
        "user_location": {
          "$ref": "#/definitions/OpenAI.Location",
          "description": "The user's location.",
          "x-nullable": true
        },
        "search_context_size": {
          "type": "string",
          "description": "High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.",
          "enum": [
            "low",
            "medium",
            "high"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        }
      },
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "web_search_preview"
    },
    "OpenAI.WebSearchToolCallItemParam": {
      "type": "object",
      "description": "The results of a web search tool call. See the\n[web search guide](/docs/guides/tools-web-search) for more information.\n",
      "properties": {
        "action": {
          "$ref": "#/definitions/OpenAI.WebSearchAction",
          "description": "An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find)."
        }
      },
      "required": [
        "action"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemParam"
        }
      ],
      "x-ms-discriminator-value": "web_search_call"
    },
    "OpenAI.WebSearchToolCallItemResource": {
      "type": "object",
      "description": "The results of a web search tool call. See the\n[web search guide](/docs/guides/tools-web-search) for more information.\n",
      "properties": {
        "status": {
          "type": "string",
          "description": "The status of the web search tool call.",
          "enum": [
            "in_progress",
            "searching",
            "completed",
            "failed"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "action": {
          "$ref": "#/definitions/OpenAI.WebSearchAction",
          "description": "An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find)."
        }
      },
      "required": [
        "status",
        "action"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "web_search_call"
    },
    "OpenApiAgentTool": {
      "type": "object",
      "description": "The input definition information for an OpenAPI tool as used to configure an agent.",
      "properties": {
        "openapi": {
          "$ref": "#/definitions/OpenApiFunctionDefinition",
          "description": "The openapi function definition."
        }
      },
      "required": [
        "openapi"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "openapi"
    },
    "OpenApiAnonymousAuthDetails": {
      "type": "object",
      "description": "Security details for OpenApi anonymous authentication",
      "allOf": [
        {
          "$ref": "#/definitions/OpenApiAuthDetails"
        }
      ],
      "x-ms-discriminator-value": "anonymous"
    },
    "OpenApiAuthDetails": {
      "type": "object",
      "description": "authentication details for OpenApiFunctionDefinition",
      "properties": {
        "type": {
          "$ref": "#/definitions/OpenApiAuthType",
          "description": "The type of authentication, must be anonymous/project_connection/managed_identity"
        }
      },
      "discriminator": "type",
      "required": [
        "type"
      ]
    },
    "OpenApiAuthType": {
      "type": "string",
      "description": "Authentication type for OpenApi endpoint. Allowed types are:\n- Anonymous (no authentication required)\n- Project Connection (requires project_connection_id to endpoint, as setup in AI Foundry)\n- Managed_Identity (requires audience for identity based auth)",
      "enum": [
        "anonymous",
        "project_connection",
        "managed_identity"
      ],
      "x-ms-enum": {
        "name": "OpenApiAuthType",
        "modelAsString": true,
        "values": [
          {
            "name": "anonymous",
            "value": "anonymous"
          },
          {
            "name": "project_connection",
            "value": "project_connection"
          },
          {
            "name": "managedIdentity",
            "value": "managed_identity"
          }
        ]
      }
    },
    "OpenApiFunctionDefinition": {
      "type": "object",
      "description": "The input definition information for an openapi function.",
      "properties": {
        "name": {
          "type": "string",
          "description": "The name of the function to be called."
        },
        "description": {
          "type": "string",
          "description": "A description of what the function does, used by the model to choose when and how to call the function."
        },
        "spec": {
          "description": "The openapi function shape, described as a JSON Schema object."
        },
        "auth": {
          "$ref": "#/definitions/OpenApiAuthDetails",
          "description": "Open API authentication details"
        },
        "default_params": {
          "type": "array",
          "description": "List of OpenAPI spec parameters that will use user-provided defaults",
          "items": {
            "type": "string"
          }
        },
        "functions": {
          "type": "array",
          "description": "List of function definitions used by OpenApi tool",
          "items": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "The name of the function to be called."
              },
              "description": {
                "type": "string",
                "description": "A description of what the function does, used by the model to choose when and how to call the function."
              },
              "parameters": {
                "description": "The parameters the functions accepts, described as a JSON Schema object."
              }
            },
            "required": [
              "name",
              "parameters"
            ]
          }
        }
      },
      "required": [
        "name",
        "spec",
        "auth"
      ]
    },
    "OpenApiManagedAuthDetails": {
      "type": "object",
      "description": "Security details for OpenApi managed_identity authentication",
      "properties": {
        "security_scheme": {
          "$ref": "#/definitions/OpenApiManagedSecurityScheme",
          "description": "Connection auth security details"
        }
      },
      "required": [
        "security_scheme"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenApiAuthDetails"
        }
      ],
      "x-ms-discriminator-value": "managed_identity"
    },
    "OpenApiManagedSecurityScheme": {
      "type": "object",
      "description": "Security scheme for OpenApi managed_identity authentication",
      "properties": {
        "audience": {
          "type": "string",
          "description": "Authentication scope for managed_identity auth type"
        }
      },
      "required": [
        "audience"
      ]
    },
    "OpenApiProjectConnectionAuthDetails": {
      "type": "object",
      "description": "Security details for OpenApi project connection authentication",
      "properties": {
        "security_scheme": {
          "$ref": "#/definitions/OpenApiProjectConnectionSecurityScheme",
          "description": "Project connection auth security details"
        }
      },
      "required": [
        "security_scheme"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenApiAuthDetails"
        }
      ],
      "x-ms-discriminator-value": "project_connection"
    },
    "OpenApiProjectConnectionSecurityScheme": {
      "type": "object",
      "description": "Security scheme for OpenApi managed_identity authentication",
      "properties": {
        "project_connection_id": {
          "type": "string",
          "description": "Project connection id for Project Connection auth type"
        }
      },
      "required": [
        "project_connection_id"
      ]
    },
    "SharepointAgentTool": {
      "type": "object",
      "description": "The input definition information for a sharepoint tool as used to configure an agent.",
      "properties": {
        "sharepoint_grounding_preview": {
          "$ref": "#/definitions/SharepointGroundingToolParameters",
          "description": "The sharepoint grounding tool parameters."
        }
      },
      "required": [
        "sharepoint_grounding_preview"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.Tool"
        }
      ],
      "x-ms-discriminator-value": "sharepoint_grounding_preview"
    },
    "SharepointGroundingToolParameters": {
      "type": "object",
      "description": "The sharepoint grounding tool parameters.",
      "properties": {
        "project_connections": {
          "type": "array",
          "description": "The project connections attached to this tool. There can be a maximum of 1 connection\nresource attached to the tool.",
          "maxItems": 1,
          "items": {
            "$ref": "#/definitions/ToolProjectConnection"
          }
        }
      }
    },
    "StructuredOutputDefinition": {
      "type": "object",
      "description": "A structured output that can be produced by the agent.",
      "properties": {
        "name": {
          "type": "string",
          "description": "The name of the structured output."
        },
        "description": {
          "type": "string",
          "description": "A description of the output to emit. Used by the model to determine when to emit the output."
        },
        "schema": {
          "type": "object",
          "description": "The JSON schema for the structured output.",
          "additionalProperties": {}
        },
        "strict": {
          "type": "boolean",
          "description": "Whether to enforce strict validation. Default `true`.",
          "x-nullable": true
        }
      },
      "required": [
        "name",
        "description",
        "schema",
        "strict"
      ]
    },
    "StructuredOutputsItemResource": {
      "type": "object",
      "properties": {
        "output": {
          "description": "The structured output captured during the response."
        }
      },
      "required": [
        "output"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "structured_outputs"
    },
    "ToolProjectConnection": {
      "type": "object",
      "description": "A project connection resource.",
      "properties": {
        "project_connection_id": {
          "type": "string",
          "description": "A project connection in a ToolProjectConnectionList attached to this tool."
        }
      },
      "required": [
        "project_connection_id"
      ]
    },
    "WorkflowActionOutputItemResource": {
      "type": "object",
      "properties": {
        "kind": {
          "type": "string",
          "description": "The kind of CSDL action (e.g., 'SetVariable', 'InvokeAzureAgent')."
        },
        "action_id": {
          "type": "string",
          "description": "Unique identifier for the action."
        },
        "parent_action_id": {
          "type": "string",
          "description": "ID of the parent action if this is a nested action."
        },
        "previous_action_id": {
          "type": "string",
          "description": "ID of the previous action if this action follows another."
        },
        "status": {
          "type": "string",
          "description": "Status of the action (e.g., 'in_progress', 'completed', 'failed', 'cancelled').",
          "enum": [
            "completed",
            "failed",
            "in_progress",
            "cancelled"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        }
      },
      "discriminator": "kind",
      "required": [
        "kind",
        "action_id",
        "status"
      ],
      "allOf": [
        {
          "$ref": "#/definitions/OpenAI.ItemResource"
        }
      ],
      "x-ms-discriminator-value": "workflow_action"
    }
  },
  "parameters": {
    "Azure.Core.Foundations.ApiVersionParameter": {
      "name": "api-version",
      "in": "query",
      "description": "The API version to use for this operation.",
      "required": true,
      "type": "string",
      "minLength": 1,
      "x-ms-parameter-location": "method",
      "x-ms-client-name": "apiVersion"
    }
  }
}
