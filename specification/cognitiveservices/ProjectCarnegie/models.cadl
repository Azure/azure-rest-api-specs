import "@cadl-lang/rest";

using Cadl.Rest;

namespace ProjectCarnegie;

enum TextCategory {
  "Hate",
  "SelfHarm",
  "Sexual",
  "Violence",
}

enum ImageCategory {
  "Hate",
  "SelfHarm",
  "Sexual",
  "Violence",
}

@doc("The analysis request of the text")
model TextDetectRequest {
  @doc("The text needs to be scanned")
  @maxLength(7000)
  text: string;

  @doc("""
The categories will be analyzed, if not assigned, a default set of categories'
analysis results will be returned.
""")
  categories?: TextCategory[];

  @doc("The ids of blocklists")
  blockListIds?: string[];

  @doc("""
When set to true, other analysis will be skipped once any of configured
blocklists was hit. When set to false, all the analysis will be done even when
blocklists were hit.
""")
  breakByBlocklists?: boolean;
}

@doc("The analysis response of the text")
model TextDetectResponse {
  @doc("The details of list match")
  blocklistMatchResults?: TextListMatchResult[];
  hateResult?: TextDetectMultiSeverityResult;
  selfHarmResult?: TextDetectMultiSeverityResult;
  sexualResult?: TextDetectMultiSeverityResult;
  violenceResult?: TextDetectMultiSeverityResult;
}

@doc("The result of custom list match")
model TextListMatchResult {
  @doc("The id of matched custom list")
  @maxLength(64)
  listId: string;

  @doc("The id of matched item")
  @maxLength(64)
  itemId: string;

  @doc("The content of matched item")
  @maxLength(128)
  itemText: string;

  @doc("The character offset of matched text in original input")
  offset?: int32;

  @doc("The length of matched text in original input")
  length?: int32;
}

model TextDetectMultiSeverityResult {
  category: TextCategory;
  @doc("riskLevel represent the severity of the input, currently its value could be: 0,2,4,6")
  riskLevel: int32;
}

@doc("The analysis request of the image")
model ImageDetectRequest {
  @doc("The image needs to be scanned")
  image: Image;

  @doc("""
The categories will be analyzed, if not assigned, default categories will be
analyzed
""")
  categories?: ImageCategory[];
}

@doc("The content or url of image, if both given, the content field will be used. The maxinum size of image is 4MB, and the image should not be smaller than 50*50.")
model Image {
  @doc("Base64 encoding of image")
  content?: string;

  @doc("The blob url of image")
  url?: string;
}

@doc("The analysis response of the image")
model ImageDetectResponse {
  hateResult?: ImageDetectMultiSeverityResult;
  selfHarmResult?: ImageDetectMultiSeverityResult;
  sexualResult?: ImageDetectMultiSeverityResult;
  violenceResult?: ImageDetectMultiSeverityResult;
}

model ImageDetectMultiSeverityResult {
  category: ImageCategory;
  @doc("riskLevel represent the severity of the input, currently its value could be: 0,2,4,6")
  riskLevel: int32;
}

@doc("Text List.")
@resource("text/lists")
model TextList {
  @doc("Text List Id.")
  @key("listId")
  @visibility("read","create","query")
  @maxLength(64)
  listId: string;

  @doc("Text List name.")
  @maxLength(256)
  name?: string;

  @doc("Description for Text List.")
  @maxLength(1024)
  description?: string;
}

@doc("Item in Text List")
@resource("items")
@parentResource(TextList)
model TextListItem {
  @doc("Item id")
  @key("itemId")
  @visibility("read","create","query")
  @maxLength(64)
  itemId: string;

  @doc("Text data description")
  @maxLength(1024)
  description?: string;

  @doc("Text list item content.")
  @maxLength(128)
  text?: string;

  @doc("""
Language of this item, Value may contain only the language code (ex. \"en\",
\"fr\") of BCP 47. If not assigned, \"en\" will be used
""")
  language?: string;
}