parameters:
  "service-dir":
    default: "sdk/openai"
  "dependencies":
    default: ""
emit:
  - "@azure-tools/typespec-autorest"
linter:
  extends:
    - "@azure-tools/typespec-azure-core/all"
options:
  "@azure-tools/typespec-autorest":
    emitter-output-dir: "{project-root}/../"
    output-file: "{azure-resource-provider-folder}/AzureOpenAI/inference/{version-status}/{version}/generated.json"
    azure-resource-provider-folder: "data-plane"
    examples-directory: "{project-root}/examples"
    omit-unreachable-types: true
  "@azure-tools/typespec-csharp":
    package-dir: "Azure.AI.OpenAI"
    namespace: "Azure.AI.OpenAI"
    clear-output-folder: true
    model-namespace: false
    generate-protocol-methods: false
    flavor: azure
  "@azure-tools/typespec-java":
    package-dir: "azure-ai-openai"
    namespace: "com.azure.ai.openai"
    partial-update: true
    enable-sync-stack: true
    generate-tests: false
    custom-types-subpackage: "implementation.models"
    custom-types: "FunctionCallPreset"
    customization-class: customization/src/main/java/ChatCompletionsToolCallCustomizations.java
    flavor: azure
    stream-style-serialization: false
  "@azure-tools/typespec-ts":
    package-dir: "openai"
    generateMetadata: false
    generateTest: false
    isModularLibrary: true
    packageDetails:
      name: "@azure/openai"
    flavor: azure
