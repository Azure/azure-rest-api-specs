{
  "swagger": "2.0",
  "info": {
    "title": "Azure OpenAI API",
    "version": "2022-06-01-preview",
    "description": "Azure OpenAI APIs for completions and search",
    "x-cadl-generated": [
      {
        "emitter": "@azure-tools/cadl-autorest"
      }
    ]
  },
  "schemes": [
    "https"
  ],
  "x-ms-parameterized-host": {
    "hostTemplate": "{endpoint}/openai",
    "useSchemePrefix": false,
    "parameters": [
      {
        "name": "endpoint",
        "in": "path",
        "required": true,
        "description": "Supported Cognitive Services endpoints (protocol and hostname, for example:\nhttps://westus.api.cognitive.microsoft.com).",
        "type": "string"
      }
    ]
  },
  "produces": [
    "application/json"
  ],
  "consumes": [
    "application/json"
  ],
  "security": [
    {
      "ApiKeyAuth": []
    },
    {
      "OAuth2Auth": []
    }
  ],
  "securityDefinitions": {
    "ApiKeyAuth": {
      "type": "apiKey",
      "in": "header",
      "name": "apiKey"
    },
    "OAuth2Auth": {
      "type": "oauth2",
      "flow": "implicit",
      "authorizationUrl": "https://login.microsoftonline.com/common/oauth2/v2.0/authorize",
      "scopes": {}
    }
  },
  "tags": [],
  "paths": {
    "/deployments/{deploymentId}/completions": {
      "post": {
        "operationId": "Operations_CompletionsCreate",
        "summary": "Create a completion from a chosen model",
        "description": "Create a completion from a chosen model",
        "parameters": [
          {
            "$ref": "#/parameters/CompletionsCreateRequest.deploymentId"
          },
          {
            "$ref": "#/parameters/Azure.Core.Foundations.ApiVersionParameter"
          },
          {
            "$ref": "#/parameters/CompletionsCreateRequest.body"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "headers": {
              "apim-request-id": {
                "description": "Request ID for troubleshooting purposes",
                "type": "string"
              }
            },
            "schema": {
              "$ref": "#/definitions/CompletionsCreateResponse"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            }
          }
        }
      }
    },
    "/deployments/{deploymentId}/embeddings": {
      "post": {
        "operationId": "Operations_EmbeddingsCreate",
        "summary": "Return the embeddings for a given prompt.",
        "description": "Return the embeddings for a given prompt.",
        "parameters": [
          {
            "$ref": "#/parameters/EmbeddingsCreateRequest.deploymentId"
          },
          {
            "$ref": "#/parameters/Azure.Core.Foundations.ApiVersionParameter"
          },
          {
            "$ref": "#/parameters/EmbeddingsCreateRequest.body"
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/object"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            }
          }
        }
      }
    }
  },
  "definitions": {
    "Azure.Core.Foundations.Error": {
      "type": "object",
      "properties": {
        "code": {
          "type": "string",
          "description": "One of a server-defined set of error codes."
        },
        "message": {
          "type": "string",
          "description": "A human-readable representation of the error."
        },
        "target": {
          "type": "string",
          "description": "The target of the error."
        },
        "details": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/Azure.Core.Foundations.Error"
          },
          "x-ms-identifiers": [],
          "x-cadl-name": "Azure.Core.Foundations.Error[]",
          "description": "An array of details about specific errors that led to this reported error."
        },
        "innererror": {
          "$ref": "#/definitions/Azure.Core.Foundations.InnerError",
          "description": "An object containing more specific information than the current object about the error."
        }
      },
      "description": "The error object.",
      "required": [
        "code",
        "message",
        "details"
      ]
    },
    "Azure.Core.Foundations.ErrorResponse": {
      "type": "object",
      "properties": {
        "error": {
          "$ref": "#/definitions/Azure.Core.Foundations.Error",
          "description": "The error object."
        }
      },
      "description": "A response containing error details.",
      "required": [
        "error"
      ]
    },
    "Azure.Core.Foundations.InnerError": {
      "type": "object",
      "properties": {
        "code": {
          "type": "string",
          "description": "One of a server-defined set of error codes."
        },
        "innererror": {
          "$ref": "#/definitions/Azure.Core.Foundations.InnerError",
          "description": "Inner error."
        }
      },
      "description": "An object containing more specific information about the error. As per Microsoft One API guidelines - https://github.com/Microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses.",
      "required": [
        "code"
      ]
    },
    "CompletionsChoice": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "description": "Generated text for given completion prompt"
        },
        "index": {
          "type": "integer",
          "format": "int32",
          "description": "Index"
        },
        "logprobs": {
          "$ref": "#/definitions/CompletionsLogProbsModel",
          "description": "Log Prob Model"
        },
        "finish_reason": {
          "type": "string",
          "description": "Reason for finishing"
        }
      },
      "description": "Choice model within completion response"
    },
    "CompletionsCreateBody": {
      "type": "object",
      "properties": {
        "prompt": {
          "$ref": "#/definitions/CompletionsPrompt",
          "description": "An optional prompt to complete from, encoded as a string, a list of strings, or\na list of token lists. Defaults to <|endoftext|>. The prompt to complete from.\nIf you would like to provide multiple prompts, use the POST variant of this\nmethod. Note that <|endoftext|> is the document separator that the model sees\nduring training, so if a prompt is not specified the model will generate as if\nfrom the beginning of a new document. Maximum allowed size of string list is\n2048."
        },
        "max_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "The maximum number of tokens to generate. Has minimum of 0."
        },
        "temperature": {
          "type": "number",
          "format": "float",
          "description": "What sampling temperature to use. Higher values means the model will take more\nrisks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones\nwith a well-defined answer.\nWe generally recommend using this or `top_p` but\nnot both.\nMinimum of 0 and maximum of 2 allowed.\n"
        },
        "top_p": {
          "type": "number",
          "format": "float",
          "description": "An alternative to sampling with temperature, called nucleus sampling, where the\nmodel considers the results of the tokens with top_p probability mass. So 0.1\nmeans only the tokens comprising the top 10% probability mass are\nconsidered.\nWe generally recommend using this or `temperature` but not\nboth.\nMinimum of 0 and maximum of 1 allowed.\n"
        },
        "logit_bias": {
          "$ref": "#/definitions/object",
          "description": "Defaults to null. Modify the likelihood of specified tokens appearing in the\ncompletion. Accepts a json object that maps tokens (specified by their token ID\nin the GPT tokenizer) to an associated bias value from -100 to 100. You can use\nthis tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to\ntoken IDs. Mathematically, the bias is added to the logits generated by the\nmodel prior to sampling. The exact effect will vary per model, but values\nbetween -1 and 1 should decrease or increase likelihood of selection; values\nlike -100 or 100 should result in a ban or exclusive selection of the relevant\ntoken. As an example, you can pass {\"50256\" &#58; -100} to prevent the\n<|endoftext|> token from being generated."
        },
        "user": {
          "type": "string",
          "description": "The ID of the end-user, for use in tracking and rate-limiting."
        },
        "n": {
          "type": "integer",
          "format": "int32",
          "description": "How many snippets to generate for each prompt. Minimum of 1 and maximum of 128\nallowed."
        },
        "stream": {
          "type": "boolean",
          "description": "Whether to enable streaming for this endpoint. If set, tokens will be sent as\nserver-sent events as they become available."
        },
        "logprobs": {
          "type": "integer",
          "format": "int32",
          "description": "Include the log probabilities on the `logprobs` most likely tokens, as well the\nchosen tokens. So for example, if `logprobs` is 10, the API will return a list\nof the 10 most likely tokens. If `logprobs` is 0, only the chosen tokens will\nhave logprobs returned. Minimum of 0 and maximum of 100 allowed."
        },
        "model": {
          "type": "string",
          "description": "The name of the model to use"
        },
        "echo": {
          "type": "boolean",
          "description": "Echo back the prompt in addition to the completion"
        },
        "stop": {
          "$ref": "#/definitions/CompletionsStop",
          "description": "A sequence which indicates the end of the current document."
        },
        "completion_config": {
          "type": "string",
          "description": "Completion configuration"
        },
        "cache_level": {
          "type": "integer",
          "format": "int32",
          "description": "can be used to disable any server-side caching, 0=no cache, 1=prompt prefix\nenabled, 2=full cache"
        },
        "presence_penalty": {
          "type": "number",
          "format": "float",
          "description": "How much to penalize new tokens based on their existing frequency in the text\nso far. Decreases the model's likelihood to repeat the same line verbatim. Has\nminimum of -2 and maximum of 2."
        },
        "frequency_penalty": {
          "type": "number",
          "format": "float",
          "description": "How much to penalize new tokens based on whether they appear in the text so\nfar. Increases the model's likelihood to talk about new topics."
        },
        "best_of": {
          "type": "integer",
          "format": "int32",
          "description": "How many generations to create server side, and display only the best. Will not\nstream intermediate progress if best_of > 1. Has maximum value of 128."
        }
      },
      "description": "Post body schema to create a prompt completion from a deployment"
    },
    "CompletionsCreateRequest": {
      "type": "object",
      "properties": {
        "body": {
          "$ref": "#/definitions/CompletionsCreateBody",
          "description": "expected schema for the body of the completion post request"
        }
      },
      "description": "Input model for completions create endpoint",
      "required": [
        "body"
      ]
    },
    "CompletionsCreateResponse": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "description": "Id for completion response"
        },
        "object": {
          "type": "string",
          "description": "Object for completion response"
        },
        "created": {
          "type": "integer",
          "format": "int32",
          "description": "Created time for completion response"
        },
        "model": {
          "type": "string",
          "description": "Model used for completion response"
        },
        "choices": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/CompletionsChoice"
          },
          "x-ms-identifiers": [],
          "x-cadl-name": "CompletionsChoice[]",
          "description": "Array of choices returned containing text completions to prompts sent"
        }
      },
      "description": "Expected response schema to completion request"
    },
    "CompletionsLogProbsModel": {
      "type": "object",
      "properties": {
        "tokens": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "x-cadl-name": "string[]",
          "description": "Tokens"
        },
        "token_logprobs": {
          "type": "array",
          "items": {
            "type": "number",
            "format": "float"
          },
          "x-cadl-name": "float32[]",
          "description": "LogProbs of Tokens"
        },
        "top_logprobs": {
          "type": "array",
          "items": {
            "type": "object",
            "additionalProperties": {
              "type": "number",
              "format": "float"
            },
            "x-cadl-name": "Record<float32>"
          },
          "x-ms-identifiers": [],
          "x-cadl-name": "Record<float32>[]",
          "description": "Top LogProbs"
        },
        "text_offset": {
          "type": "array",
          "items": {
            "type": "integer",
            "format": "int32"
          },
          "x-cadl-name": "int32[]",
          "description": "Text offset"
        }
      },
      "description": "LogProbs model within completion choice"
    },
    "CompletionsPrompt": {
      "type": "object",
      "properties": {},
      "description": "An optional prompt to complete from, encoded as a string, a list of strings, or\na list of token lists. Defaults to <|endoftext|>. The prompt to complete from.\nIf you would like to provide multiple prompts, use the POST variant of this\nmethod. Note that <|endoftext|> is the document separator that the model sees\nduring training, so if a prompt is not specified the model will generate as if\nfrom the beginning of a new document. Maximum allowed size of string list is\n2048."
    },
    "CompletionsStop": {
      "type": "object",
      "properties": {},
      "description": "A sequence which indicates the end of the current document."
    },
    "EmbeddingsCreateBody": {
      "type": "object",
      "properties": {
        "user": {
          "type": "string",
          "description": "The ID of the end-user, for use in tracking and rate-limiting."
        },
        "input_type": {
          "type": "string",
          "description": "input type of embedding search to use"
        },
        "model": {
          "type": "string",
          "description": "ID of the model to use"
        },
        "input": {
          "$ref": "#/definitions/EmbeddingsInput",
          "description": "An input to embed, encoded as a string, a list of strings, or a list of token\nlists"
        }
      },
      "description": "Embedding request body schema",
      "required": [
        "input"
      ]
    },
    "EmbeddingsCreateRequest": {
      "type": "object",
      "properties": {
        "body": {
          "$ref": "#/definitions/EmbeddingsCreateBody",
          "description": "expected schema for the body of the embedding post request"
        }
      },
      "description": "Input model for embeddings create endpoint",
      "required": [
        "body"
      ]
    },
    "EmbeddingsInput": {
      "type": "object",
      "properties": {},
      "description": "Embedding request body schema, base fields"
    },
    "Versions": {
      "type": "string",
      "enum": [
        "2022-06-01-preview"
      ],
      "x-ms-enum": {
        "name": "Versions",
        "modelAsString": false,
        "values": [
          {
            "name": "v2022_06_01_preview",
            "value": "2022-06-01-preview"
          }
        ]
      }
    },
    "object": {
      "type": "object",
      "properties": {}
    }
  },
  "parameters": {
    "Azure.Core.Foundations.ApiVersionParameter": {
      "name": "api-version",
      "in": "query",
      "required": true,
      "description": "The API version to use for this operation.",
      "minLength": 1,
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "CompletionsCreateRequest.body": {
      "name": "body",
      "in": "body",
      "required": true,
      "description": "expected schema for the body of the completion post request",
      "schema": {
        "$ref": "#/definitions/CompletionsCreateBody"
      },
      "x-ms-parameter-location": "method"
    },
    "CompletionsCreateRequest.deploymentId": {
      "name": "deploymentId",
      "in": "path",
      "required": true,
      "description": "deployment id of the model which was deployed",
      "type": "string",
      "x-ms-parameter-location": "method"
    },
    "EmbeddingsCreateRequest.body": {
      "name": "body",
      "in": "body",
      "required": true,
      "description": "expected schema for the body of the embedding post request",
      "schema": {
        "$ref": "#/definitions/EmbeddingsCreateBody"
      },
      "x-ms-parameter-location": "method"
    },
    "EmbeddingsCreateRequest.deploymentId": {
      "name": "deploymentId",
      "in": "path",
      "required": true,
      "description": "deployment id of the model which was deployed",
      "type": "string",
      "x-ms-parameter-location": "method"
    }
  }
}
