{
  "openapi": "3.0.0",
  "info": {
    "title": "Azure OpenAI Service API",
    "description": "Azure OpenAI APIs for completions and search",
    "version": "2022-03-01-preview"
  },
  "servers": [
    {
      "url": "https://{endpoint}/openai",
      "variables": {
        "endpoint": {
          "default": "your-resource-name.openai.azure.com"
        }
      }
    }
  ],
  "security": [
    {
      "bearer": [
        "api.read"
      ]
    },
    {
      "apiKey": []
    }
  ],
  "paths": {
    "/deployments/{deployment-id}/completions": {
      "post": {
        "summary": "Create a completion from a chosen model",
        "operationId": "completions_create",
        "parameters": [
          {
            "in": "path",
            "name": "deployment-id",
            "required": true,
            "schema": {
              "type": "string",
              "example": "davinci",
              "description": "deployment id of the model which was deployed;"
            }
          },
          {
            "in": "query",
            "name": "api-version",
            "required": true,
            "schema": {
              "type": "string",
              "example": "2022-03-01-preview",
              "description": "api version"
            }
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "type": "object",
                "properties": {
                  "prompt": {
                    "description": "An optional prompt to complete from, encoded as a string, a list of strings, or a list of token lists. Defaults to <|endoftext|>. The prompt to complete from. If you would like to provide multiple prompts, use the POST variant of this method. Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document. Maximum allowed size of string list is 2048.",
                    "oneOf": [
                      {
                        "type": "string",
                        "default": "",
                        "example": "This is a test.",
                        "nullable": true
                      },
                      {
                        "type": "array",
                        "items": {
                          "type": "string",
                          "default": "",
                          "example": "This is a test.",
                          "nullable": false
                        },
                        "description": "Array size minimum of 1 and maximum of 2048"
                      },
                      {
                        "type": "array",
                        "items": {
                          "type": "integer",
                          "nullable": false
                        },
                        "example": [
                          1212,
                          318,
                          257,
                          1332,
                          13
                        ],
                        "description": "Array size minimum of 1"
                      },
                      {
                        "type": "array",
                        "items": {
                          "type": "array",
                          "items": {
                            "type": "integer",
                            "nullable": false
                          }
                        },
                        "example": [
                          [
                            1212,
                            318,
                            257,
                            1332,
                            13
                          ]
                        ],
                        "description": "Array of tokens list size minimum of 1"
                      }
                    ]
                  },
                  "max_tokens": {
                    "description": "The maximum number of tokens to generate. Has minimum of 0.",
                    "type": "integer",
                    "default": 16,
                    "example": 16,
                    "nullable": true
                  },
                  "temperature": {
                    "description": "What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\nWe generally recommend using this or `top_p` but not both.\nMinimum of 0 and maximum of 2 allowed.\n",
                    "type": "number",
                    "default": 1,
                    "example": 1,
                    "nullable": true
                  },
                  "top_p": {
                    "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend using this or `temperature` but not both.\nMinimum of 0 and maximum of 1 allowed.\n",
                    "type": "number",
                    "default": 1,
                    "example": 1,
                    "nullable": true
                  },
                  "logit_bias": {
                    "description": "Defaults to null. Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. As an example, you can pass {\"50256\" &#58; -100} to prevent the <|endoftext|> token from being generated.",
                    "type": "object",
                    "nullable": false
                  },
                  "user": {
                    "description": "The ID of the end-user, for use in tracking and rate-limiting.",
                    "type": "string",
                    "nullable": false
                  },
                  "n": {
                    "description": "How many snippets to generate for each prompt. Minimum of 1 and maximum of 128 allowed.",
                    "type": "integer",
                    "default": 1,
                    "example": 1,
                    "nullable": true
                  },
                  "stream": {
                    "description": "Whether to enable streaming for this endpoint. If set, tokens will be sent as server-sent events as they become available.",
                    "type": "boolean",
                    "nullable": true,
                    "default": false
                  },
                  "logprobs": {
                    "description": "Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. So for example, if `logprobs` is 10, the API will return a list of the 10 most likely tokens. If `logprobs` is 0, only the chosen tokens will have logprobs returned. Minimum of 0 and maximum of 100 allowed.",
                    "type": "integer",
                    "default": null,
                    "nullable": true
                  },
                  "model": {
                    "type": "string",
                    "example": "davinci",
                    "nullable": true,
                    "description": "The name of the model to use"
                  },
                  "echo": {
                    "description": "Echo back the prompt in addition to the completion",
                    "type": "boolean",
                    "default": false,
                    "nullable": true
                  },
                  "stop": {
                    "description": "A sequence which indicates the end of the current document.",
                    "oneOf": [
                      {
                        "type": "string",
                        "default": "<|endoftext|>",
                        "example": "\n",
                        "nullable": true
                      },
                      {
                        "type": "array",
                        "items": {
                          "type": "string",
                          "example": [
                            "\n"
                          ],
                          "nullable": false
                        },
                        "description": "Array minimum size of 1 and maximum of 4"
                      }
                    ]
                  },
                  "completion_config": {
                    "type": "string",
                    "nullable": true
                  },
                  "cache_level": {
                    "description": "can be used to disable any server-side caching, 0=no cache, 1=prompt prefix enabled, 2=full cache",
                    "type": "integer",
                    "nullable": true
                  },
                  "presence_penalty": {
                    "description": "How much to penalize new tokens based on their existing frequency in the text so far. Decreases the model's likelihood to repeat the same line verbatim. Has minimum of -2 and maximum of 2.",
                    "type": "number",
                    "default": 0
                  },
                  "frequency_penalty": {
                    "description": "How much to penalize new tokens based on whether they appear in the text so far. Increases the model's likelihood to talk about new topics.",
                    "type": "number",
                    "default": 0
                  },
                  "best_of": {
                    "description": "How many generations to create server side, and display only the best. Will not stream intermediate progress if best_of > 1. Has maximum value of 128.",
                    "type": "integer"
                  }
                }
              },
              "example": {
                "prompt": "Negate the following sentence.The price for bubblegum increased on thursday.\n\n Negated Sentence:",
                "max_tokens": 50
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "OK",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "id": {
                      "type": "string"
                    },
                    "object": {
                      "type": "string"
                    },
                    "created": {
                      "type": "integer"
                    },
                    "model": {
                      "type": "string"
                    },
                    "choices": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "text": {
                            "type": "string"
                          },
                          "index": {
                            "type": "integer"
                          },
                          "logprobs": {
                            "type": "object",
                            "properties": {
                              "tokens": {
                                "type": "array",
                                "items": {
                                  "type": "string"
                                }
                              },
                              "token_logprobs": {
                                "type": "array",
                                "items": {
                                  "type": "number"
                                }
                              },
                              "top_logprobs": {
                                "type": "array",
                                "items": {
                                  "type": "object",
                                  "additionalProperties": {
                                    "type": "number"
                                  }
                                }
                              },
                              "text_offset": {
                                "type": "array",
                                "items": {
                                  "type": "integer"
                                }
                              }
                            }
                          },
                          "finish_reason": {
                            "type": "string"
                          }
                        }
                      }
                    }
                  }
                },
                "example": {
                  "model": "davinci",
                  "object": "text_completion",
                  "id": "cmpl-4509KAos68kxOqpE2uYGw81j6m7uo",
                  "created": 1637097562,
                  "choices": [
                    {
                      "index": 0,
                      "text": "The price for bubblegum decreased on thursday.",
                      "logprobs": null,
                      "finish_reason": "stop"
                    }
                  ]
                }
              }
            },
            "headers": {
              "apim-request-id": {
                "description": "Request ID for troubleshooting purposes",
                "schema": {
                  "type": "string"
                }
              }
            }
          },
          "default": {
            "description": "Service unavailable",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/errorResponse"
                }
              }
            },
            "headers": {
              "apim-request-id": {
                "description": "Request ID for troubleshooting purposes",
                "schema": {
                  "type": "string"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "errorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "code": {
                "type": "string"
              },
              "message": {
                "type": "string"
              },
              "param": {
                "type": "string"
              },
              "type": {
                "type": "string"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearer": {
        "type": "oauth2",
        "flows": {
          "implicit": {
            "authorizationUrl": "https://login.microsoftonline.com/common/oauth2/v2.0/authorize",
            "scopes": {}
          }
        },
        "x-tokenInfoFunc": "api.middleware.auth.bearer_auth",
        "x-scopeValidateFunc": "api.middleware.auth.validate_scopes"
      },
      "apiKey": {
        "type": "apiKey",
        "name": "api-key",
        "in": "header"
      }
    }
  }
}
