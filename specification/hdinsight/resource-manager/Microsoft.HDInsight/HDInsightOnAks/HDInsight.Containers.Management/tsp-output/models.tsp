import "@typespec/rest";
import "@typespec/http";
import "@azure-tools/typespec-azure-core";
import "@azure-tools/typespec-azure-resource-manager";

using TypeSpec.Rest;
using TypeSpec.Http;
using Azure.ResourceManager;
using Azure.ResourceManager.Foundations;

namespace Microsoft.HDInsight;

interface Operations extends Azure.ResourceManager.Operations {}

@doc("Provisioning state of the resource.")
enum ProvisioningStatus {
  Accepted,
  Succeeded,
  Canceled,
  Failed,
}

@doc("Type of key vault object: secret, key or certificate.")
enum KeyVaultObjectType {
  Key,
  Secret,
  Certificate,
}

@doc("This property indicates if the content is encoded and is case-insensitive. Please set the value to base64 if the content is base64 encoded. Set it to none or skip it if the content is plain text.")
enum ContentEncoding {
  Base64,
  None,
}

@doc("User to specify which type of Autoscale to be implemented - Scheduled Based or Load Based.")
enum AutoscaleType {
  ScheduleBased,
  LoadBased,
}

enum ScheduleDay {
  Sunday,
  Monday,
  Tuesday,
  Wednesday,
  Thursday,
  Friday,
  Saturday,
}

@doc("The action type.")
enum ScaleActionType {
  scaleup,
  scaledown,
}

@doc("The comparison operator.")
enum ComparisonOperator {
  greaterThan,
  greaterThanOrEqual,
  lessThan,
  lessThanOrEqual,
}

@doc("Type of cluster job.")
enum JobType {
  FlinkJob,
}

@doc("A string property that indicates the action to be performed on the Flink job. It can have one of the following enum values => NEW, UPDATE, STATELESS_UPDATE, STOP, START, CANCEL, SAVEPOINT, LIST_SAVEPOINT, or DELETE.")
enum Action {
  NEW,
  UPDATE,
  STATELESS_UPDATE,
  STOP,
  START,
  CANCEL,
  SAVEPOINT,
  LIST_SAVEPOINT,
  DELETE,
}

@doc("Cluster pool resource properties.")
model ClusterPoolResourceProperties {
  @doc("Provisioning state of the resource.")
  @visibility("read")
  provisioningState?: ProvisioningStatus;

  @doc("A unique id generated by the RP to identify the resource.")
  @visibility("read")
  deploymentId?: string;

  @doc("A resource group created by RP, to hold the resources created by RP on-behalf of customers. It will also be used to generate aksManagedResourceGroupName by pattern: MC_{managedResourceGroupName}_{clusterPoolName}_{region}. Please make sure it meets resource group name restriction.")
  @maxLength(40)
  @minLength(1)
  managedResourceGroupName?: string;

  @doc("A resource group created by AKS, to hold the infrastructure resources created by AKS on-behalf of customers. It is generated by cluster pool name and managed resource group name by pattern: MC_{managedResourceGroupName}_{clusterPoolName}_{region}")
  @visibility("read")
  aksManagedResourceGroupName?: string;

  @doc("CLuster pool profile.")
  clusterPoolProfile?: ClusterPoolProfile;

  @doc("CLuster pool compute profile.")
  computeProfile: ClusterPoolComputeProfile;

  @doc("Properties of underlying AKS cluster.")
  @visibility("read")
  aksClusterProfile?: AksClusterProfile;

  @doc("Cluster pool network profile.")
  networkProfile?: ClusterPoolNetworkProfile;

  @doc("Cluster pool log analytics profile to enable OMS agent for AKS cluster.")
  logAnalyticsProfile?: ClusterPoolLogAnalyticsProfile;

  @doc("Business status of the resource.")
  @visibility("read")
  status?: string;
}

@doc("Cluster pool profile.")
model ClusterPoolProfile {
  @doc("Cluster pool version is a 2-part version.")
  @pattern("^(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})$")
  clusterPoolVersion: string;
}

@doc("Cluster pool compute profile.")
model ClusterPoolComputeProfile {
  @doc("The virtual machine SKU.")
  @pattern("^[a-zA-Z0-9_\\-]{0,256}$")
  vmSize: string;

  @doc("The number of virtual machines.")
  @visibility("read")
  count?: int32;
}

@doc("Properties of the cluster pool underlying AKS cluster.")
model AksClusterProfile {
  @doc("ARM Resource ID of the AKS cluster")
  aksClusterResourceId?: ResourceIdentifier<[
    {
      type: "Microsoft.ContainerService/managedClusters";
    }
  ]>;

  @doc("Identity properties of the AKS cluster agentpool MSI")
  aksClusterAgentPoolIdentityProfile?: IdentityProfile;

  @doc("AKS control plane and default node pool version of this ClusterPool")
  @visibility("read")
  aksVersion?: string;
}

@doc("Identity Profile with details of an MSI.")
model IdentityProfile {
  @doc("ResourceId of the MSI.")
  msiResourceId: ResourceIdentifier<[
    {
      type: "Microsoft.ManagedIdentity/userAssignedIdentities";
    }
  ]>;

  @doc("ClientId of the MSI.")
  @pattern("^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$")
  msiClientId: string;

  @doc("ObjectId of the MSI.")
  @pattern("^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$")
  msiObjectId: string;
}

@doc("Cluster pool networking configuration.")
model ClusterPoolNetworkProfile {
  @doc("Cluster pool subnet resource id.")
  subnetId: ResourceIdentifier<[
    {
      type: "Microsoft.Network/virtualNetworks/subnets";
    }
  ]>;
}

@doc("Cluster pool log analytics profile used to enable or disable OMS agent for AKS cluster.")
model ClusterPoolLogAnalyticsProfile {
  @doc("True if log analytics is enabled for cluster pool, otherwise false.")
  enabled: boolean;

  @doc("Log analytics workspace to associate with the OMS agent.")
  workspaceId?: ResourceIdentifier<[
    {
      type: "Microsoft.OperationalInsights/workspaces";
    }
  ]>;
}

@doc("Common fields that are returned in the response for all Azure Resource Manager resources")
model Resource {
  @doc("Fully qualified resource ID for the resource. E.g. \"/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}\"")
  @visibility("read")
  id?: ResourceIdentifier;

  @doc("The name of the resource")
  @visibility("read")
  name?: string;

  @doc("The type of the resource. E.g. \"Microsoft.Compute/virtualMachines\" or \"Microsoft.Storage/storageAccounts\"")
  @visibility("read")
  type?: string;

  @doc("Azure Resource Manager metadata containing createdBy and modifiedBy information.")
  @visibility("read")
  systemData?: SystemData;
}

@doc("Tags object for patch operations.")
model TagsObject {
  @doc("Resource tags.")
  tags?: Record<string>;
}

@doc("Cluster resource properties.")
model ClusterResourceProperties {
  @doc("Provisioning state of the resource.")
  @visibility("read")
  provisioningState?: ProvisioningStatus;

  @doc("The type of cluster.")
  @visibility("read", "create")
  @pattern("^[a-zA-Z][a-zA-Z0-9]{0,31}$")
  clusterType: string;

  @doc("A unique id generated by the RP to identify the resource.")
  @visibility("read")
  deploymentId?: string;

  @doc("The compute profile.")
  computeProfile: ComputeProfile;

  @doc("Cluster profile.")
  clusterProfile: ClusterProfile;

  @doc("Business status of the resource.")
  @visibility("read")
  status?: string;
}

@doc("The compute profile.")
model ComputeProfile {
  @doc("The nodes definitions.")
  nodes: NodeProfile[];
}

@doc("The node profile.")
model NodeProfile {
  @doc("The node type.")
  @pattern("^(head|Head|HEAD|worker|Worker|WORKER)$")
  type: string;

  @doc("The virtual machine SKU.")
  @pattern("^[a-zA-Z0-9_\\-]{0,256}$")
  vmSize: string;

  @doc("The number of virtual machines.")
  @minValue(1)
  count: int32;
}

@doc("Cluster profile.")
model ClusterProfile {
  @doc("Version with 3/4 part.")
  @pattern("^(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})(?:\\.(0|[1-9][0-9]{0,18}))?$")
  clusterVersion: string;

  @doc("Version with three part.")
  @pattern("^(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})$")
  ossVersion: string;

  @doc("Component list of this cluster type and version.")
  @visibility("read")
  components?: ClusterComponentsItem[];

  @doc("Identity Profile with details of an MSI.")
  identityProfile: IdentityProfile;

  @doc("Authorization profile with details of AAD user Ids and group Ids authorized for data plane access.")
  authorizationProfile: AuthorizationProfile;

  @doc("The cluster secret profile.")
  secretsProfile?: SecretsProfile;

  @doc("The service configs profiles.")
  serviceConfigsProfiles?: ClusterServiceConfigsProfile[];

  @doc("Cluster connectivity profile.")
  @visibility("read")
  connectivityProfile?: ConnectivityProfile;

  @doc("Cluster log analytics profile to enable or disable OMS agent for cluster.")
  logAnalyticsProfile?: ClusterLogAnalyticsProfile;

  @doc("Cluster Prometheus profile.")
  prometheusProfile?: ClusterPrometheusProfile;

  @doc("Ssh profile for the cluster.")
  sshProfile?: SshProfile;

  @doc("This is the Autoscale profile for the cluster. This will allow customer to create cluster enabled with Autoscale.")
  autoscaleProfile?: AutoscaleProfile;

  @doc("Kafka cluster profile.")
  kafkaProfile?: Record<unknown>;

  @doc("Trino Cluster profile.")
  trinoProfile?: TrinoProfile;

  @doc("LLAP cluster profile.")
  llapProfile?: Record<unknown>;

  @doc("The Flink cluster profile.")
  flinkProfile?: FlinkProfile;

  @doc("The spark cluster profile.")
  sparkProfile?: SparkProfile;

  @doc("Stub cluster profile.")
  stubProfile?: Record<unknown>;

  @doc("The script action profile list.")
  scriptActionProfiles?: ScriptActionProfile[];
}

model ClusterComponentsItem {
  name?: string;
  version?: string;
}

@doc("Authorization profile with details of AAD user Ids and group Ids authorized for data plane access.")
model AuthorizationProfile {
  @doc("AAD user Ids authorized for data plane access.")
  userIds?: string[];

  @doc("AAD group Ids authorized for data plane access.")
  groupIds?: string[];
}

@doc("The cluster secret profile.")
model SecretsProfile {
  @doc("Name of the user Key Vault where all the cluster specific user secrets are stored.")
  keyVaultResourceId: ResourceIdentifier<[
    {
      type: "Microsoft.KeyVault/vaults";
    }
  ]>;

  @doc("Properties of Key Vault secret.")
  secrets?: SecretReference[];
}

@doc("Secret reference and corresponding properties of a key vault secret.")
model SecretReference {
  @doc("Reference name of the secret to be used in service configs.")
  referenceName: string;

  @doc("Type of key vault object: secret, key or certificate.")
  type: KeyVaultObjectType;

  @doc("Version of the secret in key vault.")
  version?: string;

  @doc("Object identifier name of the secret in key vault.")
  @pattern("^[a-zA-Z][a-zA-Z0-9-]{1,126}$")
  keyVaultObjectName: string;
}

@doc("Cluster service configs.")
model ClusterServiceConfigsProfile {
  @doc("Name of the service the configurations should apply to.")
  serviceName: string;

  @doc("List of service configs.")
  configs: ClusterServiceConfig[];
}

@doc("Cluster configs per component.")
model ClusterServiceConfig {
  @doc("Name of the component the config files should apply to.")
  component: string;

  @doc("List of Config Files.")
  files: ClusterConfigFile[];
}

@doc("Cluster configuration files.")
model ClusterConfigFile {
  @doc("Configuration file name.")
  fileName: string;

  @doc("Free form content of the entire configuration file.")
  content?: string;

  @doc("This property indicates if the content is encoded and is case-insensitive. Please set the value to base64 if the content is base64 encoded. Set it to none or skip it if the content is plain text.")
  encoding?: ContentEncoding;

  @doc("Path of the config file if content is specified.")
  path?: string;

  @doc("""
List of key value pairs
where key represents a valid service configuration name and value represents the value of the config.
""")
  values?: Record<string>;
}

@doc("Cluster connectivity profile.")
model ConnectivityProfile {
  @doc("Web connectivity endpoint details.")
  @visibility("read")
  web: WebConnectivityEndpoint;

  @doc("List of SSH connectivity endpoints.")
  ssh?: SshConnectivityEndpoint[];
}

@doc("Web connectivity endpoint details.")
model WebConnectivityEndpoint {
  @doc("Web connectivity endpoint.")
  fqdn: string;
}

@doc("SSH connectivity endpoint details.")
model SshConnectivityEndpoint {
  @doc("SSH connectivity endpoint.")
  endpoint: string;
}

@doc("Cluster log analytics profile to enable or disable OMS agent for cluster.")
model ClusterLogAnalyticsProfile {
  @doc("True if log analytics is enabled for the cluster, otherwise false.")
  enabled: boolean;

  @doc("Collection of logs to be enabled or disabled for log analytics.")
  applicationLogs?: ClusterLogAnalyticsApplicationLogs;

  @doc("True if metrics are enabled, otherwise false.")
  metricsEnabled?: boolean;
}

@doc("Collection of logs to be enabled or disabled for log analytics.")
model ClusterLogAnalyticsApplicationLogs {
  @doc("True if stdout is enabled, otherwise false.")
  stdOutEnabled?: boolean;

  @doc("True if stderror is enabled, otherwise false.")
  stdErrorEnabled?: boolean;
}

@doc("Cluster Prometheus profile.")
model ClusterPrometheusProfile {
  @doc("Enable Prometheus for cluster or not.")
  enabled: boolean;
}

@doc("Ssh profile for the cluster.")
model SshProfile {
  @doc("Number of ssh pods per cluster.")
  @maxValue(5)
  count: int32;

  @doc("Prefix of the pod names. Pod number will be appended to the prefix. The ingress URLs for the pods will be available at <clusterFqdn>/<sshBasePath>/<prefix>-<number>")
  @visibility("read")
  podPrefix?: string;
}

@doc("This is the Autoscale profile for the cluster. This will allow customer to create cluster enabled with Autoscale.")
model AutoscaleProfile {
  @doc("This indicates whether auto scale is enabled on HDInsight on AKS cluster.")
  enabled: boolean;

  @doc("This property is for graceful decommission timeout; It has a default setting of 3600 seconds before forced shutdown takes place. This is the maximal time to wait for running containers and applications to complete before transition a DECOMMISSIONING node into DECOMMISSIONED. The default value is 3600 seconds. Negative value (like -1) is handled as infinite timeout.")
  gracefulDecommissionTimeout?: int32;

  @doc("User to specify which type of Autoscale to be implemented - Scheduled Based or Load Based.")
  autoscaleType?: AutoscaleType;

  @doc("Profiles of schedule based Autoscale.")
  scheduleBasedConfig?: ScheduleBasedConfig;

  @doc("Profiles of load based Autoscale.")
  loadBasedConfig?: LoadBasedConfig;
}

@doc("Profile of schedule based Autoscale.")
model ScheduleBasedConfig {
  @doc("User has to specify the timezone on which the schedule has to be set for schedule based autoscale configuration.")
  timeZone: string;

  @doc("Setting default node count of current schedule configuration. Default node count specifies the number of nodes which are default when an specified scaling operation is executed (scale up/scale down)")
  defaultCount: int32;

  @doc("This specifies the schedules where scheduled based Autoscale to be enabled, the user has a choice to set multiple rules within the schedule across days and times (start/end).")
  schedules: Schedule[];
}

@doc("Schedule definition.")
model Schedule {
  @doc("User has to set the start time of current schedule configuration, format like 10:30 (HH:MM).")
  @pattern("^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$")
  startTime: string;

  @doc("User has to set the end time of current schedule configuration, format like 10:30 (HH:MM).")
  @pattern("^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$")
  endTime: string;

  @doc("User has to set the node count anticipated at end of the scaling operation of the set current schedule configuration, format is integer.")
  count: int32;

  @doc("User has to set the days where schedule has to be set for autoscale operation.")
  days: ScheduleDay[];
}

@doc("Profile of load based Autoscale.")
model LoadBasedConfig {
  @doc("User needs to set the minimum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.")
  minNodes: int32;

  @doc("User needs to set the maximum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.")
  maxNodes: int32;

  @doc("User can specify the poll interval, this is the time period (in seconds) after which scaling metrics are polled for triggering a scaling operation.")
  pollInterval?: int32;

  @doc("This is a cool down period, this is a time period in seconds, which determines the amount of time that must elapse between a scaling activity started by a rule and the start of the next scaling activity, regardless of the rule that triggers it. The default value is 300 seconds.")
  cooldownPeriod?: int32;

  @doc("The scaling rules.")
  scalingRules: ScalingRule[];
}

@doc("The scaling rule.")
model ScalingRule {
  @doc("The action type.")
  actionType: ScaleActionType;

  @doc("This is an evaluation count for a scaling condition, the number of times a trigger condition should be successful, before scaling activity is triggered.")
  evaluationCount: int32;

  @doc("Metrics name for individual workloads. For example: cpu")
  scalingMetric: string;

  @doc("The comparison rule.")
  comparisonRule: ComparisonRule;
}

@doc("The comparison rule.")
model ComparisonRule {
  @doc("The comparison operator.")
  operator: ComparisonOperator;

  @doc("Threshold setting.")
  threshold: float32;
}

@doc("Trino Cluster profile.")
model TrinoProfile {
  @doc("Trino cluster catalog options.")
  catalogOptions?: CatalogOptions;

  @doc("Trino Coordinator.")
  coordinator?: TrinoCoordinator;

  @doc("Trino user plugins spec")
  userPluginsSpec?: TrinoUserPlugins;

  @doc("User telemetry")
  userTelemetrySpec?: TrinoUserTelemetry;

  @doc("Trino worker.")
  worker?: TrinoWorker;
}

@doc("Trino cluster catalog options.")
model CatalogOptions {
  @doc("hive catalog options.")
  hive?: HiveCatalogOption[];
}

@doc("Hive Catalog Option")
model HiveCatalogOption {
  @doc("Name of trino catalog which should use specified hive metastore.")
  @minLength(1)
  catalogName: string;

  @doc("Secret reference name from secretsProfile.secrets containing password for database connection.")
  metastoreDbConnectionPasswordSecret: string;

  @doc("Connection string for hive metastore database.")
  metastoreDbConnectionURL: string;

  @doc("User name for database connection.")
  metastoreDbConnectionUserName: string;

  @doc("Metastore root directory URI, format: abfs[s]://<container>@<account_name>.dfs.core.windows.net/<path>. More details: https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction-abfs-uri")
  metastoreWarehouseDir: string;
}

@doc("Trino Coordinator.")
model TrinoCoordinator {
  @doc("Trino debug configuration.")
  debug?: TrinoDebugConfig;

  @doc("The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: true.")
  highAvailabilityEnabled?: boolean;
}

@doc("Trino debug configuration.")
model TrinoDebugConfig {
  @doc("The flag that if enable debug or not.")
  enable?: boolean;

  @doc("The debug port.")
  port?: int32;

  @doc("The flag that if suspend debug or not.")
  suspend?: boolean;
}

@doc("Trino user plugins spec")
model TrinoUserPlugins {
  @doc("Trino user plugins.")
  plugins?: TrinoUserPlugin[];
}

@doc("Trino user plugin.")
model TrinoUserPlugin {
  @doc("Denotes whether the plugin is active or not.")
  enabled?: boolean;

  @doc("This field maps to the sub-directory in trino plugins location, that will contain all the plugins under path.")
  @minLength(1)
  name?: string;

  @doc("Fully qualified path to the folder containing the plugins.")
  @minLength(1)
  @pattern("^(https)|(abfss)://.*$")
  path?: string;
}

@doc("User telemetry")
model TrinoUserTelemetry {
  @doc("Trino user telemetry definition.")
  storage?: TrinoTelemetryConfig;
}

@doc("Trino user telemetry definition.")
model TrinoTelemetryConfig {
  @doc("Hive Catalog name used to mount external tables on the logs written by trino, if not specified there tables are not created.")
  @minLength(1)
  hivecatalogName?: string;

  @doc("Schema of the above catalog to use, to mount query logs as external tables, if not specified tables will be mounted under schema trinologs.")
  hivecatalogSchema?: string;

  @doc("Retention period for query log table partitions, this doesn't have any affect on actual data.")
  partitionRetentionInDays?: int32;

  @doc("Azure storage location of the blobs.")
  @minLength(1)
  path?: string;
}

@doc("Trino worker.")
model TrinoWorker {
  @doc("Trino debug configuration.")
  debug?: TrinoDebugConfig;
}

@doc("The Flink cluster profile.")
model FlinkProfile {
  @doc("The storage profile")
  storage: FlinkStorageProfile;

  @doc("The number of task managers.")
  numReplicas?: int32;

  @doc("Job Manager container/ process CPU and memory requirements")
  jobManager: ComputeResourceDefinition;

  @doc("History Server container/ process CPU and memory requirements")
  historyServer?: ComputeResourceDefinition;

  @doc("Task Manager container/ process CPU and memory requirements")
  taskManager: ComputeResourceDefinition;

  @doc("Flink cluster catalog options.")
  catalogOptions?: FlinkCatalogOptions;
}

@doc("The storage profile")
model FlinkStorageProfile {
  @doc("Storage account uri which is used for savepoint and checkpoint state.")
  @pattern("^(\\w{4,5})://(.*)@(.*).\\b(blob|dfs)\\b\\.core\\.windows\\.net$")
  storageUri: string;

  @doc("Storage key is only required for wasb(s) storage.")
  storagekey?: string;
}

@doc("The cpu and memory requirement definition.")
model ComputeResourceDefinition {
  @doc("The required CPU.")
  cpu: float32;

  @doc("The required memory in MB, Container memory will be 110 percentile")
  memory: int32;
}

@doc("Flink cluster catalog options.")
model FlinkCatalogOptions {
  @doc("Hive Catalog Option for Flink cluster.")
  hive?: FlinkHiveCatalogOption;
}

@doc("Hive Catalog Option for Flink cluster.")
model FlinkHiveCatalogOption {
  @doc("Secret reference name from secretsProfile.secrets containing password for database connection.")
  metastoreDbConnectionPasswordSecret: string;

  @doc("Connection string for hive metastore database.")
  metastoreDbConnectionURL: string;

  @doc("User name for database connection.")
  metastoreDbConnectionUserName: string;
}

@doc("The spark cluster profile.")
model SparkProfile {
  @doc("The default storage URL.")
  defaultStorageUrl?: string;

  @doc("The metastore specification for Spark cluster.")
  metastoreSpec?: SparkMetastoreSpec;

  @doc("Spark user plugins spec")
  userPluginsSpec?: SparkUserPlugins;
}

@doc("The metastore specification for Spark cluster.")
model SparkMetastoreSpec {
  @doc("The database server host.")
  dbServerHost: string;

  @doc("The database name.")
  dbName: string;

  @doc("The database user name.")
  dbUserName: string;

  @doc("The secret name which contains the database user password.")
  dbPasswordSecretName: string;

  @doc("The key vault resource id.")
  keyVaultId: string;

  @doc("The thrift url.")
  thriftUrl?: string;
}

@doc("Spark user plugins spec")
model SparkUserPlugins {
  @doc("Spark user plugins.")
  plugins?: SparkUserPlugin[];
}

@doc("Spark user plugin.")
model SparkUserPlugin {
  @doc("Fully qualified path to the folder containing the plugins.")
  @minLength(1)
  @pattern("^(https)|(abfss)://.*$")
  path: string;
}

@doc("The script action profile.")
model ScriptActionProfile {
  @doc("Type of the script action. Supported type is bash scripts.")
  type: string;

  @doc("Script name.")
  name: string;

  @doc("Url of the script file.")
  @pattern("^(https)|(http)|(abfss)|(abfs)|(wasbs)|(wasb)://.*$")
  url: string;

  @doc("Additional parameters for the script action. It should be space-separated list of arguments required for script execution.")
  parameters?: string;

  @doc("List of services to apply the script action.")
  services: string[];

  @doc("Timeout duration for the script action in minutes.")
  timeoutInMinutes?: int32;

  @doc("Specify if the script should persist on the cluster.")
  shouldPersist?: boolean;
}

@doc("The parameters for resizing a cluster.")
model ClusterResizeData extends TrackedResource {
  @doc("Sets the properties. Define cluster resize specific properties.")
  properties?: ClusterResizeProperties;
}

@doc("The properties for resizing a cluster.")
model ClusterResizeProperties {
  @doc("Target node count of worker node.")
  targetWorkerNodeCount: int32;
}

@doc("The patch for a cluster.")
model ClusterPatch extends TrackedResource {
  @doc("Define cluster patch specific properties.")
  properties?: ClusterPatchProperties;
}

@doc("Cluster resource patch data.")
model ClusterPatchProperties {
  @doc("Cluster resource patch properties.")
  clusterProfile?: UpdatableClusterProfile;
}

@doc("Cluster resource patch properties.")
model UpdatableClusterProfile {
  @doc("The service configs profiles.")
  serviceConfigsProfiles?: ClusterServiceConfigsProfile[];

  @doc("Ssh profile for the cluster.")
  sshProfile?: SshProfile;

  @doc("This is the Autoscale profile for the cluster. This will allow customer to create cluster enabled with Autoscale.")
  autoscaleProfile?: AutoscaleProfile;

  @doc("Authorization profile with details of AAD user Ids and group Ids authorized for data plane access.")
  authorizationProfile?: AuthorizationProfile;

  @doc("Cluster log analytics profile to enable or disable OMS agent for cluster.")
  logAnalyticsProfile?: ClusterLogAnalyticsProfile;

  @doc("Cluster Prometheus profile.")
  prometheusProfile?: ClusterPrometheusProfile;

  @doc("The script action profile list.")
  scriptActionProfiles?: ScriptActionProfile[];
}

@doc("Cluster job.")
model ClusterJob extends ProxyResource {
  @doc("Properties of cluster job.")
  properties: ClusterJobProperties;
}

@doc("Properties of cluster job.")
@discriminator("jobType")
model ClusterJobProperties {}

@doc("Collection of cluster job.")
model ClusterJobList is Azure.Core.Page<ClusterJob>;

@doc("Cluster instance service configs api response.")
model ServiceConfigListResult is Azure.Core.Page<ServiceConfigResult>;

@doc("Cluster instance service config.")
model ServiceConfigResult {
  @doc("Cluster instance service config properties.")
  properties?: ServiceConfigResultProperties;
}

@doc("Cluster instance service config properties.")
model ServiceConfigResultProperties extends ServiceConfigListResultProperties {}

@doc("Service config response.")
model ServiceConfigListResultProperties {
  @doc("Service Config Name.")
  serviceName: string;

  @doc("File Name.")
  fileName: string;

  @doc("Content in the service config file.")
  content?: string;

  @doc("Component Name.")
  componentName: string;

  @doc("Config type.")
  type?: string;

  @doc("Config file path.")
  path?: string;

  @doc("The custom keys.")
  customKeys?: Record<string>;

  @doc("The default keys.")
  defaultKeys?: Record<ServiceConfigListResultValueEntity>;
}

@doc("Default config details.")
model ServiceConfigListResultValueEntity {
  @doc("Config value.")
  value: string;

  @doc("Config description.")
  description?: string;
}

@doc("Details of check name availability request body.")
model NameAvailabilityParameters {
  @doc("Name for checking availability.")
  name?: string;

  @doc("The resource type in Microsoft.HDInsight.")
  type?: string;
}

@doc("Result of check name availability.")
model NameAvailabilityResult {
  @doc("Indicator of availability of the Microsoft.HDInsight resource name.")
  nameAvailable?: boolean;

  @doc("The reason of unavailability.")
  reason?: string;

  @doc("The error message of unavailability.")
  message?: string;
}

@doc("The instance view of a HDInsight Cluster.")
model ClusterInstanceViewsResult is Azure.Core.Page<ClusterInstanceViewResult>;

@doc("Cluster Instance View.")
model ClusterInstanceViewResult {
  @doc("Name of the instance view.")
  name: string;

  @doc("Properties of the instance view.")
  properties: ClusterInstanceViewResultProperties;
}

@doc("Properties of the instance view.")
model ClusterInstanceViewResultProperties
  extends ClusterInstanceViewProperties {}

@doc("Cluster Instance View Properties.")
model ClusterInstanceViewProperties {
  @doc("Status of the instance view.")
  status: ClusterInstanceViewStatus;

  @doc("List of statuses of relevant services that make up the HDInsight on aks cluster to surface to the customer.")
  serviceStatuses: ServiceStatus[];
}

@doc("Status of the instance view.")
model ClusterInstanceViewStatus {
  @doc("The cluster ready status")
  ready: string;

  @doc("The status reason.")
  reason?: string;

  @doc("The additional message.")
  message?: string;
}

@doc("Describes the status of a service of a HDInsight on aks cluster.")
model ServiceStatus {
  @doc("Kind of the service. E.g. \"Zookeeper\".")
  kind: string;

  @doc("Indicates if the service is ready / healthy. Values can be \"true\", \"false\", \"unknown\" or anything else.")
  ready: string;

  @doc("A message describing the error if any.")
  message?: string;
}

@doc("Represents a list of cluster pool versions.")
model ClusterPoolVersionsListResult is Azure.Core.Page<ClusterPoolVersion>;

@doc("Available cluster pool version.")
model ClusterPoolVersion extends ProxyResource {
  @doc("Cluster pool version properties.")
  properties?: ClusterPoolVersionProperties;
}

@doc("Cluster pool version properties.")
model ClusterPoolVersionProperties {
  @doc("Cluster pool version is a 2-part version.")
  @pattern("^(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})$")
  clusterPoolVersion?: string;

  @doc("AKS version.")
  aksVersion?: string;

  @doc("Indicate if this version is in preview or not.")
  isPreview?: boolean;
}

@doc("Represents a list of cluster versions.")
model ClusterVersionsListResult is Azure.Core.Page<ClusterVersion>;

@doc("Available cluster version.")
model ClusterVersion extends ProxyResource {
  @doc("Cluster version properties.")
  properties?: ClusterVersionProperties;
}

@doc("Cluster version properties.")
model ClusterVersionProperties {
  @doc("The type of cluster.")
  @pattern("^[a-zA-Z][a-zA-Z0-9]{0,31}$")
  clusterType?: string;

  @doc("Version with three part.")
  @pattern("^(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})$")
  clusterVersion?: string;

  @doc("Version with three part.")
  @pattern("^(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})\\.(0|[1-9][0-9]{0,18})$")
  ossVersion?: string;

  @doc("The two part cluster pool version. If the cluster version is before cluster pool version on-board, the return value will be empty string")
  clusterPoolVersion?: string;

  @doc("Indicate if this version is in preview or not.")
  isPreview?: boolean;

  @doc("Component list of this cluster type and version.")
  @visibility("read")
  components?: ClusterComponentsItem[];
}

@doc("Properties of flink job.")
model FlinkJobProperties extends ClusterJobProperties {
  @doc("Name of job")
  jobName: string;

  @doc("A string property that specifies the directory where the job JAR is located.")
  jobJarDirectory?: string;

  @doc("A string property that represents the name of the job JAR.")
  jarName?: string;

  @doc("A string property that specifies the entry class for the Flink job.")
  entryClass?: string;

  @doc("A string property representing additional JVM arguments for the Flink job. It should be space separated value.")
  args?: string;

  @doc("A string property that represents the name of the savepoint for the Flink job")
  savePointName?: string;

  @doc("A string property that indicates the action to be performed on the Flink job. It can have one of the following enum values => NEW, UPDATE, STATELESS_UPDATE, STOP, START, CANCEL, SAVEPOINT, LIST_SAVEPOINT, or DELETE.")
  action?: Action;

  @doc("Additional properties used to configure Flink jobs. It allows users to set properties such as parallelism and jobSavePointDirectory. It accepts additional key-value pairs as properties, where the keys are strings and the values are strings as well.")
  flinkConfiguration?: Record<string>;

  @doc("Unique id for identifying a job")
  @visibility("read")
  jobId?: string;

  @doc("Status of job.")
  @visibility("read")
  status?: string;

  @doc("Output of job.")
  @visibility("read")
  jobOutput?: string;

  @doc("Action result of job.")
  @visibility("read")
  actionResult?: string;

  @doc("The last savepoint.")
  @visibility("read")
  lastSavePoint?: string;

  @doc("Type of cluster job.")
  jobType: "FlinkJob";
}
